
**Ce document unique est votre guide, votre r√©f√©rence pour vous et pour IA pour construire et maintenir votre assistant Khaldounia.**

Il contient :

‚úÖ Pr√©requis (mat√©riel, OS, d√©pendances)
----‚öôÔ∏è Installation compl√®te : Ollama, XTTS, LangChain, ChromaDB

üß© Modules facultatifs : Whisper, WebSearch, ImgGen, Actions syst√®me
----üõ†Ô∏è Strat√©gie de d√©bogage en plusieurs niveaux

üíæ Sauvegarde et gestion des mod√®les
----üìé Annexes avec scripts, chemins, tests et bonnes pratiques

**[DEBUT DU PROMPT de recherche avanc√©e]**

**Persona et R√¥le :**
Agis en tant qu'**Architecte Logiciel Senior et Expert en DevOps**, sp√©cialis√© dans les syst√®mes d'IA/ML locaux, Python, LangChain, Docker, et l'int√©gration WSL2/GPU NVIDIA. Tu poss√®des une expertise approfondie en revue de code, conception d'architecture distribu√©e, s√©curit√© applicative et gestion des d√©pendances.

**Contexte :**
Je te fournis un plan d'installation d√©taill√© complet ("Installation_Khaldounia_Plan.md"), √©labor√© par un utilisateur novice (Halim-IA) en collaboration avec une instance pr√©c√©dente de Gemini. Ce plan vise √† d√©ployer un assistant IA local nomm√© "Khaldounia" sur un PC Windows 10/11 via WSL2 (Ubuntu) avec un GPU NVIDIA RTX 5090. Le plan couvre les Phases 0 √† 10 et inclut des Annexes (A-E). L'objectif est de cr√©er une application multi-conteneurs (Ollama, XTTS, ChromaDB, Whisper, Stable Diffusion, application principale LangChain/Chainlit) orchestr√©e par Docker Compose.

**Objectif Principal : Analyse Technique Approfondie (Code & Architecture)**
Ton objectif principal est de r√©aliser une **revue technique critique et constructive de l'int√©gralit√© de ce plan**, en te concentrant sp√©cifiquement sur les aspects suivants d'un point de vue d'ing√©nierie logicielle et DevOps :

1.  **Qualit√© du Code Python (`app.py` final - Phase 10) :**
    * Clart√©, lisibilit√©, respect des conventions PEP 8.
    * Robustesse : Gestion des erreurs (utilisation des `try...except`, logging des erreurs sp√©cifiques).
    * Efficacit√© : Optimisations potentielles, gestion des ressources (ex: appels API asynchrones vs synchrones si pertinent).
    * S√©curit√© : Validation des inputs (surtout pour les outils syst√®me), gestion des chemins (`_is_path_safe`), exposition involontaire d'informations.
    * Modularit√© et Extensibilit√© : Structure du code, facilit√© d'ajout de nouveaux outils ou fonctionnalit√©s.
2.  **Configuration Docker (`Dockerfile`, `docker-compose.yml`) :**
    * Optimisation du `Dockerfile` : Ordre des commandes (cache layers), taille de l'image finale, s√©curit√© (utilisateur non-root ?).
    * Robustesse de `docker-compose.yml` : D√©finitions des services, gestion des d√©pendances (`depends_on`), configuration r√©seau, gestion des volumes (chemins absolus vs nomm√©s - analyse des risques/b√©n√©fices dans ce contexte), configuration des ressources (CPU/RAM/GPU), arguments CLI pour les services (SD WebUI notamment).
    * Coh√©rence des versions fig√©es entre `Dockerfile`, `requirements.txt` et `docker-compose.yml`.
3.  **Gestion des D√©pendances (`requirements.txt`, D√©pendances Syst√®me) :**
    * Pertinence et n√©cessit√© de chaque d√©pendance Python list√©e.
    * Risques li√©s aux versions fig√©es choisies (conflits potentiels connus, versions obsol√®tes avec vuln√©rabilit√©s ?).
    * Compl√©tude des d√©pendances syst√®me dans le `Dockerfile` pour `unstructured` et autres.
4.  **Architecture Logicielle et Int√©grations API :**
    * Solidit√© de l'architecture multi-services : Communication inter-conteneurs (variables d'env, r√©seau Docker).
    * Fiabilit√© des appels API dans `app.py` (timeouts, gestion des erreurs HTTP, retries potentiels si n√©cessaire).
    * Conception de l'Agent LangChain : Choix de ReAct, pertinence des descriptions d'outils pour le LLM, gestion du flux de pens√©e et des erreurs de parsing.
5.  **Script de Validation (`validate_khaldounia.sh`) :**
    * Robustesse et couverture du script.
    * Potentiels faux positifs/n√©gatifs. Suggestions d'am√©lioration.
6.  **S√©curit√© Globale :**
    * Points d'attention sp√©cifiques (ports expos√©s sur `0.0.0.0`, acc√®s API sans authentification - normal pour du local mais √† signaler, validation des inputs de l'agent).
7.  **Applicabilit√© pour Novice (Aspects Techniques) :**
    * Identifier les √©tapes de configuration ou les fichiers (`docker-compose.yml`, `app.py` initial) qui pr√©sentent le plus de risque d'erreur pour un novice *lors de la modification ou de l'adaptation*.

**M√©thodologie d'Analyse Demand√©e :**
* Analyse m√©ticuleusement chaque phase et chaque fichier de code/configuration fourni dans le plan.
* √âvalue la coh√©rence technique entre les diff√©rentes parties.
* Identifie les points forts, les faiblesses, les risques potentiels (techniques, s√©curit√©, performance) et les goulots d'√©tranglement √©ventuels.
* Consid√®re les bonnes pratiques de d√©veloppement logiciel, de gestion de conteneurs et de d√©ploiement local d'IA.
* N'h√©site pas √† pointer les incoh√©rences ou les ambigu√Øt√©s, m√™me mineures.

**Format de Sortie Attendu : Rapport Structur√©**
Fournis ta r√©ponse sous forme d'un rapport d√©taill√© et structur√© comprenant :
1.  **Synth√®se Globale :** Ton √©valuation g√©n√©rale de la qualit√© technique et architecturale du plan.
2.  **Analyse D√©taill√©e par Th√®me :** Reprends les 7 points list√©s dans "Objectif Principal" ci-dessus, en d√©veloppant tes observations pour chacun.
3.  **Points Forts Techniques Cl√©s :** Liste num√©rot√©e des aspects particuli√®rement bien con√ßus.
4.  **Faiblesses et Risques Techniques Identifi√©s :** Liste num√©rot√©e et **prioris√©e par criticit√©** (Critique > Majeur > Mineur), avec justification technique pour chaque point.
5.  **Recommandations d'Am√©lioration Concr√®tes :** Liste num√©rot√©e et **prioris√©e** de suggestions sp√©cifiques pour am√©liorer la robustesse, la s√©curit√©, la performance ou la maintenabilit√©. Fournis des exemples de code ou de configuration si pertinent. Indique clairement si une recommandation est **critique** (√† faire avant installation) ou **optionnelle/post-installation**.

**Ton Attendue :**
Sois critique mais constructif. Fournis des justifications techniques claires pour tes affirmations. Adopte un ton professionnel et expert.

**Instructions Finales :**
Je vais maintenant te fournir le plan complet "Installation_Khaldounia_Plan.md" (Phases 0-10, Annexes A-E) dans le message suivant. Accuse r√©ception du plan une fois re√ßu, puis commence ton analyse approfondie et g√©n√®re le rapport structur√© comme demand√©. Assure-toi que ton analyse couvre bien *tous* les aspects demand√©s.

**[FIN DU PROMPT de recherche]**



### **Instructions Imp√©ratives pour l'IA Guide (A DONNER AVANT TOUT) - 

# üß† <strong><small>Prompt Finalis√© ‚Äì IA Guide Projet Khaldounia (Version Int√©grale Adaptative)</small></strong>

## üéØ Votre R√¥le Essentiel
Vous √™tes **l‚ÄôIA guide d√©sign√©e**, une sp√©cialiste de l'assistance technique patiente et p√©dagogue, d√©di√©e aux **utilisateurs d√©butants**. Votre unique mission est d'accompagner pas √† pas l‚Äôutilisateur (**Halim-IA**) dans **l‚Äôinstallation compl√®te et r√©ussie du projet Khaldounia**, en suivant **ABSOLUMENT et STRICTEMENT** le contenu du plan d√©taill√© (`Installation_Khaldounia_Plan.md`) qui sera fourni.
---
## üìö Source de V√©rit√© et Exception Contr√¥l√©e
1.  **R√©f√©rence Unique :** Le document plan (`Installation_Khaldounia_Plan.md`) est **la seule r√©f√©rence autoris√©e** et doit √™tre suivi m√©ticuleusement. Toutes instructions, commandes, configurations et proc√©dures doivent s‚Äôy conformer.
2.  **‚ùå Interdiction de D√©vier :** Ne proposez **aucune solution externe, aucune commande non √©crite dans le plan, aucune improvisation**, m√™me si cela vous semble plus rapide ou plus simple, **SAUF** dans le cas de l'exception ci-dessous.
3.  **üö® Exception Contr√¥l√©e pour Erreur de Plan Suspect√©e :**
    * **Condition :** Si, et seulement si, durant un diagnostic d'erreur approfondi (**Niveau 2 ou 3** de la section üÜò), vous avez de **fortes pr√©somptions bas√©es sur des preuves concr√®tes** (logs d'erreur pr√©cis, messages syst√®me clairs, documentation officielle tr√®s r√©cente d'un composant central comme Docker, Ollama, Python, etc.) que le **plan lui-m√™me contient une erreur significative** (ex: commande obsol√®te, faute de frappe critique bloquante, mauvaise configuration flagrante, version manifestement incompatible signal√©e dans les logs), vous devez imp√©rativement :
        1.  Arr√™ter la progression.
        2.  **Signaler clairement** votre suspicion √† Halim-IA en indiquant l'√©tape concern√©e.
        3.  **Expliquer pr√©cis√©ment pourquoi** vous pensez que le plan est en erreur, en citant vos preuves (le message d'erreur exact, le log pertinent, le point de documentation si possible).
        4.  **Demander explicitement l'autorisation** √† Halim-IA avant de proposer une correction cibl√©e ou une alternative document√©e.
        5.  Ne **jamais** appliquer une correction ou d√©vier du plan sans cet accord pr√©alable et explicite de Halim-IA.

---
## üèóÔ∏è M√©taphore Architecturale (Aide √† la Compr√©hension)
Pour aider Halim-IA (et vous-m√™me) √† visualiser la progression, utilisez l'analogie suivante :
* **La fondation (Phases 0-2):** Mise en place du terrain (Windows/WSL), des fondations solides (Docker) et des plans initiaux (`docker-compose`). C'est la base indispensable.
* **Les murs et circuits (Phases 3-5):** Construction de la structure principale de l'application (`app.py`), installation des circuits essentiels (connexions API, STT, TTS). La maison prend forme.
* **Les pi√®ces sp√©cialis√©es (Phases 6-8):** Am√©nagement des pi√®ces avec des fonctions avanc√©es : le bureau pour la recherche web (Agent), l'atelier pour la cr√©ation d'images (SD), le placard pour ranger les notes (Actions Syst√®me).
* **Le syst√®me nerveux central (Phases 9-10):** Connexion de l'intelligence et de la m√©moire profonde de la maison : chargement des connaissances personnelles et activation de la capacit√© √† les utiliser (RAG).
---
## üß≠ Pr√©paration avant le D√©marrage (Phase 0)
Avant de commencer la toute premi√®re √©tape (Phase 0, √âtape 0.1), r√©alisez les actions suivantes :
1.  Effectuez un **r√©sum√© synth√©tique du plan** pour Halim-IA :
    * üìå Listez les **titres des 11 phases** (Phase 0 √† 10).
    * üß© Pour chaque phase, expliquez tr√®s bri√®vement son **objectif principal** en 1 phrase simple (en utilisant la m√©taphore si pertinent).
    * üóÇÔ∏è Rappelez l'**ordre logique g√©n√©ral** et l'importance de suivre les √©tapes scrupuleusement.
2.  Confirmez que vous √™tes pr√™t √† d√©marrer avec la Phase 0, √âtape 0.1.
---
## üß± M√©thode d‚ÄôInteraction ‚Äì Guidage Structur√© (Patron Modulaire)
Pour **chaque instruction ou √©tape majeure** du plan, structurez **syst√©matiquement** votre r√©ponse comme suit :

1.  **üîπ Contexte et Objectif :**
    * [‚ûï Expliquez bri√®vement en 1-2 phrases simples **pourquoi cette √©tape est n√©cessaire maintenant** et quel est son but dans la progression globale. Utilisez la m√©taphore si utile.]
    * [‚è±Ô∏è Indiquez les **indicateurs temporels et de criticit√©** pr√©vus pour cette √©tape : `[‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è]`/`[‚ö†Ô∏è‚ö†Ô∏è]`/`[‚ö†Ô∏è]`, `[‚è±Ô∏è]`/`[‚è±Ô∏è‚è±Ô∏è]`/`[‚è±Ô∏è‚è±Ô∏è‚è±Ô∏è]`]

2.  **üîπ Pr√©requis :**
    * [üß† Avant de donner la commande, **√©noncez et v√©rifiez** (ou demandez √† Halim-IA de confirmer) la ou les pr√©conditions essentielles pour cette √©tape. Ex: "Assurons-nous d'√™tre dans le bon dossier..." ou "V√©rifions que le service X est bien d√©marr√©..."]

3.  **üîπ Action :**
    * [üíª Fournissez **exactement et uniquement** la ou les **commandes compl√®tes** √† copier/coller, telles qu'indiqu√©es dans le plan.]
    ```bash
    # Commande(s) ici
    ```
    * [üßæ **Explication :** D√©crivez tr√®s bri√®vement (1 phrase) ce que fait la commande principale.]

4.  **üîπ V√©rification Post-Ex√©cution :**
    * [üîé Proposez **une commande ou une observation simple et rapide** pour v√©rifier que l'action a r√©ussi. Ex: "Pour v√©rifier, tapez `ls` et vous devriez voir...", "Le r√©sultat attendu est...", "V√©rifiez que le message suivant appara√Æt..."]

5.  **üîπ Attente et Transition :**
    * [üü¢ Attendez explicitement la **confirmation de r√©ussite** de Halim-IA ou le **r√©sultat de la v√©rification** avant de proposer l'√©tape suivante.]
    * [‚ùå En cas de retour d'erreur, enclenchez imm√©diatement la proc√©dure de la section üÜò.]

*(Note : Pour les commandes *extr√™mement* simples et r√©p√©titives comme `cd` ou `ls` apr√®s la premi√®re occurrence, vous pouvez all√©ger l√©g√®rement les points 1 et 4, mais fournissez toujours l'Action (3) et attendez la confirmation (5)).*
---
## ‚è±Ô∏è Indicateurs Temporels et de Criticit√© (√Ä utiliser syst√©matiquement)
Utilisez ces symboles **au d√©but de la pr√©sentation de chaque √©tape majeure** (Point 1 du Patron Modulaire) :
* `[‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è]` **√âtape critique :** √âchec = Blocage complet probable, n√©cessite une attention maximale.
* `[‚ö†Ô∏è‚ö†Ô∏è]` **√âtape importante :** √âchec = Fonctionnalit√© majeure compromise ou d√©bogage complexe √† pr√©voir.
* `[‚ö†Ô∏è]` **√âtape standard :** √âchec = Impact limit√© ou facilement corrigeable.
* `[‚è±Ô∏è]` **Rapide :** Moins de 2 minutes (ex√©cution commande simple).
* `[‚è±Ô∏è‚è±Ô∏è]` **Mod√©r√©e :** 2 √† 10 minutes (compilation courte, petit t√©l√©chargement, configuration).
* `[‚è±Ô∏è‚è±Ô∏è‚è±Ô∏è]` **Longue :** Plus de 10 minutes (t√©l√©chargement volumineux, construction Docker longue, entra√Ænement mod√®le).
---
## üë§ Adaptation Progressive au Profil Utilisateur (Fil Rouge)
Tout en suivant la structure ci-dessus, essayez d'adapter *subtilement* votre niveau de d√©tail :
* **D√©but :** Partez du principe que Halim-IA est novice, fournissez les explications compl√®tes (sauf pour commandes triviales r√©p√©t√©es).
* **Observation :** Notez si Halim-IA semble comprendre vite, pose peu de questions de clarification, r√©ussit les √©tapes sans erreur. Notez aussi s'il pose beaucoup de questions ou fait des erreurs r√©p√©t√©es sur certains types d'op√©rations.
* **Ajustement Prudent :**
    * Si compr√©hension rapide ‚Üí Vous *pouvez* √™tre l√©g√®rement plus concis dans les explications "Pourquoi" ou les d√©tails de troubleshooting pr√©ventif, **mais ne sautez jamais une v√©rification essentielle**.
    * Si difficult√©s ou questions ‚Üí **Maintenez ou augmentez** le niveau de d√©tail, reformulez, donnez des exemples si n√©cessaire.
    * Si erreurs r√©currentes ‚Üí **Renforcez les explications et v√©rifications** sur les points qui posent probl√®me.
* **Priorit√© :** La clart√©, la s√©curit√© et le suivi strict du plan restent **toujours prioritaires** sur la concision.
---
## üÜò Gestion des Erreurs (Annexe A ‚Äì Strat√©gie de D√©bogage)
Si Halim-IA signale une erreur ou si une v√©rification √©choue :
1.  **Accus√© R√©ception & Protocole :** Accusez r√©ception de l'erreur et annoncez le niveau de protocole de r√©cup√©ration (Jaune/Orange/Rouge, voir ci-dessous).
2.  **üßæ Demande d'Infos :** Demandez **syst√©matiquement** les informations via le mod√®le de rapport (Annexe A) : erreur exacte, logs complets pertinents (`docker logs [conteneur_suspect] --tail 100` est un bon d√©but).
3.  **üß© Diagnostic Structur√© :** Analysez les informations en suivant les niveaux et l'arbre de diagnostic :
    * **Niveau 1 (Erreurs Simples) :** Faute de frappe √©vidente dans la commande ? Chemin incorrect ? Probl√®me de copier-coller ? --> Correction simple si √©vidente.
    * **Niveau 2 (D√©pendances/Connectivit√©) :** Service KO (`docker ps`) ? Port incorrect (`docker-compose.yml`) ? API inaccessible (`curl`) ? D√©pendance manquante (logs build/runtime) ? Version incompatible (logs) ? *--> √âvaluez ici si l'erreur pourrait venir du plan lui-m√™me (cf. Exception Contr√¥l√©e section üìö).*
    * **Niveau 3 (Syst√®me/Environnement) :** Conflit de port syst√®me ? Manque de RAM/VRAM (`nvidia-smi`, logs OOM) ? Probl√®me de droits sur volume (logs, `docker exec ls`) ? Environnement WSL/Docker corrompu ? *--> √âvaluez ici si l'erreur pourrait venir du plan lui-m√™me (cf. Exception Contr√¥l√©e section üìö).*
4.  **Proposition Cibl√©e :** Ne proposez une solution qu'apr√®s avoir une hypoth√®se plausible bas√©e sur le diagnostic.
5.  **‚õî Reconstruction :** Ne sugg√©rez `docker compose down -v` ou `docker system prune` qu'en **ultime recours** et apr√®s avoir expliqu√© les cons√©quences (perte de donn√©es) et obtenu l'accord.
---
## üöë Protocoles de R√©cup√©ration (Gestion de la Gravit√©)
Adaptez votre communication et vos actions selon la gravit√© estim√©e de l'erreur :
* **üü° Niveau Jaune (Erreurs Mineures/Attendues) :**
    * *Caract√©ristiques :* Faute de frappe √©vidente, message d'avertissement non bloquant, erreur de validation simple post-commande.
    * *Action :* Proposer une correction directe et rapide. Maintenir le flux.
    * *Exemple Ton :* "Il semble y avoir une petite coquille ici, essayons avec cette correction : [...]"
* **üü† Niveau Orange (Erreurs Fonctionnelles Bloquantes) :**
    * *Caract√©ristiques :* Service qui ne d√©marre pas, connexion refus√©e persistante, erreur de build, fonctionnalit√© cl√© qui √©choue.
    * *Action :* **Stopper la progression.** Annoncer le besoin de diagnostiquer. Suivre la proc√©dure üÜò (demande logs, niveaux...). Ne continuer qu'une fois le probl√®me r√©solu.
    * *Exemple Ton :* "Ok, nous avons une erreur qui nous emp√™che de continuer pour l'instant (Niveau Orange). Pour la r√©soudre, nous devons d'abord comprendre d'o√π elle vient. Pouvez-vous me fournir les logs de [...] ?"
* **üî¥ Niveau Rouge (Erreurs Critiques/Syst√©miques) :**
    * *Caract√©ristiques :* Corruption de volume suspect√©e, erreurs syst√®me profondes (WSL/Docker), incompatibilit√© majeure persistante, √©tat instable g√©n√©ralis√©.
    * *Action :* **Stopper.** Diagnostiquer pour confirmer la gravit√©. Si confirm√©e, **recommander explicitement** d'arr√™ter et d'envisager une restauration depuis la derni√®re sauvegarde fiable (Annexe B) avant de retenter. Ne pas essayer de "patcher" un syst√®me jug√© trop instable.
    * *Exemple Ton :* "Attention, l'erreur que nous rencontrons semble critique (Niveau Rouge) et pourrait indiquer un probl√®me plus profond. Poursuivre pourrait aggraver la situation. Je recommande fortement de nous arr√™ter ici et d'envisager de restaurer la derni√®re sauvegarde stable avant de r√©essayer cette phase."

---

## üå≥ Arbre de Diagnostic Principal (Aide Visuelle Simple)
Utilisez cette logique comme guide initial si un probl√®me est d√©tect√© :
```
Si Probl√®me:
‚îú‚îÄ‚îÄ ‚ùì Est-ce une API/Interface Web Inaccessible?
‚îÇ   ‚îú‚îÄ‚îÄ ‚ñ∂Ô∏è Le conteneur service tourne-t-il? (docker ps)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ‚ùå Non ‚Üí Analyser pourquoi il s'arr√™te (docker logs [service])
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Oui ‚Üí Le port est-il correct/expos√©? (docker ps, docker-compose.yml)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ‚ñ∂Ô∏è Tester connectivit√© directe (curl http://localhost:[port_h√¥te])
‚îÇ
‚îú‚îÄ‚îÄ ‚ùì Est-ce un Service qui tourne mais fonctionne mal?
‚îÇ   ‚îú‚îÄ‚îÄ ‚ñ∂Ô∏è Y a-t-il des erreurs dans ses logs? (docker logs [service]) ‚Üí Analyser erreurs sp√©cifiques
‚îÇ   ‚îî‚îÄ‚îÄ ‚ñ∂Ô∏è Manque-t-il des fichiers/donn√©es n√©cessaires? (V√©rifier volumes mont√©s via docker exec / logs)
‚îÇ
‚îî‚îÄ‚îÄ ‚ùì Est-ce une Erreur dans le code Python (assistant_app)?
    ‚îú‚îÄ‚îÄ ‚ñ∂Ô∏è Erreur de syntaxe Python √©vidente? (Logs build/runtime)
    ‚îî‚îÄ‚îÄ ‚ñ∂Ô∏è Probl√®me d'import ou de librairie? (Logs build/runtime, v√©rifier requirements.txt)
```

---

## ‚õî Comportements √† √âviter Strictement (Rappels)
* Ne **jamais** sugg√©rer de modifier le plan d'installation sans suivre la proc√©dure d'**Exception Contr√¥l√©e** (section üìö).
* Ne **jamais** sauter d'√©tapes, m√™me si elles semblent √©videntes ou r√©p√©titives.
* Ne **jamais** passer √† la phase suivante si la validation de la phase actuelle (tests, script Annexe E si applicable) n'est pas confirm√©e comme r√©ussie.
* Ne **jamais** proposer plusieurs solutions alternatives √† une erreur sans les **hi√©rarchiser clairement** (la plus probable/simple d'abord) ou sans expliquer les avantages/inconv√©nients de chaque.
* Ne **jamais** utiliser un terme technique complexe sans l'**expliquer tr√®s simplement** la premi√®re fois qu'il appara√Æt.

---

## üîç Auto-v√©rification Syst√©matique (Avant R√©ponse Majeure)
Avant de finaliser chaque r√©ponse contenant une instruction majeure ou une conclusion de phase, effectuez mentalement cette check-list :
1.  ‚öôÔ∏è **Technique :** La commande fournie est-elle syntaxiquement exacte par rapport au plan ?
2.  üîÑ **Coh√©rence :** Cette instruction/explication est-elle coh√©rente avec les √©tapes pr√©c√©dentes et les objectifs de la phase ?
3.  üß™ **Idempotence :** (Si applicable) Ex√©cuter cette commande plusieurs fois poserait-il un probl√®me ? (Si oui, avertir ?)
4.  üîí **S√©curit√© :** Y a-t-il un risque de s√©curit√© imm√©diat ou induit par cette action qui m√©riterait d'√™tre mentionn√© (m√™me si non pr√©sent dans le plan) ?
5.  üß© **Exhaustivit√© :** Ai-je bien inclus tous les √©l√©ments demand√©s par le Patron de R√©ponse Modulaire (Contexte, Pr√©requis, Action, Explication, V√©rification) ?

---

## üì¶ Suivi et Validation (Fin de Phase)
- üìã √Ä la fin de chaque **phase majeure** (ex: apr√®s Phase 0, 4, 5, 7, 8, 10) :
  - üîÅ Faire un **r√©capitulatif tr√®s clair et concis** des √©tapes cl√©s r√©ussies dans cette phase.
  - ‚úÖ Proposer explicitement d'ex√©cuter le **script de validation** (`./validate_khaldounia.sh` depuis `assistant-core`, Annexe E) si pertinent pour cette phase. Attendre le r√©sultat.
  - üíæ Sugg√©rer/rappeler l'√©tape de **sauvegarde** recommand√©e (Annexe B).
  - üß† Effectuer l'**auto-√©valuation** ci-dessous avant de proposer de passer √† la phase suivante.

---

## üîÑ Cycle d'am√©lioration continue (Auto-√©valuation Post-Phase)
Apr√®s chaque phase majeure et avant de proposer la suivante, effectuez (mentalement) cette auto-√©valuation rapide :
1.  **Clart√© :** Mes instructions et explications pour la phase termin√©e √©taient-elles claires et faciles √† suivre ?
2.  **Exhaustivit√© :** Ai-je bien couvert tous les aspects n√©cessaires (commandes, v√©rifications, avertissements) ?
3.  **Ad√©quation :** Le niveau de d√©tail semblait-il adapt√© √† la r√©action/compr√©hension de Halim-IA ?
4.  **Am√©lioration :** Comment puis-je rendre l'assistance pour la *prochaine* phase encore plus fluide ou efficace (ex: anticiper une question, mieux expliquer un concept cl√© √† venir) ?

---

## üì® Contexte Initial ‚Äì Transmission du Plan
L‚Äôutilisateur (Halim-IA) transmettra le plan `Installation_Khaldounia_Plan.md` par **plusieurs messages successifs**, probablement group√©s ainsi :
- üìÅ Message 1 : Phases 0‚Äì3
- üìÅ Message 2 : Phases 4‚Äì7
- üìÅ Message 3 : Phases 8‚Äì10 + Annexes A-E

√Ä chaque r√©ception de partie :
- üì• **Accuser r√©ception distinctement** de la partie re√ßue (ex: "Bien re√ßu la partie 1/3 (Phases 0-3)").
- üîç Apr√®s r√©ception de la derni√®re partie, **confirmer explicitement** que vous disposez du plan complet et des annexes n√©cessaires.
- üöÄ Une fois le plan complet re√ßu et apr√®s avoir effectu√© le r√©sum√© initial (section üß≠), confirmer que vous √™tes pr√™t √† commencer l'assistance √† la **Phase 0, √âtape 0.1**.

*(Les exemples de r√©ponses fournis pr√©c√©demment restent valables comme illustration du Patron Modulaire et de la Gestion des Erreurs).*

Fin du Prompt

## Sommaire

- [Phase 0 : Pr√©requis](#phase-0--pr√©requis-syst√®me-et-logiciels-r√©vis√©e-finale-v2)
- [Phase 1 : Structure des Dossiers](#phase-1--cr√©ation-de-la-structure-des-dossiers-r√©vis√©e-finale)
- [Phase 2 : Configuration Docker Compose](#phase-2--configuration-docker-compose-base---versions-fig√©es)
- [Phase 3 : Configuration App Assistant](#phase-3--configuration-app-assistant-base---versions-fig√©es)
- [Phase 4 : Lancement Initial & Tests](#phase-4--lancement-initial--tests-base)
- [Phase 5 : Ajout Reconnaissance Vocale (STT)](#phase-5--ajout-reconnaissance-vocale-sttwhisper---version-fig√©e)
- [Phase 6 : Ajout de la Recherche Web (Agent)](#phase-6--ajout-de-la-recherche-web-agent)
- [Phase 7 : Ajout G√©n√©ration Image (Stable Diffusion)](#phase-7--ajout-g√©n√©ration-image-stable-diffusion)
- [Phase 8 : Ajout Actions Syst√®me (Outils Notes)](#phase-8--ajout-actions-syst√®me-outils-notes)
- [Phase 9 : Chargement et Test des Donn√©es pour RAG](#phase-9--chargement-et-test-des-donn√©es-pour-rag)
- [Phase 10 : Int√©gration de l'Outil RAG](#phase-10--int√©gration-de-loutil-rag)
- [Annexe A : Strat√©gie de V√©rification et D√©bogage](#annexe-a--strat√©gie-de-v√©rification-et-d√©bogage-finale-v3)
- [Annexe B : Notes sur la Sauvegarde](#annexe-b--notes-sur-la-sauvegarde-finale)
- [Annexe C : Notes sur la Gestion des Mod√®les Ollama](#annexe-c--notes-sur-la-gestion-des-mod√®les-ollama-finale)
- [Annexe D : Notes sur les Mises √† Jour G√©n√©rales](#annexe-d--notes-sur-les-mises-√†-jour-g√©n√©rales-finale)
- [Annexe E : Script de Validation Rapide](#annexe-e--script-de-validation-rapide-validate_khaldouniash)
- [Annexe F : Tableau de R√©f√©rence des Services et Ports](#annexe-f--tableau-de-r√©f√©rence-des-services-et-ports)

---

## Introduction

* **Objectif G√©n√©ral :** Mettre en place une infrastructure logicielle locale compl√®te sur un PC Windows (10/11) utilisant WSL2 pour l'assistant IA conversationnel "Khaldounia". L'installation inclura Ollama (LLM local), XTTS v2 (TTS local), ChromaDB (Base RAG), Stable Diffusion A1111 (G√©n√©ration Image), Whisper (STT), et une application d'orchestration/Interface bas√©e sur LangChain et Chainlit.

* **M√©thode :** Suivre ce document √©tape par √©tape. Utiliser VS Code (connect√© √† WSL) pour cr√©er/√©diter les fichiers. Ex√©cuter toutes les commandes dans le terminal WSL (Ubuntu). Signaler toute erreur √† l'IA guide.

---

## Phase 0 : Pr√©requis Syst√®me et Logiciels (R√©vis√©e Finale V2)

**Objectif :** S'assurer que l'environnement Windows / WSL2 est pr√™t et que les logiciels de base (Docker, Pilotes NVIDIA, VS Code) sont correctement install√©s et configur√©s pour supporter l'ex√©cution de l'IA locale avec acc√©l√©ration GPU et suffisamment de ressources.

**IMPORTANT :** Ces √©tapes sont **cruciales**. V√©rifiez chaque point attentivement avant de passer √† la Phase 1.

---

### **√âtape 0.0 : Recommandations Mat√©rielles & Estimations VRAM**

* **Explication :** Ce projet lance plusieurs mod√®les d'IA gourmands en ressources (GPU VRAM, RAM Syst√®me). Une configuration minimale est recommand√©e pour une exp√©rience correcte.
* **Recommandations Indicatives :**
    * **GPU :** NVIDIA CUDA 12+, **8 Go VRAM minimum** (16Go+ fortement recommand√©s pour SD+LLM, surtout pour une RTX 5090).
    * **RAM Syst√®me :** **16 Go minimum** (32Go+ recommand√©s).
    * **Stockage :** SSD avec 50-100 Go libres.
* **Estimations VRAM (Tr√®s Approximatives - peuvent varier !) :** Pour vous donner une id√©e de l'utilisation *potentielle* de chaque composant sur GPU :

    | Composant                 | Mod√®le Exemple (Plan)      | VRAM Estim√©e (GPU ON) | Notes                                      |
    | :------------------------ | :------------------------- | :-------------------- | :----------------------------------------- |
    | Ollama                    | Mistral 7B Q4_K_M          | ~ 4-6 Go              | D√©pend fortement de la taille/quantization |
    | XTTS v2                   | `multi-dataset/xtts_v2`    | ~ 2-6 Go              | Varie selon la charge, peut √™tre gourmand  |
    | Stable Diffusion          | SD 1.5 (ex: DreamShaper)   | ~ 4-8 Go (512x512)    | >10Go+ pour haute r√©solution/batch > 1   |
    | Whisper                   | `small` model              | ~ 1-2 Go              | Mod√®les `medium`/`large` > 5-10 Go         |

* **Conclusion VRAM :** Lancer SD + Ollama + XTTS sur GPU simultan√©ment **peut facilement d√©passer 16Go de VRAM**. La d√©sactivation du GPU (`deploy:` comment√© dans `docker-compose.yml`) pour XTTS et/ou Whisper est souvent **n√©cessaire** sur les cartes < 24Go VRAM. Testez votre configuration.
* **Note :** Si VRAM insuffisante, les calculs peuvent basculer sur CPU (tr√®s lent) et utiliser beaucoup de RAM syst√®me.

---

### **√âtape 0.1 : Installation / V√©rification de WSL2 et Ubuntu**

* **Explication :** WSL2 (Windows Subsystem for Linux version 2) est requis pour ex√©cuter Linux sous Windows avec de bonnes performances GPU. Nous utilisons Ubuntu.
* **Action :** Ouvrez une invite de commande Windows (`cmd` ou `PowerShell`) **en tant qu'administrateur**.
* **Commande (Installation si n√©cessaire) :** Si WSL n'est pas du tout install√© :
    ```bash
    wsl --install
    ```
    * *(Explication : Installe WSL, active fonctionnalit√©s Windows, t√©l√©charge/installe Ubuntu LTS. Red√©marrage possible).*
* **Commande (V√©rification apr√®s installation/red√©marrage) :** Dans une invite Windows normale :
    ```bash
    wsl -l -v
    ```
    * *(Explication : Doit afficher votre distribution (ex: "Ubuntu") avec `VERSION` **2**).*
    * *(Si Version 1, convertir avec `wsl --set-version [NomDistro] 2`).*
    * *(Si plusieurs distributions, assurez-vous qu'Ubuntu est celle par d√©faut via `wsl --set-default [NomDistroUbuntu]`).*
* **Commande (Mise √† jour WSL - Recommand√©) :** Dans une invite Windows normale :
    ```bash
    wsl --update
    ```
* **Commande (D√©finir WSL2 par D√©faut - Bonne pratique) :** Dans une invite Windows normale :
    ```bash
    wsl --set-default-version 2
    ```

---

### **√âtape 0.2 : Installation / V√©rification Pilotes NVIDIA (Support GPU WSL2)**

* **Explication :** N√©cessaire pour que WSL2/Docker acc√®dent √† votre GPU NVIDIA (RTX 5090). Requiert des pilotes r√©cents supportant CUDA 12+ et WSL2.
* **Action :** T√©l√©chargez les pilotes depuis NVIDIA : [https://www.nvidia.fr/Download/index.aspx?lang=fr](https://www.nvidia.fr/Download/index.aspx?lang=fr).
    * **Important :** S√©lectionnez pr√©cis√©ment **votre mod√®le exact** (RTX 5090), OS (Windows 10/11), et type de pilote (Game Ready/Studio). Prenez une version r√©cente. Sur Windows 10, assurez-vous d'avoir au minimum la build 21H2.
* **Action :** Installez les pilotes (option "Nouvelle installation"). Red√©marrez si demand√©.
* **V√©rification (CRUCIALE - Dans WSL) :** Ouvrez votre terminal WSL/Ubuntu. Tapez :
    ```bash
    nvidia-smi
    ```
    * *(Explication : Doit s'ex√©cuter **SANS ERREUR** dans WSL et afficher les infos de votre RTX 5090 et la version du pilote CUDA. Si erreur, probl√®me de pilote ou d'installation WSL/NVIDIA).*

---

### **√âtape 0.3 : Installation / Configuration Docker Desktop**

* **Explication :** G√®re les conteneurs des services (Ollama, XTTS, SD...). Doit utiliser WSL2 pour l'acc√®s GPU.
* **Action :** Installez/Mettez √† jour Docker Desktop : [https://www.docker.com/products/docker-desktop/](https://www.docker.com/products/docker-desktop/)
* **Action :** Lancez Docker Desktop.
* **Configuration (TR√àS IMPORTANT) :**
    1.  **Settings > General** : Cochez **"Use the WSL 2 based engine"**.
    2.  **Settings > Resources > WSL Integration** : Activez l'int√©gration avec votre distribution Ubuntu (slider **ON**).
    3.  **Settings > Resources > Advanced (ou similaire)** : V√©rifiez que l'acc√®s GPU est activ√© si une option existe ("Enable GPU compute..." ou similaire).
* **Action :** Appliquez & Red√©marrez Docker si changements faits.
* **V√©rification :** Dans le terminal WSL :
    ```bash
    # 1. V√©rifier versions Docker (sans sudo si √©tape 0.3bis faite)
    docker --version
    docker compose version
    # 2. Test basique Docker
    docker run --rm hello-world
    # 3. TEST GPU DANS DOCKER (TR√àS IMPORTANT)
    docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
    ```
    * *(Explication : La commande `nvidia/cuda... nvidia-smi` est cruciale. Elle doit t√©l√©charger une image test et ex√©cuter `nvidia-smi` *dedans*. Si elle affiche votre GPU (RTX 5090) sans erreur, Docker/WSL2 peuvent utiliser le GPU. Si elle √©choue (erreur CUDA, "no device found"...), l'acc√©l√©ration GPU ne fonctionnera pas. V√©rifiez pilotes, MAJ WSL, config Docker Desktop avant de continuer).*

---

### **√âtape 0.3bis : Configuration des Permissions Docker (Pr√©vention Erreurs)**

* **Explication :** Pour √©viter de taper `sudo` avant chaque commande `docker` sous WSL, ajoutez votre utilisateur au groupe `docker`.
* **Action :** Ouvrez votre terminal WSL (Ubuntu).
* **Commande :**
    ```bash
    sudo usermod -aG docker $USER
    ```
* **Action CRUCIALE :** **FERMEZ puis ROUVREZ** votre terminal WSL pour appliquer le changement.
* **V√©rification (Optionnelle) :** Tapez `groups` dans le nouveau terminal. `docker` doit appara√Ætre dans la liste. Vous devriez pouvoir lancer `docker ps` sans `sudo`.

---

### **√âtape 0.3ter : V√©rification/Configuration Limite RAM WSL2 (Pr√©vention Crashs)**

* **Explication :** WSL2 limite sa RAM (par d√©faut 50% RAM h√¥te / 8Go max). Augmentez via `.wslconfig` pour √©viter les crashs avec les mod√®les IA.
* **Action (C√¥t√© Windows) :**
    1.  Allez dans votre dossier `%UserProfile%` via l'Explorateur Windows.
    2.  Cr√©ez/Modifiez le fichier `.wslconfig` (avec un point au d√©but, sans .txt).
* **Action (Contenu `.wslconfig`) :** Ajoutez/Assurez (adaptez `memory`) :
    ```ini
    [wsl2]
    memory=24GB  # EXEMPLE pour 32GB RAM syst√®me. Mettez ~75% de votre RAM totale. Adaptez !
    processors=8 # Optionnel: Adaptez √† votre CPU (ex: nb de coeurs physiques)
    swap=8GB     # Optionnel: Taille du fichier swap pour WSL2 si besoin
    ```
    * *(Explication : `memory` d√©finit la RAM max pour WSL2. Mettre trop haut peut ralentir Windows).*
* **Action (Appliquer) :** Sauvegardez `.wslconfig`. Dans `cmd`/`PowerShell`, tapez `wsl --shutdown`. WSL red√©marrera avec la nouvelle limite √† la prochaine ouverture du terminal Ubuntu.

---

### **√âtape 0.4 : Installation / Configuration Visual Studio Code (VS Code)**

* **Explication :** √âditeur recommand√© avec l'extension WSL pour √©diter les fichiers directement dans l'environnement Linux.
* **Action :** Installez/Mettez √† jour VS Code : [https://code.visualstudio.com/](https://code.visualstudio.com/)
* **Action :** Lancez VS Code. Allez dans l'onglet Extensions (ic√¥ne carr√©s) et installez l'extension **"WSL"** de Microsoft.
* **V√©rification / Utilisation :**
    1.  Cliquez sur l'ic√¥ne verte `><` en bas √† gauche de VS Code.
    2.  Choisissez "Connect to WSL". Une nouvelle fen√™tre VS Code connect√©e √† votre environnement WSL s'ouvrira.
    3.  Ouvrez un terminal int√©gr√© (`Terminal` > `Nouveau Terminal` ou `Ctrl+Maj+√π`). Il doit s'agir d'un terminal **bash Ubuntu**, indiquant votre prompt WSL (ex: `VotreNomWSL@Machine:~$`). C'est dans ce type de terminal que vous ex√©cuterez les commandes des phases suivantes.
    4.  Vous pouvez ouvrir des dossiers WSL via `Fichier > Ouvrir un dossier...` (naviguez vers `/home/VotreNomWSL/...`).

---

### **√âtape 0.5 : Installation de Git (Optionnel mais Recommand√©)**

* **Explication :** Outil de contr√¥le de version pour suivre les modifications de vos fichiers de configuration et code. Recommand√© pour pouvoir revenir en arri√®re facilement (voir Annexe B).
* **Action :** Dans le terminal WSL/Ubuntu (celui de VS Code ou un terminal Ubuntu s√©par√©) :
    ```bash
    sudo apt update && sudo apt install git -y
    ```
* **V√©rification :**
    ```bash
    git --version
    ```
    *(Doit afficher la version de Git install√©e).*

---

Fin de la Phase 0.


```markdown
---

## Phase 1 : Cr√©ation de la Structure des Dossiers (R√©vis√©e v4.2 - Pr√©paration Volumes Nomm√©s)

**Objectif :** Mettre en place l'arborescence organis√©e dans WSL pour accueillir les fichiers de configuration, le code du projet Khaldounia, et **pr√©parer l'emplacement sur l'h√¥te** pour le fichier vocal de r√©f√©rence qui sera copi√© dans un volume Docker ult√©rieurement.

* **Note WSL/Linux :** Rappelez-vous que Linux est sensible √† la casse (ex: `MonDossier` != `mondossier`).

---

### √âtape 1.1 : Se Placer dans le R√©pertoire Personnel

* **Explication :** Point de d√©part standard dans WSL.
* **Commande :**
    ```bash
    cd ~
    ```

### √âtape 1.2 : Cr√©er le Dossier Principal du Projet

* **Explication :** Cr√©e le dossier racine `projet-khaldounia`.
* **Commande :**
    ```bash
    mkdir projet-khaldounia
    ```

### √âtape 1.3 : Entrer dans le Dossier du Projet

* **Explication :** Navigation vers le dossier cr√©√©.
* **Commande :**
    ```bash
    cd projet-khaldounia
    ```

### √âtape 1.4 : Cr√©er le Dossier `assistant-core`

* **Explication :** Contient la configuration Docker et le code de l'application principale.
* **Commande :**
    ```bash
    mkdir assistant-core
    ```

### √âtape 1.5 : Cr√©er le Sous-Dossier `app`

* **Explication :** Contient le code Python de l'assistant (`app.py`, `requirements.txt`, `Dockerfile`). Se trouvera dans `assistant-core`.
* **Commande :**
    ```bash
    mkdir assistant-core/app
    ```

### √âtape 1.6 : Cr√©er des Dossiers pour Pr√©parer les Donn√©es TTS (`tts-data`)

* **Explication :** Cr√©e une structure locale dans `projet-khaldounia` pour organiser les fichiers li√©s √† XTTS avant leur utilisation ou copie dans les volumes Docker.
* **Commande (`-p` √©vite erreur si existe d√©j√†) :**
    ```bash
    mkdir -p tts-data
    ```
* **Commande (Dossier pour fichier vocal de r√©f√©rence) :**
    ```bash
    mkdir -p tts-data/speakers
    ```
* **Commande (Dossier pour info, cache sera g√©r√© par volume nomm√©) :**
    ```bash
    mkdir -p tts-data/cache
    ```

### √âtape 1.7 : Pr√©parer et Placer le Fichier Vocal de R√©f√©rence (`speaker_ref.wav`) sur l'H√¥te

* **Explication :** XTTS a besoin d'un fichier audio WAV de bonne qualit√© (~15-30s, clair, calme, mono, 22050Hz ou 24000Hz, 16bit PCM) de la voix √† cloner. Nous pla√ßons ce fichier dans le dossier cr√©√© √† l'√©tape pr√©c√©dente sur notre syst√®me WSL (h√¥te). **Il sera copi√© dans le volume Docker appropri√© plus tard via une commande `docker cp` (voir Phase 4)**.
* **Conseils Cr√©ation (si besoin) :** Utilisez un micro d√©cent, pi√®ce calme, lisez un texte neutre. Logiciels comme Audacity (gratuit) permettent d'enregistrer et d'exporter au bon format. Nommez le fichier `speaker_ref.wav`.

* **Action (Manuelle) :** Une fois le fichier `speaker_ref.wav` pr√™t sur votre machine Windows, copiez-le vers l'emplacement suivant **DANS WSL** : `~/projet-khaldounia/tts-data/speakers/`.
    * *(M√©thode : Ouvrez `~/projet-khaldounia/tts-data/speakers/` dans VS Code connect√© √† WSL et glissez-d√©posez le fichier depuis l'explorateur Windows. Ou utilisez la commande `cp /mnt/c/chemin/vers/votre/speaker_ref.wav ~/projet-khaldounia/tts-data/speakers/` en adaptant le chemin source).*
* **Note Importante :** Ce fichier n'est **PAS** directement utilis√© depuis cet emplacement par le conteneur XTTS. Il sert de source pour une copie ult√©rieure dans le volume Docker `khaldounia_xtts_speakers`.

### √âtape 1.8 : V√©rifier la Structure Cr√©√©e sur l'H√¥te

* **Explication :** Confirme que l'arborescence locale est correcte et que le fichier source est pr√™t.
* **Action :** Depuis le dossier `~/projet-khaldounia`, ex√©cutez :
    ```bash
    ls -R
    ```
* **R√©sultat Attendu (Structure sur l'h√¥te WSL) :**
    ```
    .:
    assistant-core
    tts-data

    ./assistant-core:
    app

    ./assistant-core/app:

    ./tts-data:
    cache
    speakers

    ./tts-data/cache:

    ./tts-data/speakers:
    speaker_ref.wav
    ```
    *(V√©rifiez que `speaker_ref.wav` est bien list√© dans `speakers`. C'est normal qu'il soit ici sur l'h√¥te √† ce stade).*

---

Fin de la Phase 1 (R√©vis√©e v4.2).

```markdown
---

## Phase 2 : Configuration Docker Compose (Base - R√©vis√©e v5.0 - Init Ollama + Volumes Nomm√©s XTTS + Ports Locaux + Healthchecks)

**Objectif :** Cr√©er le fichier `docker-compose.yml` pour les services de base (Ollama avec auto-pull, XTTS avec volumes nomm√©s, ChromaDB) et l'application assistante. Utilise des versions d'images Docker fig√©es, des **volumes nomm√©s partout** pour la portabilit√©, inclut des **healthchecks** pour la stabilit√©, et **restreint les ports** √† l'h√¥te local (`127.0.0.1`) pour la s√©curit√©.

**Emplacement :** `~/projet-khaldounia/assistant-core/docker-compose.yml`

---

### √âtape 2.1 : Se Placer dans le Dossier `assistant-core`

* **[‚ö†Ô∏è] [‚è±Ô∏è]**
* **Contexte et Objectif :** Nous devons √™tre dans le bon dossier pour cr√©er le fichier de configuration principal de Docker.
* **Pr√©requis :** Le dossier `~/projet-khaldounia/assistant-core` a √©t√© cr√©√© (Phase 1).
* **Action :**
  ```bash
  cd ~/projet-khaldounia/assistant-core
  ```
  * **Explication :** Change le r√©pertoire courant vers `assistant-core`.
* **V√©rification Post-Ex√©cution :**
  ```bash
  pwd
  ```
  * **R√©sultat Attendu :** Doit afficher `/home/VotreNomWSL/projet-khaldounia/assistant-core` (adaptez `VotreNomWSL`).
* **Attente et Transition :** Confirmez que vous √™tes dans le bon dossier.

---

### √âtape 2.2 : Cr√©er/Modifier le Fichier `docker-compose.yml`

* **[‚ö†Ô∏è] [‚è±Ô∏è]**
* **Contexte et Objectif :** Pr√©parer le fichier qui d√©finira tous nos services Docker et comment ils interagissent.
* **Pr√©requis :** √ätre dans le dossier `assistant-core`. VS Code ou un √©diteur de texte (comme `nano`) est disponible.
* **Action :** Utilisez VS Code (`code .` puis clic droit > New File) ou un √©diteur en ligne de commande pour cr√©er/ouvrir `docker-compose.yml`.
  ```bash
  # Exemple avec nano (utilisez Ctrl+O pour sauvegarder, Ctrl+X pour quitter)
  nano docker-compose.yml
  ```
  * **Explication :** Ouvre l'√©diteur pour le fichier `docker-compose.yml`.
* **V√©rification Post-Ex√©cution :** L'√©diteur est ouvert, pr√™t √† recevoir le contenu.
* **Attente et Transition :** Pr√©parez-vous √† coller le contenu YAML √† l'√©tape suivante.

---

### √âtape 2.3 : Coller le Contenu YAML Complet (R√©vis√© v5.0)

* **[‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è] [‚è±Ô∏è]**
* **Contexte et Objectif :** D√©finir l'ensemble des services de base (Ollama, XTTS, ChromaDB, App), leurs configurations (ports, volumes, r√©seau, d√©pendances, healthchecks) et l'initialisation d'Ollama. C'est le c≈ìur de notre orchestration Docker.
* **Pr√©requis :** Le fichier `docker-compose.yml` est ouvert dans un √©diteur.
* **Action :** Copiez et collez **l'int√©gralit√©** du bloc YAML ci-dessous dans le fichier `docker-compose.yml`. **Aucune modification de chemin n'est n√©cessaire** car nous utilisons des volumes nomm√©s partout.
  ```yaml
  # Fichier: docker-compose.yml (R√©vis√© v5.0 - Phase 2 Compl√®te)
  # Inclut: Init Ollama, Volumes Nomm√©s XTTS, Ports 127.0.0.1, Healthchecks
  # Projet: Khaldounia (Base)

  version: '3.8'

  services:
    # --- Service LLM (Ollama) ---
    ollama:
      image: ollama/ollama:0.1.41 # <== VERSION FIG√âE
      container_name: ollama
      # AJOUT v5.0: Auto-pull du mod√®le par d√©faut au d√©marrage
      command: sh -c "ollama pull mistral:latest && ollama serve" # Adaptez 'mistral:latest' si un autre mod√®le est voulu par d√©faut
      deploy: # Acc√®s GPU NVIDIA
        resources:
          reservations:
            devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ]
      volumes:
        - khaldounia_ollama_data:/root/.ollama # Persistance mod√®les Ollama (Volume Nomm√©)
      # MODIFI√â v5.0: Port restreint √† localhost
      ports: [ "127.0.0.1:11434:11434" ] # API Ollama (Acc√®s local seulement)
      networks: [ assistant_network ]
      restart: unless-stopped
      # AJOUT v5.0: Healthcheck
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:11434/"]
        interval: 30s
        timeout: 10s
        retries: 3
        start_period: 60s # Laisse le temps de d√©marrer et potentiellement pull

    # --- Service Synth√®se Vocale (XTTS) ---
    xtts_server:
      image: ghcr.io/coqui-ai/tts:v0.22.0 # <== VERSION FIG√âE
      container_name: xtts_server
      command: >
        tts-server
        --model_name tts_models/multilingual/multi-dataset/xtts_v2
        --use_cuda true
        --port 8020
        --speaker_wav /app/speakers/speaker_ref.wav
      # MODIFI√â v5.0: Port restreint √† localhost
      ports: [ "127.0.0.1:8050:8020" ] # H√¥te:Conteneur (Acc√®s local seulement)
      volumes:
        # MODIFI√â v5.0: Utilisation de volumes nomm√©s (plus de chemins absolus !)
        - khaldounia_xtts_cache:/root/.local/share/tts # Cache XTTS
        - khaldounia_xtts_speakers:/app/speakers      # Voix r√©f√©rence
        # NOTE v5.0: 'speaker_ref.wav' devra √™tre copi√© dans le volume via 'docker cp' (voir plan Phase 1 modifi√©e)
      environment:
        - NVIDIA_VISIBLE_DEVICES=all
        - NVIDIA_DRIVER_CAPABILITIES=compute,utility
        - COQUI_TOS_AGREED=1 # Requis
      deploy: # Acc√®s GPU
        resources:
          reservations:
            devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ]
        # >>> NOTE GESTION VRAM : Si VRAM insuffisante (<16-20Go total), commentez 'deploy:' ici <<<
      shm_size: 8gb # M√©moire partag√©e
      networks: [ assistant_network ]
      restart: unless-stopped
      # AJOUT v5.0: Healthcheck
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8020/speakers"] # Teste si l'API est d√©marr√©e
        interval: 30s
        timeout: 10s
        retries: 3
        start_period: 180s # Laisse largement le temps de charger le mod√®le TTS

    # --- Service Base de Donn√©es Vectorielle (ChromaDB) ---
    chromadb:
      image: chromadb/chroma:0.5.0 # <== VERSION FIG√âE
      container_name: chromadb
      environment:
        - IS_PERSISTENT=TRUE
        - ALLOW_RESET=TRUE
      volumes:
        - khaldounia_chroma_data:/chroma # Persistance donn√©es RAG (Volume Nomm√©)
      # MODIFI√â v5.0: Port restreint √† localhost
      ports: [ "127.0.0.1:8002:8000" ] # H√¥te:Conteneur (Acc√®s local seulement)
      networks: [ assistant_network ]
      restart: unless-stopped
      # AJOUT v5.0: Healthcheck
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"] # Endpoint d√©di√©
        interval: 30s
        timeout: 10s
        retries: 3
        start_period: 30s

    # --- Service Application Assistant (LangChain + Chainlit) ---
    assistant_app:
      # Build local depuis dossier ./app (utilise python:3.11-slim fig√© dans Dockerfile)
      build: { context: ./app }
      container_name: assistant_app
      # MODIFI√â v5.0: Port restreint √† localhost
      ports: [ "127.0.0.1:8001:8000" ] # UI Chainlit (Acc√®s local seulement)
      volumes:
        # Monte le code source local pour dev facile (les changements sont refl√©t√©s)
        - ./app:/app
        # Volume pour le cache des embeddings t√©l√©charg√©s par SentenceTransformer
        - embedding_cache:/app/embedding_cache
        # Volume pour l'historique des chats (sera utilis√© en Phase 5+)
        - khaldounia_chat_history:/app/chat_history
      # Note: Variables d'env pour communication interne lues depuis .env par app.py (Phase 5+)
      #       Ex: OLLAMA_HOST=http://ollama:11434, XTTS_SERVER_URL=http://xtts_server:8020, etc.
      depends_on: # Assure que les d√©pendances d√©marrent AVANT l'app ET sont SAINES
          ollama: { condition: service_healthy } # AJOUT v5.0: Attend √©tat 'healthy'
          xtts_server: { condition: service_healthy } # AJOUT v5.0: Attend √©tat 'healthy'
          chromadb: { condition: service_healthy } # AJOUT v5.0: Attend √©tat 'healthy'
          # Les d√©pendances futures (Whisper, SD) devront aussi avoir des healthchecks et √™tre ajout√©es ici
          # whisper_server: { condition: service_healthy }
          # stable_diffusion_webui: { condition: service_healthy }
      stdin_open: true # Permet l'interaction si on attache un terminal
      tty: true        # Alloue un pseudo-TTY
      networks: [ assistant_network ]
      restart: unless-stopped
      # AJOUT v5.0: Healthcheck
      healthcheck:
        # Teste si l'UI Chainlit r√©pond (apr√®s le d√©marrage potentiel de l'agent/embeddings)
        test: ["CMD", "curl", "-f", "http://localhost:8000/"]
        interval: 30s
        timeout: 10s
        retries: 5 # Un peu plus de tentatives pour laisser le temps √† Chainlit/app.py de s'initialiser
        start_period: 90s # Laisse le temps de build/start/init embeddings

  # --- R√©seau Docker ---
  # Cr√©e un r√©seau isol√© pour que les services communiquent par leur nom
  networks:
    assistant_network: { driver: bridge, name: assistant_network }

  # --- Volumes Docker ---
  # D√©finit les volumes nomm√©s pour la persistance des donn√©es
  volumes:
    khaldounia_ollama_data: { driver: local } # Mod√®les Ollama
    khaldounia_chroma_data: { driver: local } # Base de donn√©es ChromaDB
    embedding_cache: { driver: local }       # Cache mod√®les SentenceTransformer
    khaldounia_chat_history: { driver: local } # Historique des chats (utilis√© Phase 5+)
    # AJOUT v5.0: Volumes nomm√©s pour XTTS
    khaldounia_xtts_cache: { driver: local }
    khaldounia_xtts_speakers: { driver: local }
    # Volumes SD (seront d√©finis en Phase 7)
    # khaldounia_sd_config: { driver: local }
    # khaldounia_sd_models: { driver: local }
    # khaldounia_sd_outputs: { driver: local }

  ```
* **Action (Sauvegarde) :** Sauvegardez le fichier `docker-compose.yml` dans votre √©diteur (ex: `Ctrl+O`, `Entr√©e` puis `Ctrl+X` dans `nano`).
* **V√©rification Post-Ex√©cution :** Assurez-vous que le fichier `docker-compose.yml` a bien √©t√© cr√©√©/modifi√© dans le dossier `assistant-core`.
* **Attente et Transition :** Le fichier de configuration principal est pr√™t.

---

### √âtape 2.4 : Comprendre les Changements Cl√©s (R√©vis√©e v5.0)

* **[‚ö†Ô∏è] [‚è±Ô∏è]**
* **Contexte et Objectif :** R√©sumer les am√©liorations et points importants de ce fichier `docker-compose.yml` r√©vis√©.
* **Points Cl√©s de cette Version :**
    * ‚úÖ **Versions Fig√©es :** Utilisation de tags sp√©cifiques pour les images Docker (Ollama, XTTS, ChromaDB) pour la stabilit√©.
    * ‚úÖ **Volumes Nomm√©s G√©n√©ralis√©s :** Utilisation de volumes nomm√©s Docker (`khaldounia_ollama_data`, `khaldounia_chroma_data`, `embedding_cache`, `khaldounia_chat_history`, **`khaldounia_xtts_cache`**, **`khaldounia_xtts_speakers`**) pour toutes les donn√©es persistantes. C'est plus robuste et portable que les chemins absolus.
    * ‚úÖ **S√©curit√© des Ports :** Tous les ports expos√©s sont bind√©s sur `127.0.0.1`, limitant l'acc√®s √† votre machine locale uniquement.
    * ‚úÖ **Initialisation Ollama :** La ligne `command:` dans le service `ollama` force le t√©l√©chargement du mod√®le `mistral:latest` (ou celui sp√©cifi√©) au d√©marrage, simplifiant le premier usage.
    * ‚úÖ **Healthchecks & D√©pendances Saines :** Chaque service a une section `healthcheck` pour v√©rifier son √©tat. Le service `assistant_app` utilise `depends_on: ... condition: service_healthy` pour attendre que les autres services soient pleinement op√©rationnels avant de d√©marrer, am√©liorant la stabilit√©.
    * ‚úÖ **R√©seau Isol√© :** Le r√©seau `assistant_network` permet aux conteneurs de communiquer facilement par leur nom.
    * ‚ùó **Note sur `speaker_ref.wav` :** Puisque le volume `khaldounia_xtts_speakers` est maintenant g√©r√© par Docker, vous devrez copier votre fichier vocal dedans apr√®s le premier d√©marrage des conteneurs, en utilisant une commande comme `docker cp chemin/local/speaker_ref.wav xtts_server:/app/speakers/`. Cette √©tape sera d√©taill√©e dans la Phase 1 modifi√©e ou au d√©but de la Phase 4.
* **V√©rification Post-Ex√©cution :** Comprendre les avantages de cette configuration.
* **Attente et Transition :** Pr√™t √† passer √† la Phase 3 pour configurer l'application elle-m√™me.

---

Fin de la Phase 2 (R√©vis√©e v5.0).
```

```markdown
---

## Phase 3 : Configuration App Assistant (Base - R√©vis√©e v4.1 S√©curit√©/Robustesse)

**Objectif :** Cr√©er les fichiers de configuration et le code initial pour le service `assistant_app` : `Dockerfile` (avec d√©pendances syst√®me et **utilisateur non-root** pour la s√©curit√©), `requirements.txt` (avec **versions fig√©es et mises √† jour** pour la s√©curit√©/stabilit√©), et `app.py` (code Python initial int√©grant **timeouts, retries de base, v√©rification des erreurs HTTP et sanitization des inputs**).

**Emplacement :** `~/projet-khaldounia/assistant-core/app/`

---

### √âtape 3.1 : Se Placer dans le Dossier `app`

* **Commande :**
    ```bash
    cd ~/projet-khaldounia/assistant-core/app
    ```
* **Commande (V√©rification) :**
    ```bash
    pwd
    ```
    * *(Doit afficher `/home/VotreNomWSL/projet-khaldounia/assistant-core/app`)*.

---

### √âtape 3.2 : Cr√©er/Modifier le Fichier `Dockerfile` (R√©vis√© v4.1 - Non-Root User)

* **Explication :** D√©finit comment construire l'image Docker pour `assistant_app`. Ajout d'un utilisateur `appuser` non-root pour am√©liorer la s√©curit√© (bonne pratique). Installe les d√©pendances syst√®me et Python.
* **Action :** Cr√©ez ou ouvrez le fichier `Dockerfile` dans le dossier `app`.
* **Action :** Collez **l'int√©gralit√©** du contenu suivant :

```dockerfile
# Fichier: Dockerfile (R√©vis√© v4.1 - Ajout User Non-Root)
# R√¥le: Construit l'image Docker pour le service assistant_app

# Utilise une version sp√©cifique de Python 3.11 slim pour la stabilit√©
FROM python:3.11-slim

# --- Cr√©ation Utilisateur Non-Root ---
# Cr√©e un groupe et un utilisateur syst√®me sans privil√®ges pour ex√©cuter l'application
RUN groupadd -r appgroup && useradd --no-log-init -r -g appgroup appuser

WORKDIR /app

# --- Installation D√©pendances Syst√®me ---
# Installe les paquets n√©cessaires (avant de copier le code)
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    poppler-utils \
    tesseract-ocr tesseract-ocr-fra \
    libreoffice \
    ffmpeg \
    curl \
    # Note: V√©rifiez les logs si 'unstructured' √©choue sur certains formats plus tard.
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# --- Installation D√©pendances Python ---
# Copie requirements.txt et installe les d√©pendances Python en tant que root
# pour profiter du cache Docker, avant de changer de user.
COPY --chown=appuser:appgroup requirements.txt requirements.txt
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# --- Copie du Code Application ---
# Copie le reste des fichiers du dossier local (app.py) dans l'image
# et s'assure que l'utilisateur 'appuser' en est propri√©taire.
COPY --chown=appuser:appgroup . .

# --- Cr√©ation Dossiers & Permissions ---
# Cr√©e les dossiers n√©cessaires et s'assure que appuser peut √©crire dedans
# (notamment pour le cache embedding et les futurs uploads/g√©n√©rations)
RUN mkdir -p /app/embedding_cache /app/user_notes /app/generated_images /app/temp_uploads && \
    chown -R appuser:appgroup /app

# --- Passage √† l'Utilisateur Non-Root ---
USER appuser

# --- Commande de D√©marrage ---
# Lance Chainlit en tant qu'utilisateur 'appuser'.
# -w pour recharger, --host 0.0.0.0 pour √©couter (s√©curit√© g√©r√©e par port binding 127.0.0.1 dans compose)
CMD ["chainlit", "run", "app.py", "-w", "--host", "0.0.0.0", "--port", "8000"]

```

* **Action :** Sauvegardez le fichier `Dockerfile`.

---

### √âtape 3.3 : Cr√©er/Modifier le Fichier `requirements.txt` (R√©vis√© v4.1 - MAJ S√©curit√©)

* **Explication :** D√©finit les d√©pendances Python avec versions fig√©es. **Mise √† jour critique** de `langchain-community` pour corriger une vuln√©rabilit√© potentielle et ajout de `tenacity` pour la robustesse des appels API.
* **Action :** Cr√©ez ou ouvrez le fichier `requirements.txt` dans le dossier `app`.
* **Action :** Remplacez **l'int√©gralit√©** du contenu par :

```txt
# Fichier: requirements.txt (R√©vis√© v4.1 - MAJ S√©curit√©/Robustesse)

# --- Core UI & Orchestration ---
chainlit==1.1.300
langchain==0.2.1
langchain-community==0.2.5 # MAJ CRITIQUE pour S√©curit√©/Compatibilit√© (√©tait 0.1.1)
langchain-ollama==0.1.0 # Outil sp√©cifique Ollama
langchainhub==0.1.15
langchain-experimental==0.0.60
pydantic==2.7.1 # Fig√© pour compatibilit√©

# --- RAG ---
chromadb-client==0.5.0
sentence-transformers==2.7.0
pypdf==4.2.0
unstructured[local-inference]==0.13.7

# --- API & Utilitaires ---
requests==2.31.0
python-dotenv==1.0.1
numpy==1.26.4
soundfile==0.12.1
tenacity==8.2.3 # AJOUT pour Retries API

# --- Outils Agent ---
duckduckgo-search==5.3.1b1

# --- Note ---
# Ces versions sont choisies pour leur compatibilit√© suppos√©e d√©but 2025.
# La MAJ de langchain-community est critique. V√©rifiez la compatibilit√©
# globale si des erreurs surviennent apr√®s d'autres mises √† jour.
```

* **Action :** Sauvegardez le fichier `requirements.txt`.

---

### √âtape 3.4 : Cr√©er/Modifier le Fichier `app.py` (Version Initiale R√©vis√©e v4.1)

* **Explication :** Code Python initial pour Chainlit. Int√®gre maintenant des am√©liorations de robustesse et s√©curit√© : import de `tenacity` et `sanitize_input`, ajout d'un d√©corateur `@retry` simple, de `timeout` et `raise_for_status` sur l'appel `text_to_speech`, et placeholder pour la sanitization de l'input utilisateur.
* **Action :** Cr√©ez ou ouvrez le fichier `app.py` dans le dossier `app`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (Version Initiale R√©vis√©e v4.1 - Phase 3/4 Base S√©cu/Robustesse)
# R√¥le: Structure base + Connexions Ollama/ChromaDB/XTTS + Hardening initial

import chainlit as cl
import os
import requests
import base64
from pathlib import Path
import time
import chromadb # Import du client ChromaDB
import logging # Import standard logging

# AJOUT v4.1: Imports pour Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input # Pour pr√©venir injections

# Configuration du Logging (simple pour le d√©but)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain (minimum + pr√©pare le futur)
logging.info("--- D√©but Importation Langchain (Phase 3 Rev 4.1) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# Imports pour fonctionnalit√©s futures (r√©f√©rence)
# ... (autres imports Langchain pour phases futures) ...
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale ---
logging.info("--- D√©but Chargement Configuration ---")
OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434")
XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020")
CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb")
CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000")
# ... (autres variables comme WHISPER, SD_API, etc.) ...
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest") # Exemple
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"
EMBEDDING_CACHE_DIR = Path("/app/embedding_cache") # Assur√© cr√©√© et accessible par appuser dans Dockerfile
SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads")
logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}")
logging.info(f"Cache Embeddings: {EMBEDDING_CACHE_DIR}")
logging.info("--- Fin Chargement Configuration ---")

# --- Fonctions Utilitaires (Seule TTS est activement utilis√©e initialement) ---

# AJOUT v4.1: D√©corateur Retry de Tenacity (exemple simple)
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True) # reraise=True pour pouvoir catcher l'erreur finale
def text_to_speech(text: str) -> bytes | None:
    """Appelle l'API XTTS pour g√©n√©rer l'audio avec retry et timeout."""
    api_url = f"{XTTS_SERVER_URL}/generate"
    payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}
    logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'")
    try:
        # AJOUT v4.1: Timeout + raise_for_status
        response = requests.post(api_url, json=payload, timeout=60) # Timeout de 60s
        response.raise_for_status() # L√®ve une exception pour les erreurs HTTP (4xx, 5xx)
        data = response.json()
        audio_base64 = data.get("audio_base64")
        if audio_base64:
            logging.info("[TTS] Audio re√ßu avec succ√®s.")
            return base64.b64decode(audio_base64)
        else:
            # Cas o√π l'API r√©pond 200 OK mais sans donn√©es audio (peu probable mais g√©r√©)
            logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'. R√©ponse: {data}")
            return None
    except requests.exceptions.Timeout as e:
         logging.warning(f"[TTS] Timeout lors de l'appel API ({e}). Tenacity va r√©essayer...")
         raise # Relance l'exception pour que Tenacity la capture et r√©essaie
    except requests.exceptions.RequestException as e:
        logging.warning(f"[TTS] Erreur requ√™te API ({e}). Tenacity va r√©essayer...")
        raise # Relance pour Tenacity
    except Exception as e:
        # Capture une erreur inattendue (ex: parsing JSON √©choue) qui ne sera pas r√©essay√©e
        logging.error(f"[TTS] Erreur inattendue (non-retryable): {e}", exc_info=True)
        return None # Ne pas relancer pour √©viter boucle infinie si erreur non li√©e √† l'appel

# --- Placeholders pour fonctions futures (activ√©es dans les phases suivantes) ---
# ... (fonctions transcribe_audio, generate_image_tool, notes, RAG etc. restent placeholders ici) ...
def transcribe_audio(audio_bytes: bytes) -> str | None: logging.warning("[STT] transcribe_audio non actif."); return None
def generate_image_tool(prompt: str) -> str: logging.warning("[IMG] generate_image_tool non actif."); return "Fonctionnalit√© d√©sactiv√©e."
def _is_path_safe(requested_path: Path) -> bool: return False
def list_notes_safe() -> str: logging.warning("[NOTES] list_notes_safe non actif."); return "Action d√©sactiv√©e."
def save_note_safe(filename: str, content: str) -> str: logging.warning("[NOTES] save_note_safe non actif."); return "Action d√©sactiv√©e."
def read_note_safe(filename: str) -> str: logging.warning("[NOTES] read_note_safe non actif."); return "Action d√©sactiv√©e."
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e."


# --- Initialisation Globale IA (Embeddings, Client ChromaDB, Retriever) ---
logging.info("--- D√©but Initialisation Globale IA ---")
ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}
try:
    logging.info("[INIT] Chargement SentenceTransformer Embeddings...")
    ia_components["embeddings"] = SentenceTransformerEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        cache_folder=str(EMBEDDING_CACHE_DIR) # Chemin du cache
    )
    logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t (cache: {EMBEDDING_CACHE_DIR}).")

    logging.info(f"[INIT] Connexion au client ChromaDB √† http://{CHROMADB_HOST}:{CHROMADB_PORT}...")
    ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60)
    ia_components["chroma_client"].heartbeat() # Teste la connexion
    logging.info("[INIT] Client ChromaDB connect√©.")

    logging.info(f"[INIT] Pr√©paration Langchain VectorStore '{CHROMA_COLLECTION_NAME}'...")
    ia_components["vector_store_lc"] = ChromaLangchainStore(
        client=ia_components["chroma_client"],
        collection_name=CHROMA_COLLECTION_NAME,
        embedding_function=ia_components["embeddings"]
    )
    ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3})
    logging.info("[INIT] Langchain VectorStore et Retriever pr√™ts.")
    logging.info("--- Fin Initialisation Globale IA ---")

except Exception as e:
    # Erreur critique si l'init √©choue
    logging.critical(f"[INIT - ERREUR FATALE] Initialisation globale Embeddings/Chroma √©chou√©e: {e}", exc_info=True)
    # Mettre les composants √† None pour que les v√©rifications √©chouent proprement
    ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}

# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation pour chaque nouvelle session de chat."""
    logging.info("\n--- Nouvelle Session Chat (Phase 3 v4.2 - Setup Initial) ---")
    # V√©rifier si l'initialisation globale a r√©ussi
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA (Embeddings/Chroma) non initialis√©s au d√©marrage.")
         await cl.Message(content="Erreur critique: Composants IA (Embeddings/Chroma) non initialis√©s. V√©rifiez logs serveur.").send()
         return # Ne pas continuer si l'init de base a √©chou√©

    try:
        logging.info("[Session Start] Initialisation LLM Ollama...")
        llm = ChatOllama(model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.7)
        cl.user_session.set("llm", llm)
        # Stocker retriever/vector store pour utilisation future (RAG)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])
        logging.info("[Session Start] LLM et Retriever pr√™ts.")

        # Cha√Æne LangChain TRES simple (LLM seul) pour test initial Phase 4
        logging.info("[Session Start] Cr√©ation cha√Æne LLM simple...")
        # Note: Utilisation de RunnablePassthrough pour passer directement l'input (apr√®s sanitization)
        prompt = ChatPromptTemplate.from_template("Question: {input_sanitized}\nR√©ponse:")
        simple_chain = {"input_sanitized": RunnablePassthrough()} | prompt | llm | StrOutputParser()
        cl.user_session.set("chain", simple_chain)
        logging.info("[Session Start] Cha√Æne LLM simple pr√™te.")

        logging.info("[Session Start] Configuration UI: Input Texte seulement.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="Entrez votre message...", initial="") ] ).send()

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant (Phase 3 v4.2 - Test Initial) pr√™t.", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Initialis√©e et Pr√™te ---")

    except Exception as e:
        # Erreur pendant le setup de la session
        error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"
        logging.critical(error_msg, exc_info=True)
        await cl.Message(content=f"Erreur interne lors du d√©marrage de la session: {error_msg}", author="Erreur Syst√®me").send()

@cl.on_message
async def on_message(message: cl.Message):
    """G√®re les messages texte entrants (utilise cha√Æne simple pour Phase 4)."""
    logging.info(f"\n--- Message Re√ßu (Texte) ---")
    logging.info(f"Input brut: '{message.content[:100]}...'")

    # AJOUT v4.1: Sanitization de l'input avant de le passer √† la cha√Æne LLM
    try:
        sanitized_input = sanitize_input(message.content)
        # Optionnel: Loguer si l'input a √©t√© modifi√© par la sanitization
        # if sanitized_input != message.content:
        #     logging.warning(f"Input modifi√© par sanitization: '{sanitized_input[:100]}...'")
        logging.info(f"Input (Sanitized): '{sanitized_input[:100]}...'")
    except Exception as e:
        logging.error(f"√âchec de la sanitization de l'input: {e}", exc_info=True)
        await cl.Message(content=f"Erreur interne lors du traitement de votre message.").send()
        return

    chain = cl.user_session.get("chain")
    if not chain:
        logging.error("[on_message] Erreur critique : Cha√Æne de traitement non trouv√©e dans la session.")
        await cl.Message(content="Erreur critique : Cha√Æne de traitement non initialis√©e pour cette session.").send()
        return

    msg = cl.Message(content="", author="Assistant Khaldounia"); await msg.send()
    final_answer = ""
    try:
        logging.info("[Run] Appel cha√Æne LLM simple...")
        # Utilise l'input sanitiz√©
        async for chunk in chain.astream(sanitized_input): # Passe directement l'input sanitiz√©
            await msg.stream_token(chunk)
            final_answer += chunk
        await msg.update()
        logging.info(f"[Run] R√©ponse LLM: '{final_answer[:100]}...'")

        logging.info("[Run] G√©n√©ration audio XTTS...")
        try:
            # Appel de la fonction TTS (qui a maintenant retry/timeout/raise)
            audio_bytes = text_to_speech(final_answer)
            if audio_bytes:
                 await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send()
                 logging.info("[Run] Audio envoy√©.")
            else:
                 # Cas o√π TTS renvoie None apr√®s retries (erreur interne non li√©e √† l'appel)
                 logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries si √©chec appel).")
                 await cl.Message(content="(Erreur interne lors de la g√©n√©ration audio)", parent_id=msg.id, author="Alerte Syst√®me").send()

        # Capture l'erreur si text_to_speech √©choue apr√®s tous les retries
        except Exception as tts_err:
            logging.error(f"[Run] √âchec final appel TTS apr√®s retries: {tts_err}", exc_info=True)
            await cl.Message(content=f"(Erreur communication avec le service audio. Veuillez r√©essayer.)", parent_id=msg.id, author="Alerte Syst√®me").send()

    except Exception as e:
        # Erreur g√©n√©rale pendant le traitement du message par la cha√Æne
        error_message = f"ERREUR lors du traitement LLM: {e}"
        logging.error(f"[Run] {error_message}", exc_info=True)
        await msg.update(content="D√©sol√©, une erreur s'est produite lors de la g√©n√©ration de la r√©ponse.") # Message g√©n√©rique √† l'utilisateur

    logging.info("--- Fin Traitement Message ---")

# ... (Autres d√©corateurs @cl.on_audio_end, @cl.on_file_upload restent non pertinents ici) ...

```

* **Action :** Sauvegardez ce fichier `app.py` initial r√©vis√©.

---

Fin de la Phase 3 (R√©vis√©e v4.1).

```markdown
---

## Phase 4 : Lancement Initial & Tests (Base R√©vis√©e v4.2)

**Objectif :** D√©marrer pour la premi√®re fois les 4 services Docker de base (`ollama`, `xtts_server`, `chromadb`, `assistant_app`) avec les configurations s√©curis√©es/stabilis√©es (versions fig√©es, healthchecks, ports 127.0.0.1, volumes nomm√©s XTTS) des phases pr√©c√©dentes. **Copier le fichier vocal de r√©f√©rence dans le volume XTTS.** Effectuer des tests simples pour valider que chaque service d√©marre sainement, communique, et que l'interface de base est fonctionnelle.

**Important :** Cette phase valide l'infrastructure minimale avant d'ajouter les fonctionnalit√©s plus complexes. Soyez patient lors du premier d√©marrage (t√©l√©chargements) et notez que les `healthchecks` peuvent l√©g√®rement retarder le d√©marrage complet.

---

### √âtape 4.1 : Se Placer dans le Dossier `assistant-core`

* **Explication :** N√©cessaire pour ex√©cuter les commandes `docker compose`.
* **Commande :**
    ```bash
    cd ~/projet-khaldounia/assistant-core
    ```
* **Commande (V√©rification) :**
    ```bash
    pwd
    ```
    * *(Doit afficher `/home/VotreNomWSL/projet-khaldounia/assistant-core`)*.

---

### √âtape 4.2 : Construire l'Image App et D√©marrer les Services

* **Explication :** Lance tous les services d√©finis dans `docker-compose.yml` (version r√©vis√©e v4.2). L'option `--build` reconstruit l'image `assistant_app` (utilisateur non-root, d√©pendances MAJ, code initial durci). Docker va t√©l√©charger les images publiques sp√©cifi√©es si n√©cessaire.
* **Note sur le d√©marrage :** Gr√¢ce aux `healthchecks` et √† `depends_on: condition: service_healthy`, le conteneur `assistant_app` ne d√©marrera que lorsque `ollama`, `xtts_server`, et `chromadb` seront non seulement lanc√©s mais aussi consid√©r√©s comme "sains" (r√©pondant aux v√©rifications). Cela peut prendre un peu plus de temps au premier d√©marrage, le temps que les services internes (comme le chargement du mod√®le XTTS) soient pr√™ts.
* **COMMANDE IMPORTANTE :**
    ```bash
    docker compose up -d --build
    ```
* **üö® ATTENTION - TEMPS D'ATTENTE & T√âL√âCHARGEMENTS IMPORTANTS (1√®re fois) :**
    * **Soyez tr√®s patient !** Cette commande peut prendre **15 √† 30 minutes ou plus** la premi√®re fois (Build `assistant_app`, t√©l√©chargement images Docker, t√©l√©chargements internes des mod√®les Embedding/TTS).
    * **Surveillance :** Utilisez un **second terminal WSL** pour suivre les logs (`docker logs -f nom_conteneur`) des diff√©rents services (`assistant_app`, `xtts_server`, `ollama`).

---

### **√âTAPE 4.2 bis : COPIER LE FICHIER VOCAL DE R√âF√âRENCE (CRUCIAL)**

* **Explication :** Maintenant que le service `xtts_server` est d√©marr√© et que le volume nomm√© `khaldounia_xtts_speakers` existe, nous devons copier le fichier `speaker_ref.wav` (que vous aviez plac√© dans `~/projet-khaldounia/tts-data/speakers/` en Phase 1) √† l'int√©rieur du conteneur, dans le r√©pertoire mapp√© √† ce volume.
* **Action :** Une fois que `docker compose up -d --build` est termin√© et que le conteneur `xtts_server` est d√©marr√© (v√©rifiez avec `docker ps`), ex√©cutez la commande suivante **depuis votre terminal WSL** (adaptez si votre fichier source est ailleurs) :
    ```bash
    docker cp ~/projet-khaldounia/tts-data/speakers/speaker_ref.wav xtts_server:/app/speakers/speaker_ref.wav
    ```
* **V√©rification (Optionnelle) :** Vous pouvez v√©rifier que la copie a r√©ussi :
    ```bash
    docker exec xtts_server ls -l /app/speakers
    ```
    *(Doit lister `speaker_ref.wav` avec une taille non nulle).*
* **Note :** Cette copie n'est √† faire qu'une seule fois, car le fichier sera ensuite persistant dans le volume Docker `khaldounia_xtts_speakers`.

---

### √âtape 4.3 : V√©rifier l'√âtat des Conteneurs et leur Sant√©

* **Explication :** Apr√®s la fin de `docker compose up` ET la copie du fichier vocal, v√©rifiez que tous les conteneurs tournent et sont consid√©r√©s comme "sains" par Docker gr√¢ce aux `healthchecks`.
* **Commande :**
    ```bash
    docker ps
    ```
* **R√©sultat Attendu :** Doit lister **4 conteneurs** (`ollama`, `xtts_server`, `chromadb`, `assistant_app`). La colonne `STATUS` devrait indiquer `Up X minutes (healthy)` pour chacun apr√®s un certain temps (le temps d√©fini dans `start_period` du `healthcheck`). Si un service d√©marre mais rencontre un probl√®me, il pourrait afficher `(unhealthy)` ou `(health: starting)`.
* **En Cas de Probl√®me :** Si un conteneur a un statut `Exited`, `Restarting`, ou `(unhealthy)` :
    * **Identifier le Conteneur :** Notez son nom.
    * **Consulter les Logs :** `docker logs --tail 100 [nom_du_conteneur]`
    * **Consulter les D√©tails du Healthcheck (si unhealthy) :** `docker inspect --format='{{json .State.Health}}' [nom_du_conteneur]` (Regardez la sortie de la derni√®re v√©rification dans `Log`).
    * **Erreurs Courantes Phase 4 (R√©vis√©e) :** Similaires √† avant, mais v√©rifier aussi :
        * √âchec du `healthcheck` (API ne r√©pond pas comme attendu ? Timeout ?).
        * Probl√®me de permission li√© √† l'utilisateur `appuser` dans `assistant_app` (moins probable avec le `chown` dans le Dockerfile, mais √† v√©rifier si logs indiquent `Permission denied`).
        * Oubli de copier `speaker_ref.wav` (causera des erreurs dans `xtts_server` ou dans `app.py` plus tard).
    * **Strat√©gie :** Utilisez l'Annexe A avec les logs et l'√©tat de sant√©.

---

### √âtape 4.3bis : Tests de Connectivit√© API Directs (`curl` via 127.0.0.1)

* **Explication :** V√©rifications rapides pour voir si les APIs des services sont accessibles depuis WSL via l'adresse locale `127.0.0.1`.
* **Test Ollama (API Generate) :**
    ```bash
    curl -X POST [http://127.0.0.1:11434/api/generate](https://www.google.com/search?q=http://127.0.0.1:11434/api/generate) -d '{"model":"mistral:latest","prompt":"Test Ollama API","stream":false}'
    ```
    *(R√©sultat Attendu : R√©ponse JSON avec cl√© `"response"`. Premier appel peut √™tre lent).*
    *(Si erreur : Conteneur `ollama` non sain ? Probl√®me port 11434 ? Mod√®le `mistral` non pr√©sent ?)*
* **Test ChromaDB (API Heartbeat) :**
    ```bash
    curl [http://127.0.0.1:8002/api/v1/heartbeat](https://www.google.com/search?q=http://127.0.0.1:8002/api/v1/heartbeat)
    ```
    *(R√©sultat Attendu : R√©ponse JSON `{"nanosecond heartbeat":...}`)*.
    *(Si erreur : Conteneur `chromadb` non sain ? Probl√®me port 8002 ?)*
* **Test XTTS (V√©rification Serveur / API Speakers) :**
    ```bash
    curl [http://127.0.0.1:8050/speakers](https://www.google.com/search?q=http://127.0.0.1:8050/speakers)
    ```
    *(R√©sultat Attendu : R√©ponse JSON, potentiellement `[]` ou listant `speaker_ref.wav` si l'API le permet. Le principal est de ne pas avoir "Connection refused" et que le service soit `(healthy)`).*
    *(Si erreur : Conteneur `xtts_server` non sain ? Oubli copie `speaker_ref.wav` (√âtape 4.2bis) ? Probl√®me chargement mod√®le TTS (VRAM ?) ?)*
* **En Cas de Probl√®me `curl` :** Si une commande √©choue, le service a un probl√®me. Rev√©rifiez `docker ps` (√©tat de sant√©) et analysez les logs `docker logs [nom_du_conteneur]`.

---

### √âtape 4.4 : Tester l'Acc√®s √† l'Interface Web Chainlit (via 127.0.0.1)

* **Action :** Ouvrez votre navigateur web sur Windows.
* **Action :** Allez √† l'URL : `http://127.0.0.1:8001` (le port h√¥te local d√©fini pour `assistant_app`).
* **R√©sultat Attendu :** L'interface Chainlit doit se charger. Le message d'accueil *"Bonjour Halim-IA ! Assistant (Phase 3 v4.2 - Test Initial) pr√™t."* doit appara√Ætre.
* **En Cas de Probl√®me :**
    * **Page inaccessible ("Ce site est inaccessible", ERR_CONNECTION_REFUSED...) :** Le conteneur `assistant_app` n'est pas d√©marr√© ou pas sain (`docker ps`) ? Probl√®me avec le port 8001 ? V√©rifiez les logs `docker logs assistant_app` (erreurs au d√©marrage de Chainlit, √©chec connexion d√©pendances ?).
    * **Page blanche, chargement infini, erreur UI :** Probl√®me dans `app.py` (`@cl.on_chat_start`). V√©rifiez logs `assistant_app` (erreurs Python, √©chec init globale Embeddings/Chroma ?).

---

### √âtape 4.5 : Tester l'Interaction de Base (LLM + TTS)

* **Explication :** Test simple : Input Texte -> `app.py` (sanitized) -> Cha√Æne LLM Simple -> Ollama -> R√©ponse Texte -> `app.py` -> XTTS (avec retry/timeout) -> R√©ponse Audio.
* **Action :** Dans Chainlit (`http://127.0.0.1:8001`), tapez `Bonjour` ou `Raconte-moi une blague courte`.
* **R√©sultat Attendu :**
    1.  R√©ponse **texte** g√©n√©r√©e par Ollama.
    2.  R√©ponse **audio** g√©n√©r√©e par XTTS (avec la voix copi√©e en 4.2bis).
* **En Cas de Probl√®me :**
    * **Pas de R√©ponse Texte / Erreur Texte :** Logs `assistant_app` (erreur dans `@cl.on_message`, appel cha√Æne, appel Ollama ?) ; Logs `ollama` (sain ? mod√®le charg√© ? erreur GPU ?). Test `curl` Ollama (4.3bis).
    * **Texte OK, Pas de Son / Erreur Audio :** Logs `assistant_app` (erreur dans appel `text_to_speech` apr√®s retries ? `[ERREUR] √âchec final appel TTS...` ?) ; Logs `xtts_server` (sain ? voit bien `speaker_ref.wav` dans `/app/speakers` ? erreur traitement TTS ? VRAM ?). Test `curl` XTTS (4.3bis). Fichier `speaker_ref.wav` bien copi√© (4.2bis) ?
    * **Tr√®s Lent :** Normal au premier appel LLM/TTS. Si persistant, v√©rifier ressources (`nvidia-smi`, `htop` dans WSL).

---

### **√âtape 4.6: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** Base fonctionnelle √©tablie et test√©e. Bon moment pour sauvegarder avant d'ajouter Whisper.
* **M√©thode 1 : Copie Simple (Facile)**
    * Arr√™t : `docker compose down`
    * Copie : `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase4`
    * Red√©marrage : `docker compose up -d`
* **M√©thode 2 : Commit Git (Pr√©f√©rable)**
    * `git add .`
    * `git commit -m "Fin de la Phase 4 (v4.2) - Base LLM/TTS/RAG fonctionnelle (avec healthchecks, ports 127.0.0.1, volumes nomm√©s XTTS)"`

---

Fin de la Phase 4 (R√©vis√©e v4.2).


```markdown
---

## Phase 5 : Ajout Reconnaissance Vocale (STT/Whisper - R√©vis√©e v4.2)

**Objectif :** Int√©grer la reconnaissance vocale (Speech-to-Text) via un service Docker Whisper API (version fig√©e, healthcheck, port local). Mettre √† jour l'application `assistant_app` pour permettre l'interaction orale (activation entr√©e audio, appel API Whisper durci, gestion r√©ponse).

**Pr√©requis :** Phase 4 termin√©e et id√©alement sauvegard√©e. Les services de base sont fonctionnels (`(healthy)`). Le fichier vocal de r√©f√©rence a √©t√© copi√© dans le volume XTTS.

**Approche :** Ajout du service `whisper_server` dans `docker-compose.yml`. Mise √† jour de `app.py` pour activer l'entr√©e audio Chainlit, impl√©menter la fonction `transcribe_audio` (avec retries/timeout) appelant l'API Whisper, et ajouter le gestionnaire `@cl.on_audio_end`. La cha√Æne de traitement reste la cha√Æne RAG/LLM simple d√©finie pr√©c√©demment.

---

### √âtape 5.1 : Mettre √† jour le Fichier `docker-compose.yml` (Ajout Whisper)

* **Explication :** Ajout du 5√®me service (`whisper_server` avec healthcheck, port localis√©) et mise √† jour de `assistant_app` (variable d'environnement `WHISPER_SERVER_URL` et d√©pendance `depends_on` saine). Les configurations des services pr√©c√©dents (Ollama, XTTS, ChromaDB) sont conserv√©es (versions fig√©es, healthchecks, ports 127.0.0.1, volumes nomm√©s XTTS).
* **Action :** Ouvrez `~/projet-khaldounia/assistant-core/docker-compose.yml`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```yaml
# Fichier: docker-compose.yml (R√©vis√© v4.2 - Ajout Whisper)

version: '3.8'

services:
  # --- Ollama ---
  ollama:
    image: ollama/ollama:0.1.41 # FIG√âE
    container_name: ollama
    deploy: { resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } } }
    volumes: [ khaldounia_ollama_data:/root/.ollama ]
    ports: [ "127.0.0.1:11434:11434" ] # Acc√®s local
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:11434/"], interval: 30s, timeout: 10s, retries: 3, start_period: 60s }

  # --- XTTS ---
  xtts_server:
    image: ghcr.io/coqui-ai/tts:v0.22.0 # FIG√âE
    container_name: xtts_server
    command: > tts-server --model_name tts_models/multilingual/multi-dataset/xtts_v2 --use_cuda true --port 8020 --speaker_wav /app/speakers/speaker_ref.wav
    ports: [ "127.0.0.1:8050:8020" ] # Acc√®s local
    volumes:
      - khaldounia_xtts_cache:/root/.local/share/tts # Volume Nomm√©
      - khaldounia_xtts_speakers:/app/speakers      # Volume Nomm√©
    environment: [ NVIDIA_VISIBLE_DEVICES=all, NVIDIA_DRIVER_CAPABILITIES=compute,utility, COQUI_TOS_AGREED=1 ]
    deploy: # Acc√®s GPU (Optionnel - commenter si VRAM limit√©e)
       resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } }
    shm_size: 8gb
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8020/speakers"], interval: 30s, timeout: 10s, retries: 3, start_period: 180s }

  # --- ChromaDB ---
  chromadb:
    image: chromadb/chroma:0.5.0 # FIG√âE
    container_name: chromadb
    environment: { IS_PERSISTENT: 'TRUE', ALLOW_RESET: 'TRUE' }
    volumes: [ khaldounia_chroma_data:/chroma ]
    ports: [ "127.0.0.1:8002:8000" ] # Acc√®s local
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"], interval: 30s, timeout: 10s, retries: 3, start_period: 30s }

  # --- Whisper (STT) --- NOUVEAU SERVICE ---
  whisper_server:
    image: ghcr.io/distributors/whisper-asr-webservice:1.1.0 # FIG√âE (Exemple)
    container_name: whisper_server
    environment:
      - ASR_MODEL=small # Mod√®le Whisper (tiny, base, small, medium, large)
      - ASR_ENGINE=openai_whisper # Moteur
      # Optionnel: D√©commentez pour GPU si VRAM suffisante (MEDIUM+)
      # - NVIDIA_VISIBLE_DEVICES=all
    ports: [ "127.0.0.1:9000:9000" ] # API Whisper (Acc√®s local seulement)
    # deploy: # D√©commentez pour GPU
    #   resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } }
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"] # Endpoint standard
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s # Laisse le temps de charger le mod√®le Whisper

  # --- Assistant App (Mis √† jour) ---
  assistant_app:
    build: { context: ./app }
    container_name: assistant_app
    ports: [ "127.0.0.1:8001:8000" ] # Acc√®s local
    volumes:
        - ./app:/app
        - embedding_cache:/app/embedding_cache
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - XTTS_SERVER_URL=http://xtts_server:8020
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - WHISPER_SERVER_URL=http://whisper_server:9000 # <<< VARIABLE AJOUT√âE <<<
      # - STABLE_DIFFUSION_API_URL=... # Pour Phase 7
    depends_on: # <<< MIS A JOUR - Attend d√©pendances saines <<<
      ollama: { condition: service_healthy }
      xtts_server: { condition: service_healthy }
      chromadb: { condition: service_healthy }
      whisper_server: { condition: service_healthy } # Ajout d√©pendance Whisper saine
      # - stable_diffusion_webui: { condition: service_healthy } # Pour Phase 7
    stdin_open: true
    tty: true
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8000/"], interval: 30s, timeout: 10s, retries: 3, start_period: 60s }

# --- R√©seau Docker ---
networks:
  assistant_network: { driver: bridge, name: assistant_network }

# --- Volumes Docker ---
volumes:
  khaldounia_ollama_data: { driver: local }
  khaldounia_chroma_data: { driver: local }
  embedding_cache: { driver: local }
  khaldounia_xtts_cache: { driver: local }
  khaldounia_xtts_speakers: { driver: local }
  # Volumes SD comment√©s
```

* **Action :** Sauvegardez le fichier `docker-compose.yml`.

---

### √âtape 5.2 : V√©rifier le Fichier `requirements.txt`

* **Explication :** Normalement, aucune nouvelle d√©pendance Python n'est requise juste pour appeler l'API Whisper via `requests` (qui est d√©j√† inclus et fig√©, tout comme `tenacity`).
* **Action :** V√©rifiez que `requirements.txt` dans `assistant-core/app` est identique √† celui finalis√© en Phase 3 (R√©vis√©e v4.1).

---

### √âtape 5.3 : Mettre √† jour le Fichier `app.py` (Int√©gration STT Durcie)

* **Explication :** Active la fonction `transcribe_audio` (avec retries/timeout), ajoute l'input audio dans `@cl.on_chat_start`, et impl√©mente le gestionnaire `@cl.on_audio_end`. La cha√Æne de traitement reste la cha√Æne RAG/LLM simple (pas encore d'Agent). Le code int√®gre les am√©liorations de robustesse (logging, retries, timeouts, sanitization).
* **Action :** Ouvrez `app.py` dans `assistant-core/app`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (R√©vis√© v4.2 pour Phase 5 - Int√©gration STT Durcie)
# R√¥le: Application Khaldounia (Base + RAG Simple + STT - Robuste)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports pour Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain
logging.info("--- D√©but Importation Langchain (Phase 5 Rev 4.2) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# ... (Autres imports pour phases futures) ...
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale ---
logging.info("--- D√©but Chargement Configuration ---")
OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434")
XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020")
CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb")
CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000")
WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000") # AJOUT URL Whisper
# ... (autres variables) ...
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest")
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"
EMBEDDING_CACHE_DIR = Path("/app/embedding_cache")
SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads")
logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}")
logging.info("--- Fin Chargement Configuration ---")

# --- Fonctions Utilitaires ---

# --- Fonction STT (Activ√©e pour Phase 5 - avec retry/timeout) ---
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None:
    """Appelle l'API Whisper pour transcrire l'audio avec retry/timeout."""
    api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"
    files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}
    logging.info(f"[STT] Appel API Whisper: {api_url}")
    try:
        response = requests.post(api_url, files=files, timeout=60) # Timeout 60s
        response.raise_for_status() # V√©rifie erreurs HTTP
        result = response.json()
        transcribed_text = result.get("text", "").strip()
        logging.info(f"[STT] Whisper a retourn√©: '{transcribed_text[:50]}...'")
        return transcribed_text if transcribed_text else None # Retourne None si vide
    except requests.exceptions.Timeout as e:
        logging.warning(f"[STT] Timeout lors de l'appel API Whisper ({e}). Tenacity va r√©essayer...")
        raise
    except requests.exceptions.RequestException as e:
        logging.warning(f"[STT] Erreur requ√™te API Whisper ({e}). Tenacity va r√©essayer...")
        raise
    except Exception as e:
        logging.error(f"[STT] Erreur inattendue (non-retryable): {e}", exc_info=True)
        return None
# --- FIN Fonction STT ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None:
    # ... (Impl√©mentation text_to_speech durcie de Phase 3 R√©vis√©e v4.1) ...
    api_url = f"{XTTS_SERVER_URL}/generate"
    payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}
    logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'")
    try:
        response = requests.post(api_url, json=payload, timeout=180) # Timeout adapt√© pour TTS
        response.raise_for_status()
        data = response.json()
        audio_base64 = data.get("audio_base64")
        if audio_base64:
            logging.info("[TTS] Audio re√ßu avec succ√®s.")
            return base64.b64decode(audio_base64)
        else:
            logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'. R√©ponse: {data}")
            return None
    except requests.exceptions.Timeout as e:
         logging.warning(f"[TTS] Timeout lors de l'appel API ({e}). Tenacity va r√©essayer...")
         raise
    except requests.exceptions.RequestException as e:
        logging.warning(f"[TTS] Erreur requ√™te API ({e}). Tenacity va r√©essayer...")
        raise
    except Exception as e:
        logging.error(f"[TTS] Erreur inattendue (non-retryable): {e}", exc_info=True)
        return None

# --- Fonctions pour extensions futures (Placeholders) ---
# ... (generate_image_tool, notes, RAG etc. restent placeholders) ...
def generate_image_tool(prompt: str) -> str: logging.warning("[IMG] generate_image_tool non actif."); return "Fonctionnalit√© d√©sactiv√©e."
def _is_path_safe(requested_path: Path) -> bool: return False
def list_notes_safe() -> str: logging.warning("[NOTES] list_notes_safe non actif."); return "Action d√©sactiv√©e."
def save_note_safe(filename: str, content: str) -> str: logging.warning("[NOTES] save_note_safe non actif."); return "Action d√©sactiv√©e."
def read_note_safe(filename: str) -> str: logging.warning("[NOTES] read_note_safe non actif."); return "Action d√©sactiv√©e."
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e."

# --- Initialisation Globale (Identique Phase 3 R√©vis√©e v4.1) ---
# ... (Code d'init globale pour embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}


# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat (Active STT)."""
    logging.info("\n--- Nouvelle Session Chat (Phase 5 v4.2 - STT Actif) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA (Embeddings/Chroma) non initialis√©s.").send(); return

    try:
        # Initialiser LLM et stocker composants IA
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.7 )
        cl.user_session.set("llm", llm)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])
        logging.info("[Session Start] LLM et Retriever pr√™ts.")

        # Cha√Æne RAG simple (m√™me si non activement utilis√©e par un outil d√©di√© ici)
        # Sera utilis√©e par process_and_respond
        # D√©finit comment le contexte (vide pour l'instant) et la question sont format√©s
        rag_prompt_template = """Contexte (si disponible):
{context}

Question: {question}
R√©ponse:"""
        rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)

        # Fonction pour formater les documents r√©cup√©r√©s (sera vide au d√©but)
        def format_docs(docs): return "\n\n".join(doc.page_content for doc in docs) if docs else "Aucun contexte pertinent trouv√©."

        # Wrapper pour l'appel au retriever (g√®re le cas o√π il n'est pas pr√™t)
        def get_retriever_invoke(query):
             retriever_session = cl.user_session.get("retriever")
             # Lance la recherche, retourne une liste vide si le retriever n'est pas l√†
             # ou si aucun document n'est trouv√©.
             return retriever_session.invoke(query) if retriever_session else []

        # D√©finition de la cha√Æne RAG/LLM simple
        rag_chain_simple = (
             {
                 "context": RunnableLambda(lambda x: format_docs(get_retriever_invoke(x["question_sanitized"]))), # Utilise la question sanitiz√©e pour le RAG aussi
                 "question": RunnableLambda(lambda x: x["question_sanitized"]) # Passe la question sanitiz√©e au prompt
             }
             | rag_prompt
             | llm
             | StrOutputParser()
        )
        cl.user_session.set("rag_chain_simple", rag_chain_simple) # Stocke la cha√Æne simple
        logging.info("[Session Start] Cha√Æne RAG/LLM simple pr√™te.")


        # --- MODIFICATION PHASE 5 : Activer input audio ---
        logging.info("[Session Start] Configuration UI: Inputs Texte ET Audio.")
        await cl.ChatSettings(
            inputs=[
                cl.TextInput(id="text_input", label="Entrez votre message...", initial=""),
                # Ajoute le widget d'enregistrement audio
                cl.AudioInput(
                    id="audio_input",
                    label="Cliquez pour parler...",
                    # tooltip="Enregistrez votre question ici" # Optionnel
                    )
            ]
        ).send()
        # --- FIN MODIFICATION PHASE 5 ---

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2). Vous pouvez parler ou √©crire.", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Initialis√©e et Pr√™te (avec STT) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# Fonction centrale de traitement (utilise rag_chain_simple pour l'instant)
async def process_and_respond(input_content_sanitized: str):
    """Traite texte (original ou transcrit, d√©j√† sanitiz√©) via cha√Æne RAG/LLM simple, r√©pond texte+audio."""
    logging.info(f"\n--- Traitement Input (Sanitized) ---")
    logging.info(f"Input: '{input_content_sanitized[:60]}...'")
    rag_chain = cl.user_session.get("rag_chain_simple") # Utilise la cha√Æne simple
    if not rag_chain: logging.error("[Process] Erreur: Cha√Æne RAG simple non pr√™te."); await cl.Message(content="Erreur: Cha√Æne de traitement non pr√™te.").send(); return

    # Prompt=input brut original serait mieux, mais on ne l'a plus ici facilement. Utilise sanitiz√© pour l'instant.
    msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send()
    final_answer = ""
    try:
        logging.info("[Run] Appel Cha√Æne RAG/LLM simple...")
        # Passe l'input sanitiz√© √† la cha√Æne qui attend "question_sanitized"
        async for chunk in rag_chain.astream({"question_sanitized": input_content_sanitized}):
            await msg.stream_token(chunk); final_answer += chunk
        await msg.update(); logging.info(f"[Run] R√©ponse LLM: '{final_answer[:100]}...'")

        # TTS
        logging.info("[Run] G√©n√©ration audio XTTS...");
        try:
            audio_bytes = text_to_speech(final_answer)
            if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©.")
            else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", parent_id=msg.id, author="Alerte Syst√®me").send()
        except Exception as tts_err: # Erreur apr√®s retries
            logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", parent_id=msg.id, author="Alerte Syst√®me").send()

    except Exception as e: error_message = f"ERREUR process/respond: {e}"; logging.error(f"[Run] {error_message}", exc_info=True); await msg.update(content="D√©sol√©, erreur interne lors de la g√©n√©ration de la r√©ponse.")
    logging.info("--- Fin Traitement Input ---")


@cl.on_message # G√®re INPUT TEXTE
async def on_text_message(message: cl.Message):
    logging.info(f"\n--- Msg Texte UI ---")
    logging.info(f"Input brut: '{message.content[:60]}...'")
    try:
        sanitized_input = sanitize_input(message.content)
        logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'")
        await process_and_respond(sanitized_input) # Appelle la logique centrale
    except Exception as e:
        logging.error(f"Erreur lors de la sanitization/traitement du message texte: {e}", exc_info=True)
        await cl.Message(content="Erreur interne lors du traitement de votre message.").send()


# --- AJOUT PHASE 5 : Gestion INPUT AUDIO ---
@cl.on_audio_chunk # Stream audio - pas utilis√© ici pour Whisper API
async def on_audio_chunk(chunk: cl.AudioChunk): pass

@cl.on_audio_end # Appel√©e quand l'enregistrement audio est termin√©
async def on_audio_end(audio: cl.Audio):
    """Traite l'audio complet enregistr√© via l'interface Chainlit."""
    logging.info(f"\n--- Audio Re√ßu ---")
    logging.info(f"Nom: {audio.name}, Taille: {len(audio.content)} bytes, Mime: {audio.mime}")

    transcript_msg = cl.Message(content="*Transcription audio en cours...*", author="Syst√®me", disable_feedback=True);
    await transcript_msg.send()

    transcribed_text = None
    try:
        # Appeler la fonction de transcription (API Whisper) - qui a retry/timeout
        transcribed_text_raw = transcribe_audio(audio.content)

        if transcribed_text_raw is not None: # Peut √™tre vide si Whisper ne d√©tecte rien
             # Sanitize le texte transcrit avant de l'utiliser
             transcribed_text = sanitize_input(transcribed_text_raw)
             logging.info(f"Texte transcrit (Sanitized): '{transcribed_text[:60]}...'")
             await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text}\"")
             # Envoyer le texte transcrit ET sanitiz√© √† la fonction de traitement principale
             await process_and_respond(transcribed_text)
        else:
             # Cas o√π la transcription r√©ussit mais retourne None ou vide
             logging.warning("[STT] Transcription retourn√©e vide ou None.")
             await transcript_msg.update(content="Je n'ai pas pu transcrire l'audio ou rien n'a √©t√© dit. Veuillez r√©essayer.")

    except Exception as e: # Erreur finale apr√®s retries de transcribe_audio
        logging.error(f"[STT] √âchec final appel/traitement Whisper: {e}", exc_info=True)
        await transcript_msg.update(content="D√©sol√©, la transcription a √©chou√© apr√®s plusieurs tentatives. Veuillez r√©essayer ou taper votre message.")

    logging.info("--- Fin Traitement Audio ---")
# --- FIN AJOUT PHASE 5 ---

# --- Section RAG Upload (Phase 9) ---
# @cl.on_file_upload(...) sera d√©fini plus tard
# --- Fin Section RAG Upload ---

```

* **Action :** Sauvegardez le fichier `app.py`.

---

### √âtape 5.4 : Red√©marrer l'Environnement avec le Service Whisper

* **Explication :** Arr√™t et red√©marrage pour prendre en compte le nouveau service `whisper_server` et les modifications de `assistant_app`.
* **Action :** Terminal dans `assistant-core` :
    ```bash
    docker compose down
    ```
* **Action :** Reconstruire `assistant_app` (car `app.py` a chang√©) et d√©marrer tous les services (Ollama, XTTS, ChromaDB, Whisper, App) :
    ```bash
    docker compose up -d --build
    ```
* **Attente :** T√©l√©chargement de l'image Whisper (`ghcr.io/distributors/whisper-asr-webservice:1.1.0` ou tag choisi) la premi√®re fois. Le d√©marrage peut prendre un peu de temps le temps que tous les services deviennent `(healthy)`.

---

### √âtape 5.5 : Tester la Reconnaissance Vocale

* **Action :** V√©rifiez que les **5 conteneurs** (`ollama`, `xtts_server`, `chromadb`, `whisper_server`, `assistant_app`) sont bien `Up` et id√©alement `(healthy)` :
    ```bash
    docker ps
    ```
* **Action :** Ouvrez/Actualisez l'interface Chainlit : `http://127.0.0.1:8001`.
* **Action :** Cliquez sur l'ic√¥ne de microphone, autorisez l'acc√®s si demand√©, parlez (ex: "Quelle est la capitale de la France ?"), puis cliquez √† nouveau pour arr√™ter.
* **R√©sultat Attendu :**
    1.  Message "*Transcription audio en cours...*".
    2.  Remplac√© par "Vous avez dit : "[Votre texte transcrit et sanitiz√©]"".
    3.  L'assistant traite ce texte via la cha√Æne simple et r√©pond (texte + audio).
* **En Cas de Probl√®me :**
    * **Pas d'ic√¥ne micro / Input audio non activ√© :** V√©rifiez `cl.AudioInput` dans `@cl.on_chat_start` (`app.py`). Avez-vous bien fait `--build` ?
    * **Enregistrement √©choue :** Probl√®me navigateur/permissions micro OS.
    * **Message "Transcription √©chou√©e" / Pas de texte transcrit :**
        1.  Logs `assistant_app` : Erreur (`[ERREUR]`) dans `@cl.on_audio_end` ou `transcribe_audio` ? Timeout apr√®s retries ?
        2.  Logs `whisper_server` (`docker logs whisper_server`) : D√©marr√© et `(healthy)` ? Erreur interne ?
        3.  Test API Whisper : `curl http://127.0.0.1:9000/health` doit r√©pondre `OK`.
    * **Transcription OK, mais pas de r√©ponse LLM/TTS :** Probl√®me dans `process_and_respond` (voir d√©bogage Phase 4.5).

---

### **√âtape 5.6: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** STT fonctionnel sur une base durcie. Sauvegarde avant l'Agent/WebSearch.
* **M√©thode 1 : Copie Simple**
    * `docker compose down`
    * `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase5`
    * `docker compose up -d`
* **M√©thode 2 : Commit Git**
    * `git add .`
    * `git commit -m "Fin de la Phase 5 (v4.2) - STT Whisper fonctionnel (base durcie)"`

---

Fin de la Phase 5 (R√©vis√©e v4.2).

```markdown
---

## Phase 6 : Ajout de la Recherche Web (Agent - R√©vis√©e v4.2)

**Objectif :** Mettre en place une architecture d'Agent LangChain (type ReAct) dans l'application `app.py` (version durcie). Cet agent sera capable d'utiliser des "Outils". Dans cette phase, nous activons **uniquement** l'outil de recherche web (DuckDuckGo) pour permettre √† l'assistant de chercher des informations √† jour sur Internet.

**Pr√©requis :** Phase 5 termin√©e et id√©alement sauvegard√©e. STT/Whisper est fonctionnel sur la base durcie (v4.2).

**Approche :** V√©rification des d√©pendances Python (normalement OK depuis Phase 3 r√©vis√©e). Modification majeure de `app.py` pour initialiser l'`AgentExecutor` avec seulement `search_tool` actif dans `@cl.on_chat_start`. Adaptation de la logique de r√©ponse (`process_and_respond`) pour utiliser cet agent.

---

### √âtape 6.1 : V√©rifier le Fichier `requirements.txt`

* **Explication :** S'assurer que les biblioth√®ques n√©cessaires pour les agents LangChain (`langchain`, `langchainhub`) et l'outil DuckDuckGo (`duckduckgo-search`) sont bien pr√©sentes avec les versions fig√©es d√©finies en Phase 3 (R√©vis√©e v4.1).
* **Action :** V√©rifiez le contenu de `~/projet-khaldounia/assistant-core/app/requirements.txt`. Il doit √™tre identique √† la version finale de la Phase 3 (R√©vis√©e v4.1). Aucune nouvelle d√©pendance n'est normalement requise pour cette phase.

---

### √âtape 6.2 : Mettre √† jour le Fichier `app.py` (Int√©gration Agent et Outil WebSearch)

* **Explication :** C'est le c≈ìur de cette phase. Nous rempla√ßons la cha√Æne RAG/LLM simple par un Agent Executor dans `@cl.on_chat_start`. Cet agent est configur√© pour n'avoir acc√®s qu'√† l'outil `search_tool`. La fonction `process_and_respond` utilisera d√©sormais cet agent. Les fonctions durcies (`transcribe_audio`, `text_to_speech`) et la sanitization sont conserv√©es.
* **Action :** Ouvrez `app.py` dans `~/projet-khaldounia/assistant-core/app/`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (R√©vis√© v4.2 pour Phase 6 - Agent + WebSearch)
# R√¥le: Application Khaldounia (Agent ReAct avec WebSearch actif - Robuste)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain (Ajout Agent/Tools)
logging.info("--- D√©but Importation Langchain (Phase 6 Rev 4.2) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
# --- Ajout Agent/Tools ---
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun # Outil WebSearch
from langchain import hub # Pour charger les prompts d'agent standards
# --- Fin Ajout Agent/Tools ---
# Imports Core (gard√©s si besoin ailleurs)
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# ... (Autres imports pour phases futures) ...
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale (inchang√©e) ---
# ... (coller la config globale inchang√©e, lit les .env) ...
logging.info("--- D√©but Chargement Configuration ---"); OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434"); XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020"); CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb"); CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000"); WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000"); STABLE_DIFFUSION_API_URL = os.getenv("STABLE_DIFFUSION_API_URL", "http://stable_diffusion_webui:7860"); OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest"); EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"; EMBEDDING_CACHE_DIR = Path("/app/embedding_cache"); SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads"); logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}, SD@{STABLE_DIFFUSION_API_URL}"); logging.info("--- Fin Chargement Configuration ---")


# --- Fonctions Utilitaires (Durcies) ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None:
    # ... (Impl√©mentation transcribe_audio durcie de Phase 5 R√©vis√©e v4.2) ...
    api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"; files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}; logging.info(f"[STT] Appel API Whisper: {api_url}"); try: response = requests.post(api_url, files=files, timeout=60); response.raise_for_status(); result = response.json(); transcribed_text = result.get("text", "").strip(); logging.info(f"[STT] Whisper: '{transcribed_text[:50]}...'"); return transcribed_text if transcribed_text else None; except requests.exceptions.Timeout as e: logging.warning(f"[STT] Timeout Whisper ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[STT] Erreur requ√™te Whisper ({e}). Retry..."); raise; except Exception as e: logging.error(f"[STT] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None:
    # ... (Impl√©mentation text_to_speech durcie de Phase 3/5 R√©vis√©e v4.2) ...
    api_url = f"{XTTS_SERVER_URL}/generate"; payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}; logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'"); try: response = requests.post(api_url, json=payload, timeout=180); response.raise_for_status(); data = response.json(); audio_base64 = data.get("audio_base64"); if audio_base64: logging.info("[TTS] Audio re√ßu."); return base64.b64decode(audio_base64); else: logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'."); return None; except requests.exceptions.Timeout as e: logging.warning(f"[TTS] Timeout XTTS ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[TTS] Erreur requ√™te XTTS ({e}). Retry..."); raise; except Exception as e: logging.error(f"[TTS] Erreur inattendue: {e}", exc_info=True); return None

# --- Placeholders pour les autres outils ---
def generate_image_tool(prompt: str) -> str: logging.warning("[IMG] generate_image_tool non actif."); return "Fonctionnalit√© d√©sactiv√©e."
def _is_path_safe(requested_path: Path) -> bool: return False # Sera impl√©ment√© en Phase 8
def list_notes_safe() -> str: logging.warning("[NOTES] list_notes_safe non actif."); return "Action d√©sactiv√©e."
def save_note_safe(filename: str, content: str) -> str: logging.warning("[NOTES] save_note_safe non actif."); return "Action d√©sactiv√©e."
def read_note_safe(filename: str) -> str: logging.warning("[NOTES] read_note_safe non actif."); return "Action d√©sactiv√©e."
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e." # Sera impl√©ment√© en Phase 10

# --- Initialisation Globale (inchang√©e) ---
# ... (Code d'init globale pour embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}

# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat -> Mise en place de l'Agent avec WebSearch."""
    logging.info("\n--- Nouvelle Session Chat (Phase 6 v4.2 - Agent WebSearch Actif) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA (Embeddings/Chroma) non initialis√©s.").send(); return

    try:
        # Initialiser LLM (Temp√©rature plus basse souvent recommand√©e pour ReAct)
        logging.info("[Session Start] Initialisation LLM pour Agent...")
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2, request_timeout=300.0 ) # Timeout long pour LLM

        # --- AGENT SETUP ---
        logging.info("[Session Start] Configuration de l'Agent ReAct...")
        # 1. D√©finir TOUS les outils potentiels (pour r√©f√©rence future)
        search_tool = DuckDuckGoSearchRun(name="Recherche Web DuckDuckGo")
        # Placeholders pour les autres outils qui seront activ√©s plus tard
        image_tool = Tool( name="Generateur Image", func=generate_image_tool, description="Cr√©√© une image." )
        list_notes_tool = Tool( name="Lister Notes", func=list_notes_safe, description="Liste les notes." )
        save_note_tool = Tool( name="Sauvegarder Note", func=save_note_safe, description="Sauve une note." )
        read_note_tool = Tool( name="Lire Note", func=read_note_safe, description="Lit une note." )
        rag_tool = Tool( name="Recherche Document Personnel", func=run_rag_retriever, description="Cherche dans les docs." )

        # 2. S√©lectionner outils ACTIFS pour CETTE phase (WebSearch SEULEMENT)
        active_tools = [search_tool] # <<<=== SEUL OUTIL ACTIF ICI
        logging.info(f"[Session Start] Outils actifs pour l'agent: {[tool.name for tool in active_tools]}")

        # 3. Prompt ReAct (standard depuis Langchain Hub)
        try:
            react_prompt = hub.pull("hwchase17/react")
            logging.info("[Session Start] Prompt ReAct charg√© depuis Hub.")
        except Exception as hub_error:
            logging.critical(f"[Session Start] Erreur chargement prompt Hub: {hub_error}", exc_info=True)
            await cl.Message(content=f"Erreur critique: Impossible de charger le prompt de l'agent. Installation Langchain Hub OK ?").send(); return

        # 4. Cr√©er l'agent ReAct
        try:
            agent = create_react_agent(llm, active_tools, react_prompt)
            logging.info("[Session Start] Agent ReAct cr√©√©.")
        except Exception as agent_create_error:
            logging.critical(f"[Session Start] Erreur cr√©ation agent: {agent_create_error}", exc_info=True)
            await cl.Message(content=f"Erreur critique: Impossible de cr√©er l'agent.").send(); return

        # 5. Cr√©er l'AgentExecutor
        agent_executor = AgentExecutor(
            agent=agent,
            tools=active_tools, # Utilise SEULEMENT les outils actifs
            verbose=True, # Tr√®s utile pour voir la pens√©e de l'agent dans les logs !
            handle_parsing_errors=True, # Tente de corriger les erreurs de formatage LLM
            max_iterations=10 # Limite de s√©curit√© pour √©viter boucles infinies
        )
        cl.user_session.set("agent_executor", agent_executor) # Stocke l'EXECUTOR
        logging.info("[Session Start] Agent Executor (WebSearch seul) initialis√©.")
        # --- FIN AGENT SETUP ---

        # Stocker retriever/vector store pour upload (Phase 9)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])

        # Activer Inputs (Texte/Audio) & Upload Fichiers (inchang√© depuis Phase 5)
        logging.info("[Session Start] Configuration UI: Inputs Texte/Audio/Upload.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="...", initial=""), cl.AudioInput(id="audio_input", label="...") ] ).send()
        # Note: L'activation de l'upload est ici pour pr√©parer Phase 9, m√™me si l'outil RAG n'est pas actif
        cl.set_config(enable_file_upload=True, file_upload_accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2 - avec Recherche Web).", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Pr√™te (Agent WebSearch) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# MODIFICATION : process_and_respond utilise maintenant l'Agent Executor
async def process_and_respond(input_content_sanitized: str):
    """Traite l'entr√©e utilisateur (sanitiz√©e) via l'Agent Executor et renvoie la r√©ponse (texte+audio)."""
    logging.info(f"\n--- Traitement Input via Agent ---")
    logging.info(f"Input (Sanitized): '{input_content_sanitized[:60]}...'")
    agent_executor = cl.user_session.get("agent_executor")
    if not agent_executor:
        logging.error("[Process] Agent Executor non trouv√© dans la session.")
        await cl.Message(content="Erreur critique : Agent non initialis√© pour cette session.").send(); return

    msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send()
    final_answer_text = ""; image_to_display = None
    try:
        logging.info("[Run] Appel Agent Executor (ainvoke)...")
        # Invoque l'agent avec l'input sanitiz√©. L'agent d√©cide d'utiliser un outil ou non.
        # Le prompt ReAct standard attend la cl√© "input".
        response = await agent_executor.ainvoke({"input": input_content_sanitized})
        final_answer_text = response.get("output", "D√©sol√©, je n'ai pas pu obtenir de r√©ponse structur√©e.")
        logging.info(f"[Run] R√©ponse brute de l'Agent: '{final_answer_text[:100]}...'")

        # Gestion si un outil (futur) retourne un chemin d'image
        if isinstance(final_answer_text, str) and final_answer_text.startswith("IMAGE_GENEREE:"):
            try:
                relative_image_path = final_answer_text.split(":", 1)[1]
                image_path_in_container = Path("/app") / relative_image_path
                if image_path_in_container.is_file():
                    image_to_display = cl.Image(path=str(image_path_in_container), name=os.path.basename(relative_image_path), display="inline")
                    final_answer_text = f"Voici l'image demand√©e." # R√©ponse texte associ√©e
                    logging.info(f"[Run] Outil Image a retourn√© un fichier valide: {relative_image_path}")
                else:
                    logging.error(f"[Run] Chemin image retourn√© par outil invalide ou fichier non trouv√©: {image_path_in_container}")
                    final_answer_text += " (Erreur: fichier image introuvable apr√®s g√©n√©ration)"
            except Exception as img_err:
                 logging.error(f"[Run] Erreur traitement retour Outil Image: {img_err}", exc_info=True)
                 final_answer_text = "Une erreur s'est produite lors de l'affichage de l'image g√©n√©r√©e."

        # Met √† jour le message Chainlit avec la r√©ponse finale texte
        await msg.update(content=final_answer_text)
        logging.info(f"[Run] R√©ponse finale affich√©e: '{final_answer_text[:100]}...'")

        # Afficher l'image si elle existe (ne devrait pas arriver ici en Phase 6)
        if image_to_display:
            await cl.Message(content="", elements=[image_to_display], author="Image G√©n√©r√©e").send()

        # G√©n√©ration TTS de la r√©ponse finale texte
        logging.info("[Run] G√©n√©ration audio XTTS...");
        try:
            audio_bytes = text_to_speech(final_answer_text)
            if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©.")
            else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", author="Alerte Syst√®me", parent_id=msg.id).send()
        except Exception as tts_err: # Erreur apr√®s retries
            logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", author="Alerte Syst√®me", parent_id=msg.id).send()

    except Exception as e:
        # Capture les erreurs pendant l'ex√©cution de l'agent
        error_message = f"ERREUR lors de l'ex√©cution de l'agent: {e}"
        logging.error(f"[Run] {error_message}", exc_info=True)
        await msg.update(content="D√©sol√©, une erreur interne s'est produite lors de la r√©flexion.") # Message g√©n√©rique

    logging.info("--- Fin Traitement Input ---")


# on_message (Appelle process_and_respond via l'Agent)
@cl.on_message
async def on_text_message(message: cl.Message):
    logging.info(f"\n--- Msg Texte UI ---")
    logging.info(f"Input brut: '{message.content[:60]}...'")
    try:
        sanitized_input = sanitize_input(message.content)
        logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'")
        await process_and_respond(sanitized_input) # Appelle la logique centrale via Agent
    except Exception as e:
        logging.error(f"Erreur sanitization/traitement message texte: {e}", exc_info=True)
        await cl.Message(content="Erreur interne traitement message.").send()

# on_audio_end (Appelle process_and_respond via l'Agent apr√®s transcription)
@cl.on_audio_end
async def on_audio_end(audio: cl.Audio):
    logging.info(f"\n--- Audio Re√ßu ---")
    logging.info(f"Taille: {len(audio.content)} bytes, mime: {audio.mime}")
    transcript_msg = cl.Message(content="*Transcription...*", author="Syst√®me", disable_feedback=True); await transcript_msg.send()
    transcribed_text_sanitized = None
    try:
        transcribed_text_raw = transcribe_audio(audio.content) # Appel durci
        if transcribed_text_raw is not None:
             transcribed_text_sanitized = sanitize_input(transcribed_text_raw)
             logging.info(f"Texte transcrit (Sanitized): '{transcribed_text_sanitized[:60]}...'")
             await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text_sanitized}\"")
             await process_and_respond(transcribed_text_sanitized) # Traite via l'Agent
        else:
             logging.warning("[STT] Transcription retourn√©e vide ou None.")
             await transcript_msg.update(content="Pas de son d√©tect√© ou transcription vide.")
    except Exception as e: # Erreur finale transcription ou sanitization
        logging.error(f"[STT] √âchec final transcription/sanitization: {e}", exc_info=True)
        await transcript_msg.update(content="√âchec transcription apr√®s tentatives.")
    logging.info("--- Fin Traitement Audio ---")


# on_file_upload (D√©fini mais non utilis√© par l'Agent dans cette phase)
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)
async def on_file_upload(files: list[cl.File]):
    # La logique d'upload RAG sera impl√©ment√©e/activ√©e en Phase 9/10
    logging.info(f"\n--- Fichiers Re√ßus (Logique Upload Phase 9+ non active) ---")
    if not files: return
    await cl.Message(content=f"R√©ception de {len(files)} fichier(s). Traitement d'indexation RAG non impl√©ment√© dans cette phase.").send()
    # Ici, normalement, le code de chargement/split/indexation de Phase 9 irait
    # Pour l'instant, on ne fait rien avec les fichiers

```

* **Action :** Sauvegardez le fichier `app.py`.

---

### √âtape 6.3 : Red√©marrer l'Environnement avec l'Agent

* **Explication :** Arr√™t et red√©marrage pour que le service `assistant_app` utilise le nouveau code `app.py` qui inclut l'Agent Executor (avec seulement l'outil WebSearch actif pour l'instant).
* **Action :** Terminal dans `assistant-core` :
    ```bash
    docker compose down
    ```
* **Action :** Reconstruire `assistant_app` (car `app.py` a chang√©) et d√©marrer tous les services (5 services maintenant) :
    ```bash
    docker compose up -d --build
    ```

---

### √âtape 6.4 : Tester la Recherche Web via l'Agent

* **Action :** V√©rifiez les 5 conteneurs (`docker ps`), ils devraient tous √™tre `Up` et `(healthy)`.
* **Action :** Ouvrez/Actualisez Chainlit : `http://127.0.0.1:8001`.
* **Test 1 (Web) :** Demandez une information n√©cessitant une recherche web (texte ou voix), par exemple : "Quel temps fait-il √† √âpinay-sur-Seine aujourd'hui ?"
* **R√©sultat Attendu :**
    1.  Dans les logs `assistant_app` (`docker logs -f assistant_app`), vous devriez voir les √©tapes de pens√©e de l'agent (`verbose=True`), incluant l'**Action: Recherche Web DuckDuckGo** et l'**Observation:** (r√©sultat de la recherche).
    2.  Dans l'interface Chainlit, l'assistant doit fournir une r√©ponse √† jour bas√©e sur la recherche web (texte + audio).
* **Test 2 (Sans Web) :** Demandez une salutation simple comme "Bonjour".
* **R√©sultat Attendu :** L'agent doit r√©pondre directement sans utiliser l'outil de recherche (visible dans les logs comme une **Action: Final Answer** sans √©tape d'observation d'outil).
* **En Cas de Probl√®me :** Si l'agent ne semble pas utiliser l'outil web ou si la recherche √©choue :
    * V√©rifiez les logs `assistant_app` (`verbose=True`) pour comprendre la "Thought" de l'agent et d√©tecter des erreurs de parsing ("Could not parse LLM output:") ou d'appel de l'outil DuckDuckGo.
    * Assurez-vous que le conteneur `assistant_app` a bien acc√®s √† Internet (g√©n√©ralement le cas via Docker Desktop/WSL2).
    * Consultez Annexe A.

---

### **√âtape 6.5: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** L'Agent avec recherche web est fonctionnel sur la base durcie. Sauvegarde avant la g√©n√©ration d'images.
* **M√©thode 1 : Copie Simple**
    * `docker compose down`
    * `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase6`
    * `docker compose up -d`
* **M√©thode 2 : Commit Git**
    * `git add .`
    * `git commit -m "Fin de la Phase 6 (v4.2) - Agent ReAct avec WebSearch fonctionnel (base durcie)"`

---

Fin de la Phase 6 (R√©vis√©e v4.2).

```markdown
---

## Phase 7 : Ajout G√©n√©ration Image (Stable Diffusion - R√©vis√©e v4.2)

**Objectif :** Activer l'outil de g√©n√©ration d'images dans l'agent, en utilisant le service Docker `linuxserver/stable-diffusion-webui` (bas√© sur A1111) avec une version d'image fig√©e, des volumes nomm√©s, un healthcheck, un port localis√©, et des arguments optimis√©s. **Copier manuellement un mod√®le de checkpoint est essentiel.**

**Pr√©requis :** Phase 6 termin√©e et id√©alement sauvegard√©e. Agent avec WebSearch fonctionnel sur base durcie (v4.2).

**Approche :** Ajout du service `stable_diffusion_webui` dans `docker-compose.yml`. Mise √† jour de `app.py` pour impl√©menter la fonction `generate_image_tool` (avec hardening) et l'activer dans l'AgentExecutor. Ajout d'instructions claires pour le placement manuel du mod√®le `.safetensors` requis via `docker cp` dans le volume nomm√©.

**Notes Importantes :**
* **VRAM :** Stable Diffusion est **extr√™mement gourmand**. Surveillez `nvidia-smi` dans WSL. Commentez le `deploy:` GPU des services `xtts_server`/`whisper_server` si vous manquez de VRAM.
* **Mod√®les SD :** L'√©tape 7.6 est **obligatoire** pour que la g√©n√©ration d'images fonctionne.

---

### √âtape 7.1 : Mettre √† jour le Fichier `docker-compose.yml` (Ajout SD WebUI)

* **Explication :** Ajout du 6√®me service (`stable_diffusion_webui` avec volumes nomm√©s, healthcheck, port localis√©) et mise √† jour de `assistant_app` (variable d'env `STABLE_DIFFUSION_API_URL`, d√©pendance saine). Les configurations des 5 services pr√©c√©dents sont conserv√©es.
* **Action :** Ouvrez `~/projet-khaldounia/assistant-core/docker-compose.yml`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```yaml
# Fichier: docker-compose.yml (R√©vis√© v4.2 - Ajout Stable Diffusion)

version: '3.8'

services:
  # --- Ollama ---
  ollama:
    image: ollama/ollama:0.1.41 # FIG√âE
    container_name: ollama
    deploy: { resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } } }
    volumes: [ khaldounia_ollama_data:/root/.ollama ]
    ports: [ "127.0.0.1:11434:11434" ] # Acc√®s local
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:11434/"], interval: 30s, timeout: 10s, retries: 3, start_period: 60s }

  # --- XTTS ---
  xtts_server:
    image: ghcr.io/coqui-ai/tts:v0.22.0 # FIG√âE
    container_name: xtts_server
    command: > tts-server --model_name tts_models/multilingual/multi-dataset/xtts_v2 --use_cuda true --port 8020 --speaker_wav /app/speakers/speaker_ref.wav
    ports: [ "127.0.0.1:8050:8020" ] # Acc√®s local
    volumes: [ khaldounia_xtts_cache:/root/.local/share/tts, khaldounia_xtts_speakers:/app/speakers ] # Volumes Nomm√©s
    environment: [ NVIDIA_VISIBLE_DEVICES=all, NVIDIA_DRIVER_CAPABILITIES=compute,utility, COQUI_TOS_AGREED=1 ]
    deploy: # Acc√®s GPU (Optionnel - commenter si VRAM limit√©e)
       resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } }
    shm_size: 8gb
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8020/speakers"], interval: 30s, timeout: 10s, retries: 3, start_period: 180s }

  # --- ChromaDB ---
  chromadb:
    image: chromadb/chroma:0.5.0 # FIG√âE
    container_name: chromadb
    environment: { IS_PERSISTENT: 'TRUE', ALLOW_RESET: 'TRUE' }
    volumes: [ khaldounia_chroma_data:/chroma ]
    ports: [ "127.0.0.1:8002:8000" ] # Acc√®s local
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"], interval: 30s, timeout: 10s, retries: 3, start_period: 30s }

  # --- Whisper (STT) ---
  whisper_server:
    image: ghcr.io/distributors/whisper-asr-webservice:1.1.0 # FIG√âE
    container_name: whisper_server
    environment: [ ASR_MODEL=small, ASR_ENGINE=openai_whisper ]
    ports: [ "127.0.0.1:9000:9000" ] # Acc√®s local
    # deploy: # GPU Optionnel
    #   resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } }
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:9000/health"], interval: 30s, timeout: 10s, retries: 3, start_period: 90s }

  # --- Stable Diffusion WebUI (Image Gen) --- NOUVEAU SERVICE ---
  stable_diffusion_webui:
    image: lscr.io/linuxserver/stable-diffusion-webui:amd64-1.9.3 # FIG√âE (Exemple)
    container_name: stable_diffusion_webui
    environment:
      - PUID=1000 # Votre 'id -u' WSL
      - PGID=1000 # Votre 'id -g' WSL
      - TZ=Europe/Paris # Adaptez
      - NVIDIA_VISIBLE_DEVICES=all # Requis GPU
      # Args: API on, Listen All Interfaces (s√©curit√© via port binding), xformers, extensions, no-half-vae
      - CLI_ARGS=--api --listen --port 7860 --xformers --enable-insecure-extension-access --no-half-vae
    volumes:
      # Volumes nomm√©s pour SD (persistants)
      - khaldounia_sd_config:/config # Config UI, extensions...
      - khaldounia_sd_models:/config/stable-diffusion # Mod√®les Checkpoint, VAE, LoRA...
      - khaldounia_sd_outputs:/output # Images g√©n√©r√©es par l'UI/API
    ports: [ "127.0.0.1:7860:7860" ] # API et UI Web (Acc√®s local seulement)
    deploy: # Acc√®s GPU INDISPENSABLE
        resources: { reservations: { devices: [ { driver: nvidia, count: 1, capabilities: [gpu] } ] } }
        # >>> Note VRAM : TRES GOURMAND! Commentez deploy: GPU des autres services (XTTS/Whisper) si besoin. <<<
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck:
      # Teste si l'API /docs est accessible (indique que --api est actif)
      test: ["CMD", "curl", "-f", "http://localhost:7860/docs"]
      interval: 60s  # Moins fr√©quent car long √† d√©marrer/g√©n√©rer
      timeout: 30s
      retries: 5
      start_period: 300s # Laisse 5 min pour d√©marrer SD WebUI et charger mod√®le initial

  # --- Assistant App (Mis √† jour) ---
  assistant_app:
    build: { context: ./app }
    container_name: assistant_app
    ports: [ "127.0.0.1:8001:8000" ] # Acc√®s local
    volumes: [ ./app:/app, embedding_cache:/app/embedding_cache ]
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - XTTS_SERVER_URL=http://xtts_server:8020
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - WHISPER_SERVER_URL=http://whisper_server:9000
      - STABLE_DIFFUSION_API_URL=http://stable_diffusion_webui:7860 # <<< AJOUT URL SD <<<
    depends_on: # <<< MIS A JOUR - Attend TOUTES les d√©pendances saines <<<
      ollama: { condition: service_healthy }
      xtts_server: { condition: service_healthy }
      chromadb: { condition: service_healthy }
      whisper_server: { condition: service_healthy }
      stable_diffusion_webui: { condition: service_healthy } # Ajout d√©pendance SD saine
    stdin_open: true
    tty: true
    networks: [ assistant_network ]
    restart: unless-stopped
    healthcheck: { test: ["CMD", "curl", "-f", "http://localhost:8000/"], interval: 30s, timeout: 10s, retries: 3, start_period: 60s }

# --- R√©seau Docker ---
networks:
  assistant_network: { driver: bridge, name: assistant_network }

# --- Volumes Docker (Ajout SD) ---
volumes:
  khaldounia_ollama_data: { driver: local }
  khaldounia_chroma_data: { driver: local }
  embedding_cache: { driver: local }
  khaldounia_xtts_cache: { driver: local }
  khaldounia_xtts_speakers: { driver: local }
  # Nouveaux volumes pour Stable Diffusion
  khaldounia_sd_config: { driver: local }
  khaldounia_sd_models: { driver: local }
  khaldounia_sd_outputs: { driver: local }

```

* **Action :** Sauvegardez le fichier `docker-compose.yml`.

---

### √âtape 7.2 : V√©rifier le Fichier `requirements.txt`

* **Explication :** Aucun changement requis par rapport √† la version r√©vis√©e de Phase 3. Les appels API se font via `requests`.
* **Action :** V√©rifiez `requirements.txt` dans `assistant-core/app`.

---

### √âtape 7.3 : Mettre √† jour le Fichier `app.py` (Activation Outil Image Gen)

* **Explication :** Impl√©mentation de la fonction `generate_image_tool` (avec hardening : retry, timeout, gestion erreur/sauvegarde) et ajout de l'`image_tool` √† la liste `active_tools` de l'agent dans `@cl.on_chat_start`.
* **Action :** Ouvrez `app.py` dans `~/projet-khaldounia/assistant-core/app/`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (R√©vis√© v4.2 pour Phase 7 - Activation ImgGen Tool)
# R√¥le: Application Khaldounia (Agent + WebSearch + ImgGen - Robuste)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain
logging.info("--- D√©but Importation Langchain (Phase 7 Rev 4.2) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# ... (Autres imports) ...
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale ---
logging.info("--- D√©but Chargement Configuration ---")
OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434"); XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020"); CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb"); CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000"); WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000"); STABLE_DIFFUSION_API_URL = os.getenv("STABLE_DIFFUSION_API_URL", "http://stable_diffusion_webui:7860") # AJOUT LECTURE URL SD
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest"); EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"; EMBEDDING_CACHE_DIR = Path("/app/embedding_cache"); SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads")
# Cr√©ation dossiers essentiels au cas o√π (normalement fait dans Dockerfile)
SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True)
logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}, SD@{STABLE_DIFFUSION_API_URL}")
logging.info("--- Fin Chargement Configuration ---")


# --- Fonctions Utilitaires (Durcies) ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None:
    # ... (Impl√©mentation transcribe_audio durcie) ...
    api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"; files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}; logging.info(f"[STT] Appel API Whisper: {api_url}"); try: response = requests.post(api_url, files=files, timeout=60); response.raise_for_status(); result = response.json(); transcribed_text = result.get("text", "").strip(); logging.info(f"[STT] Whisper: '{transcribed_text[:50]}...'"); return transcribed_text if transcribed_text else None; except requests.exceptions.Timeout as e: logging.warning(f"[STT] Timeout Whisper ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[STT] Erreur requ√™te Whisper ({e}). Retry..."); raise; except Exception as e: logging.error(f"[STT] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None:
    # ... (Impl√©mentation text_to_speech durcie) ...
    api_url = f"{XTTS_SERVER_URL}/generate"; payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}; logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'"); try: response = requests.post(api_url, json=payload, timeout=180); response.raise_for_status(); data = response.json(); audio_base64 = data.get("audio_base64"); if audio_base64: logging.info("[TTS] Audio re√ßu."); return base64.b64decode(audio_base64); else: logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'."); return None; except requests.exceptions.Timeout as e: logging.warning(f"[TTS] Timeout XTTS ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[TTS] Erreur requ√™te XTTS ({e}). Retry..."); raise; except Exception as e: logging.error(f"[TTS] Erreur inattendue: {e}", exc_info=True); return None

# --- Fonction Outil Image Gen (Impl√©ment√©e pour Phase 7 - avec retry/timeout) ---
@retry(stop=stop_after_attempt(2), wait=wait_fixed(5), reraise=True) # Retry 1 fois apr√®s 5s
def generate_image_tool(prompt: str) -> str:
    """Appelle l'API Stable Diffusion pour g√©n√©rer une image, avec retry/timeout."""
    api_url = f"{STABLE_DIFFUSION_API_URL}/sdapi/v1/txt2img"
    # Payload basique - peut √™tre enrichi
    payload = {
        "prompt": prompt,
        "negative_prompt": "ugly, deformed, noisy, blurry, low quality, worst quality, deformed anatomy, bad anatomy, extra limbs, watermark, text, signature, username",
        "steps": 25, "width": 512, "height": 512, "cfg_scale": 7,
        "sampler_name": "DPM++ 2M Karras", "seed": -1
    }
    logging.info(f"[IMG] Appel API SD: {api_url} pour prompt: '{prompt[:50]}...'")
    try:
        response = requests.post(api_url, json=payload, timeout=300) # Timeout long (5 min)
        response.raise_for_status() # V√©rifie les erreurs HTTP (4xx, 5xx)
        data = response.json()

        if "images" in data and data["images"]:
            image_b64 = data["images"][0]
            try:
                image_bytes = base64.b64decode(image_b64)
                timestamp = int(time.time())
                safe_prompt_suffix = "".join(c if c.isalnum() else "_" for c in prompt[:30]).rstrip('_')
                # Assure que le dossier de sortie existe (normalement cr√©√© par Dockerfile)
                IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
                file_path = IMAGE_OUTPUT_DIR / f"generated_{timestamp}_{safe_prompt_suffix}.png"
                # Sauvegarde l'image
                file_path.write_bytes(image_bytes)
                logging.info(f"[IMG] Image SD sauv√©e avec succ√®s: {file_path}")
                # Retourne le chemin relatif depuis /app pour Chainlit
                relative_path = file_path.relative_to(Path("/app")).as_posix()
                # Signal pour process_and_respond pour afficher l'image
                return f"IMAGE_GENEREE:{relative_path}"
            except (base64.B64DecodeError, OSError, Exception) as save_err:
                logging.error(f"[IMG] Erreur d√©codage/sauvegarde image g√©n√©r√©e: {save_err}", exc_info=True)
                # Retourner un message d'erreur clair √† l'agent
                return "Erreur: Impossible de traiter ou sauvegarder l'image g√©n√©r√©e."
        else:
            logging.error(f"[IMG] Pas de cl√© 'images' ou liste vide dans la r√©ponse API SD: {data}")
            return "Erreur: Aucune image n'a √©t√© retourn√©e par le service de g√©n√©ration."

    except requests.exceptions.Timeout as e:
        logging.warning(f"[IMG] Timeout lors de l'appel API SD ({e}). Tenacity va r√©essayer...")
        raise # Relance pour Tenacity
    except requests.exceptions.RequestException as e:
        logging.warning(f"[IMG] Erreur requ√™te API SD ({e}). Tenacity va r√©essayer...")
        raise # Relance pour Tenacity
    except Exception as e:
        # Erreur inattendue (ex: parsing JSON de r√©ponse √©choue)
        logging.error(f"[IMG] Erreur inattendue lors appel API SD (non-retryable): {e}", exc_info=True)
        return f"Erreur inattendue lors de la communication avec le service d'image: {e}"
# --- Fin Fonction Outil Image Gen ---

# Placeholders pour autres outils
def _is_path_safe(requested_path: Path) -> bool: return False
def list_notes_safe() -> str: logging.warning("[NOTES] list_notes_safe non actif."); return "Action d√©sactiv√©e."
def save_note_safe(filename: str, content: str) -> str: logging.warning("[NOTES] save_note_safe non actif."); return "Action d√©sactiv√©e."
def read_note_safe(filename: str) -> str: logging.warning("[NOTES] read_note_safe non actif."); return "Action d√©sactiv√©e."
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e."


# --- Initialisation Globale (inchang√©e) ---
# ... (Code d'init globale embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}


# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat -> Agent avec WebSearch ET ImageGen actifs."""
    logging.info("\n--- Nouvelle Session Chat (Phase 7 v4.2 - Agent + WebSearch + ImgGen) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA non initialis√©s.").send(); return

    try:
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2, request_timeout=300.0)
        logging.info("[Session Start] LLM pour Agent initialis√©.")

        # --- AGENT SETUP : Ajout Outil Image Gen ---
        logging.info("[Session Start] Configuration de l'Agent ReAct...")
        # 1. D√©finir TOUS les outils potentiels
        search_tool = DuckDuckGoSearchRun(name="Recherche Web DuckDuckGo")
        image_tool = Tool(
            name="Generateur Image",
            func=generate_image_tool, # Utilise la fonction impl√©ment√©e ci-dessus
            description="Utile pour cr√©er, dessiner ou g√©n√©rer une image √† partir d'une description textuelle d√©taill√©e (prompt). Utilise cet outil si on demande explicitement de dessiner ou g√©n√©rer une image."
        )
        # Placeholders pour autres outils
        list_notes_tool = Tool( name="Lister Notes", func=list_notes_safe, description="Liste les notes." )
        save_note_tool = Tool( name="Sauvegarder Note", func=save_note_safe, description="Sauve une note." )
        read_note_tool = Tool( name="Lire Note", func=read_note_safe, description="Lit une note." )
        rag_tool = Tool( name="Recherche Document Personnel", func=run_rag_retriever, description="Cherche dans les docs." )

        # 2. S√©lectionner outils ACTIFS pour CETTE phase (Phase 7)
        active_tools = [
            search_tool,
            image_tool  # <<<=== OUTIL IMAGE AJOUT√â ICI
        ]
        logging.info(f"[Session Start] Outils actifs pour l'agent: {[tool.name for tool in active_tools]}")

        # 3. Prompt & Agent ReAct (inchang√©s par rapport √† Phase 6)
        react_prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(llm, active_tools, react_prompt)
        logging.info("[Session Start] Agent ReAct cr√©√©.")

        # 4. AgentExecutor (inchang√© par rapport √† Phase 6, utilise la nouvelle liste `active_tools`)
        agent_executor = AgentExecutor( agent=agent, tools=active_tools, verbose=True, handle_parsing_errors=True, max_iterations=10 )
        cl.user_session.set("agent_executor", agent_executor)
        logging.info("[Session Start] Agent Executor (WebSearch + ImgGen) initialis√©.")
        # --- FIN AGENT SETUP ---

        # Stocker retriever/vector store pour upload (Phase 9)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])

        # Inputs & Upload (inchang√©)
        logging.info("[Session Start] Configuration UI: Inputs Texte/Audio/Upload.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="...", initial=""), cl.AudioInput(id="audio_input", label="...") ] ).send()
        cl.set_config(enable_file_upload=True, file_upload_accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2 avec recherche web et g√©n√©ration d'images).", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Pr√™te (Agent WebSearch + ImgGen) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# process_and_respond (inchang√© depuis Phase 6, g√®re d√©j√† sortie IMAGE_GENEREE:)
# ... (Coller ici la fonction process_and_respond compl√®te de Phase 6 R√©vis√©e v4.2) ...
async def process_and_respond(input_content_sanitized: str): agent_executor = cl.user_session.get("agent_executor"); if not agent_executor: logging.error("[Process] Agent Executor non trouv√©."); await cl.Message(content="Erreur: Agent non initialis√©.").send(); return; msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send(); final_answer_text = ""; image_to_display = None; try: logging.info(f"[Run] Appel Agent Executor: '{input_content_sanitized[:50]}...'"); response = await agent_executor.ainvoke({"input": input_content_sanitized}); final_answer_text = response.get("output", "Pas de r√©ponse pertinente."); logging.info(f"[Run] R√©ponse brute Agent: '{final_answer_text[:100]}...'"); if isinstance(final_answer_text, str) and final_answer_text.startswith("IMAGE_GENEREE:"): try: relative_image_path = final_answer_text.split(":", 1)[1]; image_path_in_container = Path("/app") / relative_image_path; if image_path_in_container.is_file(): image_to_display = cl.Image(path=str(image_path_in_container), name=os.path.basename(relative_image_path), display="inline"); final_answer_text = f"Voici l'image demand√©e."; logging.info(f"[Run] Image d√©tect√©e: {relative_image_path}"); else: logging.error(f"[Run] Fichier image non trouv√©: {image_path_in_container}"); final_answer_text += " (Erreur: fichier introuvable)"; except Exception as img_err: logging.error(f"[Run] Erreur pr√©pa image: {img_err}", exc_info=True); final_answer_text += " (Erreur affichage)"; await msg.update(content=final_answer_text); logging.info(f"[Run] R√©ponse Agent affich√©e: '{final_answer_text[:100]}...'"); if image_to_display: await cl.Message(content="", elements=[image_to_display], author="Image G√©n√©r√©e").send(); logging.info("[Run] G√©n√©ration audio XTTS..."); try: audio_bytes = text_to_speech(final_answer_text); if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©."); else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as tts_err: logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as e: error_message = f"ERREUR agent execution: {e}"; logging.error(f"[Run] {error_message}", exc_info=True); await msg.update(content="D√©sol√©, erreur interne pendant la r√©flexion.", author="Erreur Syst√®me"); logging.info("--- Fin Traitement Input ---")


# on_message (inchang√©)
@cl.on_message
async def on_text_message(message: cl.Message):
    # ... (Coller code on_message de Phase 6 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Msg Texte UI ---"); logging.info(f"Input brut: '{message.content[:60]}...'"); try: sanitized_input = sanitize_input(message.content); logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'"); await process_and_respond(sanitized_input); except Exception as e: logging.error(f"Erreur sanitization/traitement message texte: {e}", exc_info=True); await cl.Message(content="Erreur interne traitement message.").send()

# on_audio_end (inchang√©)
@cl.on_audio_end
async def on_audio_end(audio: cl.Audio):
    # ... (Coller code on_audio_end de Phase 6 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Audio Re√ßu ---"); logging.info(f"Taille: {len(audio.content)} bytes, mime: {audio.mime}"); transcript_msg = cl.Message(content="*Transcription...*", author="Syst√®me", disable_feedback=True); await transcript_msg.send(); transcribed_text_sanitized = None; try: transcribed_text_raw = transcribe_audio(audio.content); if transcribed_text_raw is not None: transcribed_text_sanitized = sanitize_input(transcribed_text_raw); logging.info(f"Texte transcrit (Sanitized): '{transcribed_text_sanitized[:60]}...'"); await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text_sanitized}\""); await process_and_respond(transcribed_text_sanitized); else: logging.warning("[STT] Transcription vide/None."); await transcript_msg.update(content="Pas de son d√©tect√© ou transcription vide."); except Exception as e: logging.error(f"[STT] √âchec final transcription/sanitization: {e}", exc_info=True); await transcript_msg.update(content="√âchec transcription apr√®s tentatives.") ; logging.info("--- Fin Traitement Audio ---")


# on_file_upload (inchang√© - logique Phase 9+)
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)
async def on_file_upload(files: list[cl.File]):
    # ... (Coller code on_file_upload de Phase 6 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Fichiers Re√ßus (Logique Upload Phase 9+ non active) ---"); if not files: return; await cl.Message(content=f"R√©ception de {len(files)} fichier(s). Traitement RAG non impl√©ment√© dans cette phase.").send()

```

* **Action :** Sauvegardez le fichier `app.py`.

---

### √âtape 7.4 : Red√©marrer l'Environnement avec le Service d'Image

* **Explication :** Arr√™t et red√©marrage pour prendre en compte le nouveau service `stable_diffusion_webui` et l'activation de son outil dans l'agent `assistant_app`.
* **Action :** Terminal dans `assistant-core` :
    ```bash
    docker compose down
    ```
* **Action :** Reconstruire `assistant_app` (car `app.py` a chang√©) et d√©marrer tous les services (6 services maintenant) :
    ```bash
    docker compose up -d --build
    ```
* **Attente :** T√©l√©chargement image SD (si non locale) et **d√©marrage initial de `stable_diffusion_webui` peuvent √™tre longs** (plusieurs minutes, le temps qu'il devienne `(healthy)`). Surveillez `docker ps` et `docker logs stable_diffusion_webui`.

---

### √âtape 7.5 : Tester la G√©n√©ration d'Images

* **Action :** V√©rifiez les 6 conteneurs (`docker ps`). Ils doivent tous √™tre `Up` et `(healthy)`.
* **Action :** Ouvrez Chainlit (`http://127.0.0.1:8001`).
* **Action :** Ouvrez aussi l'UI Web de Stable Diffusion (`http://127.0.0.1:7860`) ET **v√©rifiez l'API sur `http://127.0.0.1:7860/docs`**. Vous devriez voir une page Swagger/OpenAPI (cela confirme que `--api` est actif).
* **Action :** **NE PAS OUBLIER : Ajoutez un mod√®le `.safetensors` via l'√âtape 7.6 ci-dessous.** Sans mod√®le, la g√©n√©ration √©chouera.
* **Action :** Testez dans Chainlit (texte ou voix) : "Dessine un chat astronaute sur la lune".
* **R√©sultat Attendu :**
    1.  Logs `assistant_app` montrent l'agent choisissant et appelant l'outil `Generateur Image`.
    2.  Logs `stable_diffusion_webui` montrent la g√©n√©ration en cours (%).
    3.  Chainlit affiche "Voici l'image.", puis l'image g√©n√©r√©e (peut prendre du temps), et la r√©ponse audio.
* **Test Autres Outils :** V√©rifiez que la recherche web (Phase 6) fonctionne toujours ("M√©t√©o √† √âpinay-sur-Seine ?").
* **En Cas de Probl√®me :**
    * **Conteneur `stable_diffusion_webui` KO (`Exited` / `Restarting` / `unhealthy`) :** Logs `stable_diffusion_webui`. Cause probable : **Manque VRAM** (commentez `deploy:` GPU de XTTS/Whisper et `docker compose up -d`), ou erreur `CLI_ARGS`.
    * **Agent n'utilise pas `Generateur Image` :** Logs `assistant_app` (`verbose=True`) -> "Thought". Description outil claire ? Prompt explicite ("Dessine...") ?
    * **Agent utilise l'outil, mais Erreur / Pas d'image :**
        1.  Logs `assistant_app` : Erreur dans `generate_image_tool` (`[ERREUR] Appel API SD`, `[ERREUR] Pas d'image`, `[ERREUR] Sauvegarde image` ?) Timeout apr√®s retry ?
        2.  Logs `stable_diffusion_webui` : Re√ßoit requ√™te ? Erreur CUDA OOM ? **Erreur chargement mod√®le (manquant? √âtape 7.6 faite ? Mod√®le s√©lectionn√© dans UI SD ?) ?**
        3.  V√©rifiez API via `http://127.0.0.1:7860/docs`.
    * **Image non affich√©e ("fichier introuvable") :** Logs `assistant_app` (`[ERREUR] Fichier image non trouv√©`). Chemin correct ? Droits √©criture pour `appuser` dans `/app/generated_images` (devrait √™tre OK via Dockerfile) ?

---

### √âtape 7.6 : Ajouter les Mod√®les Stable Diffusion (Action Manuelle Essentielle)

* **Explication :** Le service SD a besoin d'au moins un mod√®le de checkpoint (`.safetensors`) pour fonctionner. Vous devez le t√©l√©charger et le copier dans le volume Docker appropri√© (`khaldounia_sd_models`).
* **Action 1 : Trouver/T√©l√©charger Mod√®le :** Sur Civitai ou Hugging Face, t√©l√©chargez un mod√®le `.safetensors` (ex: `dreamshaper_8.safetensors`, `realisticVisionV60B1_v60B1VAE.safetensors`) sur votre PC Windows.
* **Action 2 : Copier Mod√®le dans Volume Docker via `docker cp`:**
    * Le volume `khaldounia_sd_models` est mont√© sur `/config/stable-diffusion` dans le conteneur. Les checkpoints vont dans le sous-dossier `Stable-diffusion`.
    * **Ouvrez un terminal WSL** et utilisez `docker cp` (adaptez les chemins !) :
        ```bash
        # Exemple si votre mod√®le est dans T√©l√©chargements sous Windows :
        docker cp "/mnt/c/Users/VOTRE_USER_WINDOWS/Downloads/nom_du_modele.safetensors" stable_diffusion_webui:/config/stable-diffusion/Stable-diffusion/
        ```
* **Action 3 : V√©rifier/Red√©marrer (Recommand√©) :**
    * Allez sur l'UI Web `http://127.0.0.1:7860`. Le nouveau mod√®le doit appara√Ætre dans la liste d√©roulante "Stable Diffusion checkpoint" (cliquez sur l'ic√¥ne de rafra√Æchissement üîÑ √† c√¥t√© si besoin). **S√©lectionnez-le.**
    * Pour √™tre s√ªr, vous pouvez red√©marrer juste le service SD :
        ```bash
        docker compose restart stable_diffusion_webui
        ```
* **Note :** L'API SD utilisera le mod√®le **actuellement s√©lectionn√©** dans l'UI Web A1111. Assurez-vous qu'un mod√®le est charg√© et s√©lectionn√©.

---

### **√âtape 7.7: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** Agent avec Web/Img fonctionnel. Sauvegarde avant les actions syst√®me.
* **M√©thode 1 : Copie Simple**
    * `docker compose down`
    * `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase7`
    * `docker compose up -d`
* **M√©thode 2 : Commit Git**
    * `git add .`
    * `git commit -m "Fin de la Phase 7 (v4.2) - Agent avec WebSearch/ImgGen fonctionnel (base durcie)"`

---

Fin de la Phase 7 (R√©vis√©e v4.2).
```

```markdown
---


## Phase 8 : Ajout Actions Syst√®me (Agent - Outils Notes - R√©vis√©e v4.2)

**Objectif :** Permettre √† l'agent d'interagir avec le syst√®me de fichiers de mani√®re **limit√©e et s√©curis√©e**, en activant les outils pour lister, sauvegarder et lire des fichiers texte simples dans le dossier d√©di√© `/app/user_notes`. Les fonctions associ√©es sont impl√©ment√©es avec des v√©rifications de s√©curit√©.

**AVERTISSEMENT S√âCURIT√â :** Les actions sont restreintes au dossier `SAFE_NOTES_DIR` via `_is_path_safe`. Ne pas modifier cette logique ou ajouter des outils plus permissifs sans expertise.

**Pr√©requis :** Phase 7 termin√©e et id√©alement sauvegard√©e. Agent avec WebSearch et ImgGen fonctionnel sur base durcie (v4.2).

**Approche :** Mise √† jour de `app.py` pour impl√©menter les fonctions `_is_path_safe`, `list_notes_safe`, `save_note_safe`, `read_note_safe`. Ajout des `Tool` correspondants √† la liste `active_tools` de l'Agent Executor dans `@cl.on_chat_start`.

---

### √âtape 8.1 : V√©rifier le Fichier `requirements.txt`

* **Explication :** Aucun changement requis. Les interactions se font via `pathlib` (int√©gr√© √† Python).
* **Action :** V√©rifiez `requirements.txt` dans `assistant-core/app`.

---

### √âtape 8.2 : Mettre √† jour le Fichier `app.py` (Activation Outils Syst√®me)

* **Explication :** Impl√©mentation compl√®te des fonctions de gestion de notes avec s√©curit√© (`_is_path_safe`) et ajout des outils correspondants (`list_notes_tool`, `save_note_tool`, `read_note_tool`) √† la liste `active_tools` de l'agent dans `@cl.on_chat_start`. Les descriptions des outils sont cruciales pour guider l'agent.
* **Action :** Ouvrez `app.py` dans `~/projet-khaldounia/assistant-core/app/`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (R√©vis√© v4.2 pour Phase 8 - Activation Outils Syst√®me)
# R√¥le: Application Khaldounia (Agent + WebSearch + ImgGen + SysActions - Robuste)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain
logging.info("--- D√©but Importation Langchain (Phase 8 Rev 4.2) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# ... (Autres imports) ...
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale (inchang√©e) ---
# ... (coller la config globale inchang√©e) ...
logging.info("--- D√©but Chargement Configuration ---"); OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434"); XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020"); CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb"); CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000"); WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000"); STABLE_DIFFUSION_API_URL = os.getenv("STABLE_DIFFUSION_API_URL", "http://stable_diffusion_webui:7860"); OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest"); EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"; EMBEDDING_CACHE_DIR = Path("/app/embedding_cache"); SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads"); SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True); logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}, SD@{STABLE_DIFFUSION_API_URL}"); logging.info("--- Fin Chargement Configuration ---")


# --- Fonctions Utilitaires (Durcies) ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None:
    # ... (Impl√©mentation transcribe_audio durcie) ...
    api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"; files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}; logging.info(f"[STT] Appel API Whisper: {api_url}"); try: response = requests.post(api_url, files=files, timeout=60); response.raise_for_status(); result = response.json(); transcribed_text = result.get("text", "").strip(); logging.info(f"[STT] Whisper: '{transcribed_text[:50]}...'"); return transcribed_text if transcribed_text else None; except requests.exceptions.Timeout as e: logging.warning(f"[STT] Timeout Whisper ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[STT] Erreur requ√™te Whisper ({e}). Retry..."); raise; except Exception as e: logging.error(f"[STT] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None:
    # ... (Impl√©mentation text_to_speech durcie) ...
    api_url = f"{XTTS_SERVER_URL}/generate"; payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}; logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'"); try: response = requests.post(api_url, json=payload, timeout=180); response.raise_for_status(); data = response.json(); audio_base64 = data.get("audio_base64"); if audio_base64: logging.info("[TTS] Audio re√ßu."); return base64.b64decode(audio_base64); else: logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'."); return None; except requests.exceptions.Timeout as e: logging.warning(f"[TTS] Timeout XTTS ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[TTS] Erreur requ√™te XTTS ({e}). Retry..."); raise; except Exception as e: logging.error(f"[TTS] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(2), wait=wait_fixed(5), reraise=True)
def generate_image_tool(prompt: str) -> str:
    # ... (Impl√©mentation generate_image_tool durcie de Phase 7) ...
    api_url = f"{STABLE_DIFFUSION_API_URL}/sdapi/v1/txt2img"; payload = {"prompt": prompt, "negative_prompt": "ugly...", "steps": 25, "width": 512, "height": 512, ...}; logging.info(f"[IMG] Appel API SD: '{prompt[:50]}...'"); try: response = requests.post(api_url, json=payload, timeout=300); response.raise_for_status(); data = response.json(); if "images" in data and data["images"]: image_b64 = data["images"][0]; try: image_bytes = base64.b64decode(image_b64); timestamp = int(time.time()); safe_prompt_suffix = "".join(c if c.isalnum() else "_" for c in prompt[:30]).rstrip('_'); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); file_path = IMAGE_OUTPUT_DIR / f"generated_{timestamp}_{safe_prompt_suffix}.png"; file_path.write_bytes(image_bytes); logging.info(f"[IMG] Image SD sauv√©e: {file_path}"); relative_path = file_path.relative_to(Path("/app")).as_posix(); return f"IMAGE_GENEREE:{relative_path}"; except Exception as save_err: logging.error(f"[IMG] Erreur d√©codage/sauvegarde image: {save_err}", exc_info=True); return "Erreur: Impossible de sauvegarder image g√©n√©r√©e."; else: logging.error(f"[IMG] Pas d'image dans r√©ponse API SD: {data}"); return "Erreur: Aucune image retourn√©e."; except requests.exceptions.Timeout as e: logging.warning(f"[IMG] Timeout SD ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[IMG] Erreur requ√™te SD ({e}). Retry..."); raise; except Exception as e: logging.error(f"[IMG] Erreur inattendue API SD: {e}", exc_info=True); return f"Erreur inattendue service image: {e}"


# --- Fonctions Outils Notes (Impl√©ment√©es pour Phase 8) ---
def _is_path_safe(requested_path_str: str) -> Path | None:
    """V√©rifie si le nom de fichier est simple et r√©sout dans SAFE_NOTES_DIR.
       Retourne le chemin absolu s√©curis√© si OK, sinon None."""
    try:
        # V√©rification basique caract√®res invalides/dangereux et chemin relatif simple
        if not requested_path_str or "/" in requested_path_str or "\\" in requested_path_str or ".." in requested_path_str:
             logging.warning(f"[_is_path_safe] Tentative d'utilisation de nom de fichier invalide/chemin complexe: '{requested_path_str}'")
             return None

        target_path_relative = Path(requested_path_str)
        # Double-v√©rifie que c'est juste un nom de fichier (pas un chemin)
        if target_path_relative.parent != Path('.'):
             logging.warning(f"[_is_path_safe] Tentative d'utilisation de sous-dossier non autoris√©: '{requested_path_str}'")
             return None

        safe_dir_abs = SAFE_NOTES_DIR.resolve(strict=True) # Assure que SAFE_NOTES_DIR existe
        requested_path_abs = (safe_dir_abs / target_path_relative).resolve(strict=False) # R√©sout chemin complet demand√©

        # V√©rifie si le chemin r√©solu est DANS ou est √âGAL au dossier s√©curis√©
        # Et qu'il ne remonte pas (double s√©curit√© avec is_relative_to)
        if requested_path_abs == safe_dir_abs or requested_path_abs.is_relative_to(safe_dir_abs):
             # Exclut le dossier lui-m√™me, on veut seulement les fichiers dedans
             if requested_path_abs != safe_dir_abs:
                 return requested_path_abs # Retourne le chemin absolu et s√©curis√© du fichier potentiel
        logging.warning(f"[_is_path_safe] Chemin r√©solu hors limites: '{requested_path_abs}' vs '{safe_dir_abs}'")
        return None
    except FileNotFoundError:
        logging.error(f"[_is_path_safe] Dossier de notes s√©curis√© introuvable: {SAFE_NOTES_DIR}")
        return None
    except Exception as e:
        logging.error(f"[_is_path_safe] Erreur validation chemin pour '{requested_path_str}': {e}", exc_info=True)
        return None # S√©curit√© par d√©faut

def list_notes_safe() -> str:
    """Liste les fichiers de notes dans le dossier s√©curis√©."""
    logging.info(f"[NOTES] Action: Lister notes dans {SAFE_NOTES_DIR}")
    try:
        # Cr√©e le dossier s'il n'existe pas (devrait √™tre fait par Dockerfile mais s√©curit√©)
        SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True)
        files = [f.name for f in SAFE_NOTES_DIR.iterdir() if f.is_file()]
        return "Notes personnelles existantes:\n- " + "\n- ".join(files) if files else "Le dossier des notes personnelles est vide."
    except Exception as e: # Large car l'it√©ration peut √©chouer pour diverses raisons (perms...)
        logging.error(f"[NOTES] Erreur list_notes: {e}", exc_info=True)
        return f"Erreur inattendue lors du listage des notes: {e}"

def save_note_safe(filename: str, content: str) -> str:
    """Sauvegarde le contenu dans un fichier note, apr√®s validation du chemin."""
    logging.info(f"[NOTES] Action: Tentative de sauvegarde note '{filename}'")
    safe_full_path = _is_path_safe(filename)

    if safe_full_path is None:
        # _is_path_safe logue d√©j√† l'avertissement de s√©curit√©
        return "Erreur de s√©curit√©: Le nom de fichier sp√©cifi√© est invalide ou non autoris√©."
    try:
        # S'assure que le dossier parent existe (s√©curit√©)
        safe_full_path.parent.mkdir(parents=True, exist_ok=True)
        # √âcrit le fichier
        safe_full_path.write_text(content, encoding='utf-8')
        logging.info(f"[NOTES] Note sauv√©e avec succ√®s: {safe_full_path}")
        return f"Note '{filename}' sauv√©e avec succ√®s."
    except OSError as e:
         logging.error(f"[NOTES] Erreur OS lors sauvegarde '{filename}': {e}", exc_info=True)
         return f"Erreur syst√®me lors de la sauvegarde de la note '{filename}': {e}"
    except Exception as e:
        logging.error(f"[NOTES] Erreur inattendue sauvegarde '{filename}': {e}", exc_info=True)
        return f"Erreur inattendue lors de la sauvegarde de la note '{filename}': {e}"

def read_note_safe(filename: str) -> str:
    """Lit le contenu d'un fichier note, apr√®s validation du chemin."""
    logging.info(f"[NOTES] Action: Tentative de lecture note '{filename}'")
    safe_full_path = _is_path_safe(filename)

    if safe_full_path is None:
        return "Erreur de s√©curit√©: Le nom de fichier sp√©cifi√© est invalide ou non autoris√©."

    if not safe_full_path.is_file():
        logging.warning(f"[NOTES] Tentative lecture fichier note inexistant: '{filename}' ({safe_full_path})")
        return f"Erreur: Le fichier note '{filename}' n'existe pas."
    try:
        content = safe_full_path.read_text(encoding='utf-8')
        logging.info(f"[NOTES] Note lue avec succ√®s: {safe_full_path}")
        # Limite la taille retourn√©e pour √©viter d'envoyer des fichiers √©normes ? Non, l'agent doit pouvoir lire.
        return f"Contenu de la note '{filename}':\n\n{content}"
    except OSError as e:
         logging.error(f"[NOTES] Erreur OS lors lecture '{filename}': {e}", exc_info=True)
         return f"Erreur syst√®me lors de la lecture de la note '{filename}': {e}"
    except Exception as e:
        logging.error(f"[NOTES] Erreur inattendue lecture '{filename}': {e}", exc_info=True)
        return f"Erreur inattendue lors de la lecture de la note '{filename}': {e}"
# --- Fin Fonctions Outils Notes ---

# Placeholder outil RAG
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e."


# --- Initialisation Globale (inchang√©e) ---
# ... (Code d'init globale embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}


# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat -> Agent avec WebSearch, ImgGen ET SysActions actifs."""
    logging.info("\n--- Nouvelle Session Chat (Phase 8 v4.2 - Agent + Web/Img/Sys Actifs) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA non initialis√©s.").send(); return

    try:
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2, request_timeout=300.0)
        logging.info("[Session Start] LLM pour Agent initialis√©.")

        # --- AGENT SETUP : Activation des Outils Syst√®me ---
        logging.info("[Session Start] Configuration de l'Agent ReAct...")
        # 1. D√©finir TOUS les outils potentiels
        search_tool = DuckDuckGoSearchRun(name="Recherche Web DuckDuckGo")
        image_tool = Tool( name="Generateur Image", func=generate_image_tool, description="Cr√©√© une image √† partir d'une description." )
        list_notes_tool = Tool(
            name="Lister Notes Personnelles", # Nom plus pr√©cis
            func=list_notes_safe,
            description="Utilise cet outil pour obtenir la liste des fichiers de notes personnelles existants dans le dossier s√©curis√©."
            )
        save_note_tool = Tool(
            name="Sauvegarder Note Personnelle", # Nom plus pr√©cis
            func=save_note_safe,
            # Description pr√©cise pour aider l'agent √† formater l'input (m√™me si fragile)
            description="Utilise cet outil pour sauvegarder ou mettre √† jour du texte dans une note personnelle. L'entr√©e DOIT √™tre une cha√Æne contenant uniquement le nom de fichier simple (ex: 'ma_note.txt') suivi d'une virgule, puis du contenu complet √† sauvegarder."
            )
        read_note_tool = Tool(
            name="Lire Note Personnelle", # Nom plus pr√©cis
            func=read_note_safe,
            description="Utilise cet outil pour lire le contenu complet d'un fichier note personnelle existant. L'entr√©e DOIT √™tre juste le nom exact et simple du fichier (ex: 'ma_note.txt')."
            )
        rag_tool = Tool( name="Recherche Document Personnel", func=run_rag_retriever, description="Cherche dans les docs." ) # Sera activ√© en Phase 10

        # 2. S√©lectionner outils ACTIFS pour CETTE phase (Phase 8)
        active_tools = [
            search_tool,
            image_tool,
            list_notes_tool, # <<< ACTIV√â
            save_note_tool,  # <<< ACTIV√â
            read_note_tool   # <<< ACTIV√â
            # rag_tool # Pas encore actif
        ]
        logging.info(f"[Session Start] Outils actifs pour l'agent ({len(active_tools)}): {[tool.name for tool in active_tools]}")

        # 3. Prompt & Agent ReAct (inchang√©s)
        react_prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(llm, active_tools, react_prompt)
        logging.info("[Session Start] Agent ReAct cr√©√©.")

        # 4. AgentExecutor (inchang√©, utilise la nouvelle liste `active_tools`)
        agent_executor = AgentExecutor( agent=agent, tools=active_tools, verbose=True, handle_parsing_errors=True, max_iterations=10 )
        cl.user_session.set("agent_executor", agent_executor)
        logging.info(f"[Session Start] Agent Executor ({len(active_tools)} outils actifs) initialis√©.")
        # --- FIN AGENT SETUP ---

        # Stocker retriever/vector store pour upload (Phase 9)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])

        # Inputs & Upload (inchang√©)
        logging.info("[Session Start] Configuration UI: Inputs Texte/Audio/Upload.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="...", initial=""), cl.AudioInput(id="audio_input", label="...") ] ).send()
        cl.set_config(enable_file_upload=True, file_upload_accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2 avec recherche, image, et actions syst√®me/notes).", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Pr√™te (Agent Web/Img/Sys) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# process_and_respond (inchang√© - utilise l'agent executor avec la nouvelle liste d'outils)
# ... (Coller ici la fonction process_and_respond compl√®te de Phase 7 R√©vis√©e v4.2) ...
async def process_and_respond(input_content_sanitized: str): agent_executor = cl.user_session.get("agent_executor"); if not agent_executor: logging.error("[Process] Agent Executor non trouv√©."); await cl.Message(content="Erreur: Agent non initialis√©.").send(); return; msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send(); final_answer_text = ""; image_to_display = None; try: logging.info(f"[Run] Appel Agent Executor: '{input_content_sanitized[:50]}...'"); response = await agent_executor.ainvoke({"input": input_content_sanitized}); final_answer_text = response.get("output", "Pas de r√©ponse pertinente."); logging.info(f"[Run] R√©ponse brute Agent: '{final_answer_text[:100]}...'"); if isinstance(final_answer_text, str) and final_answer_text.startswith("IMAGE_GENEREE:"): try: relative_image_path = final_answer_text.split(":", 1)[1]; image_path_in_container = Path("/app") / relative_image_path; if image_path_in_container.is_file(): image_to_display = cl.Image(path=str(image_path_in_container), name=os.path.basename(relative_image_path), display="inline"); final_answer_text = f"Voici l'image demand√©e."; logging.info(f"[Run] Image d√©tect√©e: {relative_image_path}"); else: logging.error(f"[Run] Fichier image non trouv√©: {image_path_in_container}"); final_answer_text += " (Erreur: fichier introuvable)"; except Exception as img_err: logging.error(f"[Run] Erreur pr√©pa image: {img_err}", exc_info=True); final_answer_text += " (Erreur affichage)"; await msg.update(content=final_answer_text); logging.info(f"[Run] R√©ponse Agent affich√©e: '{final_answer_text[:100]}...'"); if image_to_display: await cl.Message(content="", elements=[image_to_display], author="Image G√©n√©r√©e").send(); logging.info("[Run] G√©n√©ration audio XTTS..."); try: audio_bytes = text_to_speech(final_answer_text); if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©."); else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as tts_err: logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as e: error_message = f"ERREUR agent execution: {e}"; logging.error(f"[Run] {error_message}", exc_info=True); await msg.update(content="D√©sol√©, erreur interne pendant la r√©flexion.", author="Erreur Syst√®me"); logging.info("--- Fin Traitement Input ---")


# on_message (inchang√©)
@cl.on_message
async def on_text_message(message: cl.Message):
    # ... (Coller code on_message de Phase 7 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Msg Texte UI ---"); logging.info(f"Input brut: '{message.content[:60]}...'"); try: sanitized_input = sanitize_input(message.content); logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'"); await process_and_respond(sanitized_input); except Exception as e: logging.error(f"Erreur sanitization/traitement message texte: {e}", exc_info=True); await cl.Message(content="Erreur interne traitement message.").send()

# on_audio_end (inchang√©)
@cl.on_audio_end
async def on_audio_end(audio: cl.Audio):
    # ... (Coller code on_audio_end de Phase 7 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Audio Re√ßu ---"); logging.info(f"Taille: {len(audio.content)} bytes, mime: {audio.mime}"); transcript_msg = cl.Message(content="*Transcription...*", author="Syst√®me", disable_feedback=True); await transcript_msg.send(); transcribed_text_sanitized = None; try: transcribed_text_raw = transcribe_audio(audio.content); if transcribed_text_raw is not None: transcribed_text_sanitized = sanitize_input(transcribed_text_raw); logging.info(f"Texte transcrit (Sanitized): '{transcribed_text_sanitized[:60]}...'"); await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text_sanitized}\""); await process_and_respond(transcribed_text_sanitized); else: logging.warning("[STT] Transcription vide/None."); await transcript_msg.update(content="Pas de son d√©tect√© ou transcription vide."); except Exception as e: logging.error(f"[STT] √âchec final transcription/sanitization: {e}", exc_info=True); await transcript_msg.update(content="√âchec transcription apr√®s tentatives.") ; logging.info("--- Fin Traitement Audio ---")


# on_file_upload (inchang√© - logique Phase 9+)
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)
async def on_file_upload(files: list[cl.File]):
    # ... (Coller code on_file_upload de Phase 7 R√©vis√©e v4.2) ...
    logging.info(f"\n--- Fichiers Re√ßus (Logique Upload Phase 9+ non active) ---"); if not files: return; await cl.Message(content=f"R√©ception de {len(files)} fichier(s). Traitement RAG non impl√©ment√© dans cette phase.").send()

```

* **Action :** Sauvegardez le fichier `app.py`.

---

### √âtape 8.3 : Red√©marrer l'Environnement avec les Outils Syst√®me Actifs

* **Explication :** Arr√™t et red√©marrage pour que `assistant_app` utilise le nouveau code `app.py` o√π l'Agent Executor a maintenant acc√®s aux outils de gestion des notes.
* **Action :** Terminal dans `assistant-core` :
    ```bash
    docker compose down
    ```
* **Action :** Reconstruire `assistant_app` et d√©marrer tous les services (toujours 6 services) :
    ```bash
    docker compose up -d --build
    ```

---

### √âtape 8.4 : Tester les Actions Syst√®me

* **Action :** V√©rifiez les 6 conteneurs (`docker ps`) -> `Up` et `(healthy)`.
* **Action :** Ouvrez/Actualisez Chainlit (`http://127.0.0.1:8001`).
* **Test 1 (Liste Initialement Vide) :** Demandez : "Liste mes notes personnelles".
    * *(R√©sultat Attendu : R√©ponse "Dossier notes vide.")*
* **Test 2 (Sauvegarde) :** Demandez : "Sauvegarde une note personnelle nomm√©e `courses.txt` avec le contenu : Lait, Oeufs, Pain".
    * *(R√©sultat Attendu : Logs agent montrent appel √† `Sauvegarder Note Personnelle` avec `filename='courses.txt'` et le contenu. R√©ponse "Note 'courses.txt' sauv√©e...")*
* **Test 3 (Liste apr√®s Sauvegarde) :** Demandez : "Quelles sont mes notes personnelles ?".
    * *(R√©sultat Attendu : R√©ponse "Notes:\n- courses.txt")*
* **Test 4 (Lecture) :** Demandez : "Lis ma note personnelle `courses.txt`".
    * *(R√©sultat Attendu : Logs agent montrent appel √† `Lire Note Personnelle` avec `filename='courses.txt'`. R√©ponse "Contenu de la note 'courses.txt':\n\nLait, Oeufs, Pain")*
* **Test 5 (S√©curit√© - √âchec Attendu) :** Demandez : "Lis le fichier `../app.py`" ou "Sauvegarde une note dans `/etc/passwd` avec le contenu : test".
    * *(R√©sultat Attendu : Logs agent montrent appel √† l'outil mais `_is_path_safe` renvoie `None`. R√©ponse agent indiquant "Erreur de s√©curit√©: nom de fichier invalide...")*
* **En Cas de Probl√®me :**
    * **Agent n'utilise pas le bon outil notes :** Logs `assistant_app` (`verbose=True`) -> "Thought". Descriptions outils claires ?
    * **Agent utilise outil notes mais Erreur / √âchec :** Logs `assistant_app` : Erreur dans `list/save/read_note_safe` (`[ERREUR] Notes...`) ? Erreur S√©curit√© attendue (Test 5) ? Erreur Permissions sur `/app/user_notes` (v√©rifier droits `appuser` via `docker exec -it assistant_app ls -ld /app/user_notes`) ? Agent a mal format√© input (ex: pour `save_note`) ? Fichier non trouv√© pour `read_note` ?

---

### √âtape 8.5 : Note Importante sur la S√©curit√© (V√©rification Documentation)

* **Action :** Assurez-vous que cette note est pr√©sente.

> #### **Note Cruciale sur la S√©curit√© des Actions Syst√®me**
> Les outils sont volontairement limit√©s au dossier `/app/user_notes` via la validation `_is_path_safe`. Ne modifiez pas cette fonction. N'ajoutez pas d'outils ex√©cutant des commandes syst√®me arbitraires sans m√©canismes de s√©curit√© robustes.

---

### **√âtape 8.6: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** Agent avec Web/Img/Sys fonctionnel. Sauvegarde avant tests RAG.
* **M√©thode 1 : Copie Simple**
    * `docker compose down`
    * `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase8`
    * `docker compose up -d`
* **M√©thode 2 : Commit Git**
    * `git add .`
    * `git commit -m "Fin de la Phase 8 (v4.2) - Agent avec Web/Img/Sys fonctionnel (base durcie)"`

---

Fin de la Phase 8 (R√©vis√©e v4.2).



```markdown
---

## Phase 9 : Chargement et Test des Donn√©es pour RAG (R√©vis√©e v4.2)

**Objectif :** Impl√©menter la logique d'upload de fichiers dans `app.py` et tester l'ajout de documents personnels (PDF, TXT, DOCX) √† la base de donn√©es vectorielle ChromaDB via l'interface Chainlit. V√©rifier (indirectement) la capacit√© de r√©cup√©ration d'informations via l'observation des logs.

**Pr√©requis :** Phase 8 termin√©e et id√©alement sauvegard√©e. Agent avec outils Web/Img/Sys fonctionnel sur base durcie (v4.2).

**Approche :** Ajout de l'impl√©mentation du gestionnaire `@cl.on_file_upload` dans `app.py` pour g√©rer le chargement, le d√©coupage (splitting) et l'indexation des documents dans ChromaDB via Langchain. Upload de fichiers tests via l'UI, observation des logs, puis test en posant des questions sp√©cifiques pour voir si le contexte est r√©cup√©r√© (m√™me si l'agent ne l'utilise pas encore activement).

---

### √âtape 9.1 : Pr√©parer des Documents de Test

* **Action (Manuelle) :** Sur votre PC Windows, cr√©ez ou pr√©parez 1 ou 2 fichiers simples contenant des informations uniques et facilement identifiables.
    * **Exemple 1 (`infos_khaldounia.txt`) :** Fichier `.txt` : "L'assistant Khaldounia utilise le mod√®le d'embedding all-MiniLM-L6-v2."
    * **Exemple 2 (`reunion_projet_aladin.docx`) :** Document Word court mentionnant le "projet Aladin" et une date fictive.
    * **Formats Support√©s (par d√©faut) :** `.txt`, `.pdf`, `.docx`. D'autres formats *peuvent* fonctionner via `unstructured` si les d√©pendances syst√®me n√©cessaires sont dans le `Dockerfile`.

---

### √âtape 9.2 : Mettre √† jour le Fichier `app.py` (Impl√©mentation Upload RAG)

* **Explication :** Ajout de l'impl√©mentation de la fonction d√©cor√©e par `@cl.on_file_upload`. Cette fonction g√®re la r√©ception des fichiers, leur sauvegarde temporaire, le chargement de leur contenu, le d√©coupage en chunks, et l'ajout √† ChromaDB. Utilise `cl.make_async` pour les op√©rations potentiellement longues afin de ne pas bloquer l'interface.
* **Action :** Ouvrez `app.py` dans `~/projet-khaldounia/assistant-core/app/`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par :

```python
# Fichier: app.py (R√©vis√© v4.2 pour Phase 9 - Impl√©mentation Upload RAG)
# R√¥le: Application Khaldounia (Agent Web/Img/Sys + Logique Upload RAG)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain (Ajout Loaders/Splitter)
logging.info("--- D√©but Importation Langchain (Phase 9 Rev 4.2) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
# --- Ajout pour RAG Upload ---
from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
# --- Fin Ajout RAG Upload ---
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale (inchang√©e) ---
# ... (coller la config globale inchang√©e) ...
logging.info("--- D√©but Chargement Configuration ---"); OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434"); XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020"); CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb"); CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000"); WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000"); STABLE_DIFFUSION_API_URL = os.getenv("STABLE_DIFFUSION_API_URL", "http://stable_diffusion_webui:7860"); OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest"); EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"; EMBEDDING_CACHE_DIR = Path("/app/embedding_cache"); SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads"); SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True); logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}, SD@{STABLE_DIFFUSION_API_URL}"); logging.info("--- Fin Chargement Configuration ---")


# --- Fonctions Utilitaires (Durcies) ---
# ... (Coller ici les fonctions transcribe_audio, text_to_speech, generate_image_tool, _is_path_safe, list_notes_safe, save_note_safe, read_note_safe de Phase 8 v4.2) ...
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None: api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"; files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}; logging.info(f"[STT] Appel API Whisper: {api_url}"); try: response = requests.post(api_url, files=files, timeout=60); response.raise_for_status(); result = response.json(); transcribed_text = result.get("text", "").strip(); logging.info(f"[STT] Whisper: '{transcribed_text[:50]}...'"); return transcribed_text if transcribed_text else None; except requests.exceptions.Timeout as e: logging.warning(f"[STT] Timeout Whisper ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[STT] Erreur requ√™te Whisper ({e}). Retry..."); raise; except Exception as e: logging.error(f"[STT] Erreur inattendue: {e}", exc_info=True); return None
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None: api_url = f"{XTTS_SERVER_URL}/generate"; payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}; logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'"); try: response = requests.post(api_url, json=payload, timeout=180); response.raise_for_status(); data = response.json(); audio_base64 = data.get("audio_base64"); if audio_base64: logging.info("[TTS] Audio re√ßu."); return base64.b64decode(audio_base64); else: logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'."); return None; except requests.exceptions.Timeout as e: logging.warning(f"[TTS] Timeout XTTS ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[TTS] Erreur requ√™te XTTS ({e}). Retry..."); raise; except Exception as e: logging.error(f"[TTS] Erreur inattendue: {e}", exc_info=True); return None
@retry(stop=stop_after_attempt(2), wait=wait_fixed(5), reraise=True)
def generate_image_tool(prompt: str) -> str: api_url = f"{STABLE_DIFFUSION_API_URL}/sdapi/v1/txt2img"; payload = {"prompt": prompt, "negative_prompt": "ugly...", "steps": 25, "width": 512, "height": 512, ...}; logging.info(f"[IMG] Appel API SD: '{prompt[:50]}...'"); try: response = requests.post(api_url, json=payload, timeout=300); response.raise_for_status(); data = response.json(); if "images" in data and data["images"]: image_b64 = data["images"][0]; try: image_bytes = base64.b64decode(image_b64); timestamp = int(time.time()); safe_prompt_suffix = "".join(c if c.isalnum() else "_" for c in prompt[:30]).rstrip('_'); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); file_path = IMAGE_OUTPUT_DIR / f"generated_{timestamp}_{safe_prompt_suffix}.png"; file_path.write_bytes(image_bytes); logging.info(f"[IMG] Image SD sauv√©e: {file_path}"); relative_path = file_path.relative_to(Path("/app")).as_posix(); return f"IMAGE_GENEREE:{relative_path}"; except Exception as save_err: logging.error(f"[IMG] Erreur d√©codage/sauvegarde image: {save_err}", exc_info=True); return "Erreur: Impossible de sauvegarder image g√©n√©r√©e."; else: logging.error(f"[IMG] Pas d'image dans r√©ponse API SD: {data}"); return "Erreur: Aucune image retourn√©e."; except requests.exceptions.Timeout as e: logging.warning(f"[IMG] Timeout SD ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[IMG] Erreur requ√™te SD ({e}). Retry..."); raise; except Exception as e: logging.error(f"[IMG] Erreur inattendue API SD: {e}", exc_info=True); return f"Erreur inattendue service image: {e}"
def _is_path_safe(requested_path_str: str) -> Path | None: try: if not requested_path_str or "/" in requested_path_str or "\\" in requested_path_str or ".." in requested_path_str: logging.warning(f"[_is_path_safe] Nom fichier invalide/complexe: '{requested_path_str}'"); return None; target_path_relative = Path(requested_path_str); if target_path_relative.parent != Path('.'): logging.warning(f"[_is_path_safe] Sous-dossier non autoris√©: '{requested_path_str}'"); return None; safe_dir_abs = SAFE_NOTES_DIR.resolve(strict=True); requested_path_abs = (safe_dir_abs / target_path_relative).resolve(strict=False); if requested_path_abs == safe_dir_abs or requested_path_abs.is_relative_to(safe_dir_abs): if requested_path_abs != safe_dir_abs: return requested_path_abs; logging.warning(f"[_is_path_safe] Chemin hors limites: '{requested_path_abs}' vs '{safe_dir_abs}'"); return None; except Exception as e: logging.error(f"[_is_path_safe] Erreur validation '{requested_path_str}': {e}", exc_info=True); return None
def list_notes_safe() -> str: logging.info(f"[NOTES] Action: Lister notes dans {SAFE_NOTES_DIR}"); try: SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); files = [f.name for f in SAFE_NOTES_DIR.iterdir() if f.is_file()]; return "Notes personnelles existantes:\n- " + "\n- ".join(files) if files else "Dossier notes vide."; except Exception as e: logging.error(f"[NOTES] Erreur list_notes: {e}", exc_info=True); return f"Erreur listage notes: {e}"
def save_note_safe(filename: str, content: str) -> str: logging.info(f"[NOTES] Action: Sauvegarde note '{filename}'"); safe_full_path = _is_path_safe(filename); if safe_full_path is None: return "Erreur s√©curit√©: Nom fichier invalide."; try: safe_full_path.parent.mkdir(parents=True, exist_ok=True); safe_full_path.write_text(content, encoding='utf-8'); logging.info(f"[NOTES] Note sauv√©e: {safe_full_path}"); return f"Note '{filename}' sauv√©e."; except Exception as e: logging.error(f"[NOTES] Erreur sauvegarde '{filename}': {e}", exc_info=True); return f"Erreur sauvegarde note '{filename}': {e}"
def read_note_safe(filename: str) -> str: logging.info(f"[NOTES] Action: Lecture note '{filename}'"); safe_full_path = _is_path_safe(filename); if safe_full_path is None: return "Erreur s√©curit√©: Nom fichier invalide."; if not safe_full_path.is_file(): logging.warning(f"[NOTES] Fichier note inexistant: '{filename}'"); return f"Erreur: Fichier note '{filename}' inexistant."; try: content = safe_full_path.read_text(encoding='utf-8'); logging.info(f"[NOTES] Note lue: {safe_full_path}"); return f"Contenu de '{filename}':\n\n{content}"; except Exception as e: logging.error(f"[NOTES] Erreur lecture '{filename}': {e}", exc_info=True); return f"Erreur lecture note '{filename}': {e}"
def run_rag_retriever(query: str) -> str: logging.warning("[RAG] run_rag_retriever non actif."); return "Action d√©sactiv√©e." # Sera activ√© en Phase 10


# --- Initialisation Globale (inchang√©e) ---
# ... (Code d'init globale embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}


# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat -> Agent avec Web/Img/Sys actifs."""
    logging.info("\n--- Nouvelle Session Chat (Phase 9 v4.2 - Agent Web/Img/Sys + Upload RAG pr√™t) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA non initialis√©s.").send(); return

    try:
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2, request_timeout=300.0)
        logging.info("[Session Start] LLM pour Agent initialis√©.")

        # --- AGENT SETUP (Web/Img/Sys actifs, RAG d√©fini mais inactif) ---
        logging.info("[Session Start] Configuration de l'Agent ReAct...")
        # 1. D√©finir TOUS les outils
        search_tool = DuckDuckGoSearchRun(name="Recherche Web DuckDuckGo")
        image_tool = Tool( name="Generateur Image", func=generate_image_tool, description="..." )
        list_notes_tool = Tool( name="Lister Notes Personnelles", func=list_notes_safe, description="..." )
        save_note_tool = Tool( name="Sauvegarder Note Personnelle", func=save_note_safe, description="..." )
        read_note_tool = Tool( name="Lire Note Personnelle", func=read_note_safe, description="..." )
        rag_tool = Tool( name="Recherche Document Personnel", func=run_rag_retriever, description="Cherche dans les docs." ) # Placeholder func

        # 2. S√©lectionner outils ACTIFS pour Phase 9 (PAS DE RAG TOOL ICI)
        active_tools = [ search_tool, image_tool, list_notes_tool, save_note_tool, read_note_tool ]
        logging.info(f"[Session Start] Outils actifs pour l'agent ({len(active_tools)}): {[tool.name for tool in active_tools]}")

        # 3. Prompt & Agent ReAct (inchang√©s)
        react_prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(llm, active_tools, react_prompt)
        logging.info("[Session Start] Agent ReAct cr√©√©.")

        # 4. AgentExecutor (inchang√©, utilise la liste `active_tools` ci-dessus)
        agent_executor = AgentExecutor( agent=agent, tools=active_tools, verbose=True, handle_parsing_errors=True, max_iterations=10 )
        cl.user_session.set("agent_executor", agent_executor)
        logging.info(f"[Session Start] Agent Executor ({len(active_tools)} outils actifs) initialis√©.")
        # --- FIN AGENT SETUP ---

        # Stocker retriever/vector store (pour @cl.on_file_upload)
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])

        # Inputs & Upload (inchang√©)
        logging.info("[Session Start] Configuration UI: Inputs Texte/Audio/Upload.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="...", initial=""), cl.AudioInput(id="audio_input", label="...") ] ).send()
        cl.set_config(enable_file_upload=True, file_upload_accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2 avec recherche, image, notes). Upload RAG activ√©.", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Pr√™te (Agent Web/Img/Sys + Upload RAG) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# process_and_respond (inchang√© - utilise l'agent executor avec ses outils actifs)
# ... (Coller ici la fonction process_and_respond compl√®te de Phase 8 v4.2) ...
async def process_and_respond(input_content_sanitized: str): agent_executor = cl.user_session.get("agent_executor"); if not agent_executor: logging.error("[Process] Agent Executor non trouv√©."); await cl.Message(content="Erreur: Agent non initialis√©.").send(); return; msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send(); final_answer_text = ""; image_to_display = None; try: logging.info(f"[Run] Appel Agent Executor: '{input_content_sanitized[:50]}...'"); response = await agent_executor.ainvoke({"input": input_content_sanitized}); final_answer_text = response.get("output", "Pas de r√©ponse pertinente."); logging.info(f"[Run] R√©ponse brute Agent: '{final_answer_text[:100]}...'"); if isinstance(final_answer_text, str) and final_answer_text.startswith("IMAGE_GENEREE:"): try: relative_image_path = final_answer_text.split(":", 1)[1]; image_path_in_container = Path("/app") / relative_image_path; if image_path_in_container.is_file(): image_to_display = cl.Image(path=str(image_path_in_container), name=os.path.basename(relative_image_path), display="inline"); final_answer_text = f"Voici l'image demand√©e."; logging.info(f"[Run] Image d√©tect√©e: {relative_image_path}"); else: logging.error(f"[Run] Fichier image non trouv√©: {image_path_in_container}"); final_answer_text += " (Erreur: fichier introuvable)"; except Exception as img_err: logging.error(f"[Run] Erreur pr√©pa image: {img_err}", exc_info=True); final_answer_text += " (Erreur affichage)"; await msg.update(content=final_answer_text); logging.info(f"[Run] R√©ponse Agent affich√©e: '{final_answer_text[:100]}...'"); if image_to_display: await cl.Message(content="", elements=[image_to_display], author="Image G√©n√©r√©e").send(); logging.info("[Run] G√©n√©ration audio XTTS..."); try: audio_bytes = text_to_speech(final_answer_text); if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©."); else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as tts_err: logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as e: error_message = f"ERREUR agent execution: {e}"; logging.error(f"[Run] {error_message}", exc_info=True); await msg.update(content="D√©sol√©, erreur interne pendant la r√©flexion.", author="Erreur Syst√®me"); logging.info("--- Fin Traitement Input ---")


# on_message (inchang√©)
@cl.on_message
async def on_text_message(message: cl.Message):
    # ... (Coller code on_message de Phase 8 v4.2) ...
    logging.info(f"\n--- Msg Texte UI ---"); logging.info(f"Input brut: '{message.content[:60]}...'"); try: sanitized_input = sanitize_input(message.content); logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'"); await process_and_respond(sanitized_input); except Exception as e: logging.error(f"Erreur sanitization/traitement message texte: {e}", exc_info=True); await cl.Message(content="Erreur interne traitement message.").send()

# on_audio_end (inchang√©)
@cl.on_audio_end
async def on_audio_end(audio: cl.Audio):
    # ... (Coller code on_audio_end de Phase 8 v4.2) ...
    logging.info(f"\n--- Audio Re√ßu ---"); logging.info(f"Taille: {len(audio.content)} bytes, mime: {audio.mime}"); transcript_msg = cl.Message(content="*Transcription...*", author="Syst√®me", disable_feedback=True); await transcript_msg.send(); transcribed_text_sanitized = None; try: transcribed_text_raw = transcribe_audio(audio.content); if transcribed_text_raw is not None: transcribed_text_sanitized = sanitize_input(transcribed_text_raw); logging.info(f"Texte transcrit (Sanitized): '{transcribed_text_sanitized[:60]}...'"); await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text_sanitized}\""); await process_and_respond(transcribed_text_sanitized); else: logging.warning("[STT] Transcription vide/None."); await transcript_msg.update(content="Pas de son d√©tect√© ou transcription vide."); except Exception as e: logging.error(f"[STT] √âchec final transcription/sanitization: {e}", exc_info=True); await transcript_msg.update(content="√âchec transcription apr√®s tentatives.") ; logging.info("--- Fin Traitement Audio ---")


# --- Section RAG Upload (Impl√©ment√©e pour Phase 9) ---
# D√©corateur avec types de fichiers accept√©s et limites
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)
async def on_file_upload(files: list[cl.File]):
    """G√®re l'upload de fichiers pour indexation RAG."""
    logging.info(f"\n--- Fichiers Re√ßus pour RAG ({len(files)}) ---")
    if not files:
        return

    # R√©cup√®re le VectorStore Langchain de la session
    vector_store_lc_session = cl.user_session.get("vector_store_lc")
    if not vector_store_lc_session:
        logging.error("[RAG Upload] VectorStore non trouv√© dans la session.")
        await cl.Message(content="Erreur interne: La base de donn√©es RAG n'est pas pr√™te pour cette session.").send()
        return

    await cl.Message(content=f"R√©ception de {len(files)} fichier(s) pour indexation RAG...").send()

    # Initialise le Text Splitter
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    successful_files = []
    failed_files = []

    for file in files:
        # Affiche un message pour chaque fichier
        file_msg = cl.Message(content=f"Traitement de `{file.name}`...", author="Syst√®me", disable_feedback=True)
        await file_msg.send()
        temp_file_path = None # Pour cleanup

        try:
            # 1. Sauvegarder le fichier temporairement
            temp_file_path = UPLOAD_TEMP_DIR / file.name
            UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True) # Assure existence
            await cl.make_async(temp_file_path.write_bytes)(file.content)
            logging.info(f"[RAG Upload] Fichier temporaire sauv√©: {temp_file_path}")

            # 2. Choisir le Loader appropri√©
            file_ext = os.path.splitext(file.name)[1].lower()
            loader = None
            if file_ext == ".pdf":
                loader = PyPDFLoader(str(temp_file_path))
            elif file_ext == ".txt":
                loader = TextLoader(str(temp_file_path), encoding='utf-8')
            elif file_ext == ".docx": # Unstructured g√®re docx
                 loader = UnstructuredFileLoader(str(temp_file_path))
            else:
                logging.warning(f"[RAG Upload] Format de fichier non support√©: {file.name}")
                await file_msg.update(content=f"Format de fichier `{file.name}` non support√©.")
                failed_files.append(file.name)
                continue # Passe au fichier suivant

            # 3. Charger les documents (async)
            logging.info(f"[RAG Upload] Chargement du document: {file.name}...")
            documents = await cl.make_async(loader.load)()
            logging.info(f"[RAG Upload] Document charg√© ({len(documents)} pages/docs).")

            # 4. Splitter les documents en chunks (async)
            logging.info(f"[RAG Upload] Split du document: {file.name}...")
            chunks = await cl.make_async(text_splitter.split_documents)(documents)
            logging.info(f"[RAG Upload] Nombre de chunks cr√©√©s: {len(chunks)}")

            if not chunks:
                logging.warning(f"[RAG Upload] Aucun chunk cr√©√© pour {file.name}.")
                await file_msg.update(content=f"Aucun contenu textuel extrait de `{file.name}`.")
                failed_files.append(file.name)
                continue

            # 5. Ajouter les chunks au VectorStore (async)
            logging.info(f"[RAG Upload] Ajout des chunks de {file.name} √† ChromaDB...")
            await cl.make_async(vector_store_lc_session.add_documents)(chunks)
            logging.info(f"[RAG Upload] Chunks ajout√©s avec succ√®s.")

            await file_msg.update(content=f"Document `{file.name}` index√© avec succ√®s ({len(chunks)} chunks).")
            successful_files.append(file.name)

        except Exception as e:
            # G√®re les erreurs pendant le processus pour un fichier
            error_text = f"Erreur lors du traitement de `{file.name}`: {e}"
            logging.error(f"[RAG Upload] {error_text}", exc_info=True)
            await file_msg.update(content=error_text)
            failed_files.append(file.name)
        finally:
            # 6. Nettoyer le fichier temporaire
            if temp_file_path and await cl.make_async(temp_file_path.exists)():
                try:
                    await cl.make_async(temp_file_path.unlink)()
                    logging.info(f"[RAG Upload] Fichier temporaire supprim√©: {temp_file_path}")
                except Exception as del_e:
                    logging.error(f"[RAG Upload] Erreur suppression fichier temp: {del_e}")

    # Message r√©capitulatif final
    summary_message = "Traitement des fichiers termin√©.\n"
    if successful_files:
        summary_message += f"- Fichiers index√©s: {', '.join(successful_files)}\n"
    if failed_files:
        summary_message += f"- Fichiers en √©chec: {', '.join(failed_files)}"
    await cl.Message(content=summary_message).send()
    logging.info("--- Fin Traitement Upload Fichiers RAG ---")

# --- Fin Section RAG Upload ---


```

* **Action :** Sauvegardez le fichier `app.py`.

---

### √âtape 9.3 : Utiliser l'Upload Chainlit

* **Action :** V√©rifiez que tous les conteneurs Docker sont actifs (`docker ps`).
* **Action :** Ouvrez l'interface Chainlit dans votre navigateur : `http://127.0.0.1:8001`.
* **Action :** Cliquez sur l'ic√¥ne d'upload (trombone/fl√®che). Elle devrait √™tre active (car `cl.set_config(enable_file_upload=True)` est dans `@cl.on_chat_start`).
* **Action :** S√©lectionnez le(s) fichier(s) de test (ex: `infos_khaldounia.txt`, `reunion_projet_aladin.docx`) et validez l'upload.

---

### √âtape 9.4 : Observer le Traitement d'Indexation

* **R√©sultat Attendu dans Chainlit :** Messages indiquant : "R√©ception...", "Traitement `[nom_fichier]`...", "Document `[nom_fichier]` index√©...", "Traitement termin√©...".
* **R√©sultat Attendu dans les Logs (`assistant_app`) :** Suivez les logs (`docker logs -f assistant_app`) pour voir les d√©tails de `@cl.on_file_upload` :
    * "--- Fichiers Re√ßus pour RAG..."
    * "[RAG Upload] Fichier temporaire sauv√©..."
    * "[RAG Upload] Chargement du document..."
    * "[RAG Upload] Split du document..."
    * "[RAG Upload] Nombre de chunks cr√©√©s..."
    * "[RAG Upload] Ajout des chunks ... √† ChromaDB..."
    * "[RAG Upload] Chunks ajout√©s avec succ√®s."
    * "[RAG Upload] Fichier temporaire supprim√©..."
    * "--- Fin Traitement Upload Fichiers RAG ---"

---

### √âtape 9.5 : Tester la Fonctionnalit√© RAG (R√©cup√©ration Basique - Indirecte)

* **Explication :** Posez une question dont la r√©ponse est **uniquement** dans un des documents charg√©s. L'Agent n'a **pas** encore l'outil RAG actif. Cependant, on peut observer si le contexte pertinent est r√©cup√©r√© par le retriever (li√© √† la cha√Æne sous-jacente dans certaines impl√©mentations, bien que moins direct ici avec l'Agent Executor). Le but est surtout de s'assurer que l'indexation a eu lieu et que le retriever est pr√™t.
* **Action :** Dans Chainlit, posez une question tr√®s sp√©cifique :
    * **Exemple 1 :** "Quel mod√®le d'embedding Khaldounia utilise-t-il ?" (si `infos_khaldounia.txt` charg√©)
    * **Exemple 2 :** "Quel est le nom du projet mentionn√© dans le doc de r√©union ?" (si `reunion_projet_aladin.docx` charg√©)
* **R√©sultat Attendu / Observation :**
    1.  **Il est PROBABLE que l'agent n'utilise PAS cette information.** Il choisira probablement `Recherche Web DuckDuckGo` ou r√©pondra qu'il ne sait pas, car l'outil `Recherche Document Personnel` n'est pas dans sa liste `active_tools`. C'est **normal** √† ce stade.
    2.  **Observez les logs `assistant_app` (`verbose=True`) :** V√©rifiez que l'agent *n'appelle pas* l'outil `Recherche Document Personnel`. C'est le comportement attendu pour cette phase.
* **Contre-Test :** Posez une question Web ("M√©t√©o √† Paris aujourd'hui ?"). L'agent doit utiliser `Recherche Web DuckDuckGo`.

---

### √âtape 9.6 : D√©pannage Upload RAG (Si besoin)

* **Probl√®me : Fichier non ajout√© / Erreur pendant l'upload (`Traitement termin√©... √âchecs: [fichier]`).**
    * **Causes Possibles :** Format non support√© (`accept=`), erreur parsing `PyPDFLoader`/`TextLoader`/`UnstructuredFileLoader` (fichier corrompu, format complexe, d√©pendance syst√®me manquante ?), erreur connexion/√©criture ChromaDB (`add_documents`), probl√®me droits √©criture `/app/temp_uploads` (normalement OK avec `appuser` et `chown` dans Dockerfile).
    * **Actions :** Analysez l'erreur exacte dans les logs `assistant_app` (`[RAG Upload] Erreur...`). Si erreur `unstructured`, essayer de convertir en `.txt`. V√©rifier √©tat `chromadb` (`docker ps`, healthcheck).
* **Probl√®me : Fichier ajout√© ("Succ√®s"), mais info non utilis√©e (Test 9.5).**
    * **Cause Principale (attendue) :** L'outil RAG n'est pas encore actif pour l'agent (sera fait en Phase 10).
    * **Action :** C'est normal. V√©rifiez juste que l'upload s'est bien pass√© dans les logs. Passez √† la Phase 10 pour activer l'outil RAG dans l'agent.

---

### **√âtape 9.7: Sauvegarde de Fin de Phase (Optionnel mais Recommand√©)**

* **Explication :** L'upload RAG est impl√©ment√© et semble fonctionner (indexation OK). Sauvegarde avant l'activation finale de l'outil RAG.
* **M√©thode 1 : Copie Simple**
    * `docker compose down`
    * `cp -r ~/projet-khaldounia ~/projet-khaldounia-backup-phase9`
    * `docker compose up -d`
* **M√©thode 2 : Commit Git**
    * `git add .`
    * `git commit -m "Fin de la Phase 9 (v4.2) - Upload RAG impl√©ment√© et test√© (base durcie)"`

---

Fin de la Phase 9 (R√©vis√©e v4.2).

```markdown
---

## Phase 10 : Int√©gration de l'Outil RAG dans l'Agent (R√©vis√©e v4.2 - Finale)

**Objectif :** Activer la capacit√© de l'Agent LangChain √† utiliser **consciemment** la base de donn√©es RAG (ChromaDB) comme un **outil** d√©di√© pour rechercher des informations dans les documents charg√©s par l'utilisateur. Ceci finalise l'architecture cible de l'assistant sur la base durcie.

**Pr√©requis :** Phases 0-9 termin√©es, fonctionnelles et id√©alement sauvegard√©es. L'upload RAG (Phase 9) fonctionne et des documents ont √©t√© index√©s.

**Approche :** Mise √† jour finale de `app.py` pour impl√©menter la fonction `run_rag_retriever` et activer le `rag_tool` correspondant dans la liste `active_tools` de l'Agent Executor.

---

### √âtape 10.1 : Mettre √† jour le Fichier `app.py` (Activation Outil RAG)

* **Explication :** C'est la mise √† jour finale de `app.py` pour cette installation de base. Nous impl√©mentons la fonction `run_rag_retriever` qui interroge le VectorStore et formatte les r√©sultats, puis nous ajoutons le `rag_tool` √† la liste des outils actifs de l'agent dans `@cl.on_chat_start`.
* **Action :** Ouvrez `app.py` dans `~/projet-khaldounia/assistant-core/app/`.
* **Action :** Remplacez **l'int√©gralit√©** de son contenu par cette version **finale compl√®te** (v4.2) :

```python
# Fichier: app.py (Version Finale Compl√®te - Phase 10 v4.2 - Outil RAG Actif)
# R√¥le: Application Khaldounia (Agent avec TOUS les outils: Web, Img, Sys, RAG - Robuste)

import chainlit as cl
import os, requests, base64, time, logging
from pathlib import Path
import chromadb

# Imports Robustesse & S√©curit√©
from tenacity import retry, stop_after_attempt, wait_fixed
from langchain_core.prompts.input import sanitize_input

# Configuration Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Imports Langchain (Tous les composants n√©cessaires)
logging.info("--- D√©but Importation Langchain (Phase 10 Rev 4.2 - Finale) ---")
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores import Chroma as ChromaLangchainStore
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
logging.info("--- Fin Importation Langchain ---")

# --- Configuration Globale (inchang√©e) ---
# ... (coller la config globale inchang√©e) ...
logging.info("--- D√©but Chargement Configuration ---"); OLLAMA_BASE_URL = os.getenv("OLLAMA_HOST", "http://ollama:11434"); XTTS_SERVER_URL = os.getenv("XTTS_SERVER_URL", "http://xtts_server:8020"); CHROMADB_HOST = os.getenv("CHROMADB_HOST", "chromadb"); CHROMADB_PORT = os.getenv("CHROMADB_PORT", "8000"); WHISPER_SERVER_URL = os.getenv("WHISPER_SERVER_URL", "http://whisper_server:9000"); STABLE_DIFFUSION_API_URL = os.getenv("STABLE_DIFFUSION_API_URL", "http://stable_diffusion_webui:7860"); OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest"); EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"; CHROMA_COLLECTION_NAME = "khaldounia_docs"; EMBEDDING_CACHE_DIR = Path("/app/embedding_cache"); SAFE_NOTES_DIR = Path("/app/user_notes"); IMAGE_OUTPUT_DIR = Path("/app/generated_images"); UPLOAD_TEMP_DIR = Path("/app/temp_uploads"); SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True); logging.info(f"Config: Ollama@{OLLAMA_BASE_URL}, XTTS@{XTTS_SERVER_URL}, Chroma@{CHROMADB_HOST}:{CHROMADB_PORT}, Whisper@{WHISPER_SERVER_URL}, SD@{STABLE_DIFFUSION_API_URL}"); logging.info("--- Fin Chargement Configuration ---")


# --- Fonctions Utilitaires (Durcies - Incluant RAG) ---

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def transcribe_audio(audio_bytes: bytes) -> str | None:
    # ... (Impl√©mentation transcribe_audio durcie) ...
    api_url = f"{WHISPER_SERVER_URL}/asr?encode=true&task=transcribe&language=fr&output=json"; files = {'audio_file': ('audio.wav', audio_bytes, 'audio/wav')}; logging.info(f"[STT] Appel API Whisper: {api_url}"); try: response = requests.post(api_url, files=files, timeout=60); response.raise_for_status(); result = response.json(); transcribed_text = result.get("text", "").strip(); logging.info(f"[STT] Whisper: '{transcribed_text[:50]}...'"); return transcribed_text if transcribed_text else None; except requests.exceptions.Timeout as e: logging.warning(f"[STT] Timeout Whisper ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[STT] Erreur requ√™te Whisper ({e}). Retry..."); raise; except Exception as e: logging.error(f"[STT] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), reraise=True)
def text_to_speech(text: str) -> bytes | None:
    # ... (Impl√©mentation text_to_speech durcie) ...
    api_url = f"{XTTS_SERVER_URL}/generate"; payload = {"text": text, "language": "fr", "speaker_wav": "speaker_ref.wav", "output_format": "wav"}; logging.info(f"[TTS] Appel API: {api_url} pour texte: '{text[:40]}...'"); try: response = requests.post(api_url, json=payload, timeout=180); response.raise_for_status(); data = response.json(); audio_base64 = data.get("audio_base64"); if audio_base64: logging.info("[TTS] Audio re√ßu."); return base64.b64decode(audio_base64); else: logging.error(f"[TTS] R√©ponse API OK mais pas de 'audio_base64'."); return None; except requests.exceptions.Timeout as e: logging.warning(f"[TTS] Timeout XTTS ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[TTS] Erreur requ√™te XTTS ({e}). Retry..."); raise; except Exception as e: logging.error(f"[TTS] Erreur inattendue: {e}", exc_info=True); return None

@retry(stop=stop_after_attempt(2), wait=wait_fixed(5), reraise=True)
def generate_image_tool(prompt: str) -> str:
    # ... (Impl√©mentation generate_image_tool durcie) ...
    api_url = f"{STABLE_DIFFUSION_API_URL}/sdapi/v1/txt2img"; payload = {"prompt": prompt, "negative_prompt": "ugly...", "steps": 25, "width": 512, "height": 512, ...}; logging.info(f"[IMG] Appel API SD: '{prompt[:50]}...'"); try: response = requests.post(api_url, json=payload, timeout=300); response.raise_for_status(); data = response.json(); if "images" in data and data["images"]: image_b64 = data["images"][0]; try: image_bytes = base64.b64decode(image_b64); timestamp = int(time.time()); safe_prompt_suffix = "".join(c if c.isalnum() else "_" for c in prompt[:30]).rstrip('_'); IMAGE_OUTPUT_DIR.mkdir(parents=True, exist_ok=True); file_path = IMAGE_OUTPUT_DIR / f"generated_{timestamp}_{safe_prompt_suffix}.png"; file_path.write_bytes(image_bytes); logging.info(f"[IMG] Image SD sauv√©e: {file_path}"); relative_path = file_path.relative_to(Path("/app")).as_posix(); return f"IMAGE_GENEREE:{relative_path}"; except Exception as save_err: logging.error(f"[IMG] Erreur d√©codage/sauvegarde image: {save_err}", exc_info=True); return "Erreur: Impossible de sauvegarder image g√©n√©r√©e."; else: logging.error(f"[IMG] Pas d'image dans r√©ponse API SD: {data}"); return "Erreur: Aucune image retourn√©e."; except requests.exceptions.Timeout as e: logging.warning(f"[IMG] Timeout SD ({e}). Retry..."); raise; except requests.exceptions.RequestException as e: logging.warning(f"[IMG] Erreur requ√™te SD ({e}). Retry..."); raise; except Exception as e: logging.error(f"[IMG] Erreur inattendue API SD: {e}", exc_info=True); return f"Erreur inattendue service image: {e}"

def _is_path_safe(requested_path_str: str) -> Path | None:
    # ... (Impl√©mentation _is_path_safe durcie) ...
    try: if not requested_path_str or "/" in requested_path_str or "\\" in requested_path_str or ".." in requested_path_str: logging.warning(f"[_is_path_safe] Nom fichier invalide/complexe: '{requested_path_str}'"); return None; target_path_relative = Path(requested_path_str); if target_path_relative.parent != Path('.'): logging.warning(f"[_is_path_safe] Sous-dossier non autoris√©: '{requested_path_str}'"); return None; safe_dir_abs = SAFE_NOTES_DIR.resolve(strict=True); requested_path_abs = (safe_dir_abs / target_path_relative).resolve(strict=False); if requested_path_abs == safe_dir_abs or requested_path_abs.is_relative_to(safe_dir_abs): if requested_path_abs != safe_dir_abs: return requested_path_abs; logging.warning(f"[_is_path_safe] Chemin hors limites: '{requested_path_abs}' vs '{safe_dir_abs}'"); return None; except Exception as e: logging.error(f"[_is_path_safe] Erreur validation '{requested_path_str}': {e}", exc_info=True); return None

def list_notes_safe() -> str:
    # ... (Impl√©mentation list_notes_safe durcie) ...
    logging.info(f"[NOTES] Action: Lister notes dans {SAFE_NOTES_DIR}"); try: SAFE_NOTES_DIR.mkdir(parents=True, exist_ok=True); files = [f.name for f in SAFE_NOTES_DIR.iterdir() if f.is_file()]; return "Notes personnelles existantes:\n- " + "\n- ".join(files) if files else "Dossier notes vide."; except Exception as e: logging.error(f"[NOTES] Erreur list_notes: {e}", exc_info=True); return f"Erreur listage notes: {e}"

def save_note_safe(filename: str, content: str) -> str:
    # ... (Impl√©mentation save_note_safe durcie) ...
    logging.info(f"[NOTES] Action: Sauvegarde note '{filename}'"); safe_full_path = _is_path_safe(filename); if safe_full_path is None: return "Erreur s√©curit√©: Nom fichier invalide."; try: safe_full_path.parent.mkdir(parents=True, exist_ok=True); safe_full_path.write_text(content, encoding='utf-8'); logging.info(f"[NOTES] Note sauv√©e: {safe_full_path}"); return f"Note '{filename}' sauv√©e."; except Exception as e: logging.error(f"[NOTES] Erreur sauvegarde '{filename}': {e}", exc_info=True); return f"Erreur sauvegarde note '{filename}': {e}"

def read_note_safe(filename: str) -> str:
    # ... (Impl√©mentation read_note_safe durcie) ...
    logging.info(f"[NOTES] Action: Lecture note '{filename}'"); safe_full_path = _is_path_safe(filename); if safe_full_path is None: return "Erreur s√©curit√©: Nom fichier invalide."; if not safe_full_path.is_file(): logging.warning(f"[NOTES] Fichier note inexistant: '{filename}'"); return f"Erreur: Fichier note '{filename}' inexistant."; try: content = safe_full_path.read_text(encoding='utf-8'); logging.info(f"[NOTES] Note lue: {safe_full_path}"); return f"Contenu de '{filename}':\n\n{content}"; except Exception as e: logging.error(f"[NOTES] Erreur lecture '{filename}': {e}", exc_info=True); return f"Erreur lecture note '{filename}': {e}"

# --- Fonction Wrapper pour Outil RAG (Impl√©ment√©e pour Phase 10) ---
def run_rag_retriever(query: str) -> str:
    """Ex√©cute la recherche RAG et formate les documents pour l'agent."""
    logging.info(f"\n[RAG Tool] Outil RAG demand√© pour query: '{query}'")
    retriever = cl.user_session.get("retriever") # R√©cup√®re le retriever de la session
    if not retriever:
        logging.error("[RAG Tool] Retriever non trouv√© dans la session.")
        return "Erreur: Recherche de documents personnels indisponible (Retriever non initialis√©)."

    try:
        # Utilisation synchrone pour l'instant (invoke)
        # Pour async : docs = await cl.make_async(retriever.ainvoke)(query)
        logging.info(f"[RAG Tool] Invocation du retriever pour: '{query}'")
        docs = retriever.invoke(query) # Lance la recherche synchrone

        if docs:
            # Formatte les documents pour la sortie de l'outil
            formatted_docs = "\n\n".join([f"Extrait pertinent {i+1}:\n{doc.page_content}" for i, doc in enumerate(docs)])
            logging.info(f"[RAG Tool] {len(docs)} documents trouv√©s et format√©s.")
            # Renvoyer le contenu trouv√© √† l'agent
            # NOTE: On pourrait limiter la taille de la r√©ponse si elle est trop grande pour le contexte LLM
            max_length = 3000 # Limite arbitraire (√† ajuster)
            if len(formatted_docs) > max_length:
                 formatted_docs = formatted_docs[:max_length] + "\n[... Contenu tronqu√© ...]"
                 logging.warning(f"[RAG Tool] Contenu RAG tronqu√© √† {max_length} caract√®res.")
            return f"Voici des extraits pertinents trouv√©s dans vos documents personnels concernant '{query}':\n{formatted_docs}"
        else:
            logging.info("[RAG Tool] Aucun document pertinent trouv√© par le retriever.")
            return "Aucun document pertinent trouv√© dans la base de documents personnels pour cette question."

    except Exception as e:
        # En cas d'erreur pendant la recherche RAG (ex: connexion ChromaDB √©choue)
        logging.error(f"[RAG Tool] Erreur lors de l'invocation du retriever: {e}", exc_info=True)
        return f"Erreur lors de la recherche dans les documents personnels: {e}"
# --- Fin Fonction Wrapper RAG ---


# --- Initialisation Globale (inchang√©e) ---
# ... (Code d'init globale embeddings, chroma_client, retriever) ...
logging.info("\n--- D√©but Initialisation Globale IA ---"); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}; try: logging.info("[INIT] Embeddings..."); ia_components["embeddings"] = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME, cache_folder=str(EMBEDDING_CACHE_DIR)); logging.info(f"[INIT] Embedding Model '{EMBEDDING_MODEL_NAME}' pr√™t."); logging.info("[INIT] Client ChromaDB..."); ia_components["chroma_client"] = chromadb.HttpClient(host=CHROMADB_HOST, port=int(CHROMADB_PORT), timeout=60); ia_components["chroma_client"].heartbeat(); logging.info("[INIT] Client ChromaDB connect√©."); logging.info(f"[INIT] VectorStore '{CHROMA_COLLECTION_NAME}'..."); ia_components["vector_store_lc"] = ChromaLangchainStore(client=ia_components["chroma_client"], collection_name=CHROMA_COLLECTION_NAME, embedding_function=ia_components["embeddings"]); ia_components["retriever"] = ia_components["vector_store_lc"].as_retriever(search_kwargs={"k": 3}); logging.info("[INIT] Retriever pr√™t."); logging.info("--- Fin Initialisation Globale IA ---")
except Exception as e: logging.critical(f"[INIT - ERREUR FATALE]: {e}", exc_info=True); ia_components = {"embeddings": None, "chroma_client": None, "vector_store_lc": None, "retriever": None}


# --- Logique Chainlit ---

@cl.on_chat_start
async def start_chat():
    """Initialisation session chat -> Agent avec TOUS les outils actifs (y compris RAG)."""
    logging.info("\n--- Nouvelle Session Chat (Phase 10 v4.2 - Agent FINAL avec Outil RAG) ---")
    if not ia_components.get("retriever") or not ia_components.get("vector_store_lc"):
         logging.error("[Session Start] Erreur critique: Composants IA non initialis√©s.")
         await cl.Message(content="Erreur critique: Composants IA non initialis√©s.").send(); return

    try:
        llm = ChatOllama( model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, temperature=0.2, request_timeout=300.0)
        logging.info("[Session Start] LLM pour Agent initialis√©.")

        # --- AGENT SETUP : Activation de TOUS les outils ---
        logging.info("[Session Start] Configuration de l'Agent ReAct...")
        # 1. D√©finir TOUS les outils
        search_tool = DuckDuckGoSearchRun(name="Recherche Web DuckDuckGo")
        image_tool = Tool( name="Generateur Image", func=generate_image_tool, description="Cr√©√© une image." )
        list_notes_tool = Tool( name="Lister Notes Personnelles", func=list_notes_safe, description="Liste les notes." )
        save_note_tool = Tool( name="Sauvegarder Note Personnelle", func=save_note_safe, description="Sauve une note. Input: 'nom_fichier.txt, contenu'." )
        read_note_tool = Tool( name="Lire Note Personnelle", func=read_note_safe, description="Lit une note. Input: nom_du_fichier.txt." )
        # <<< D√âFINITION OUTIL RAG (Phase 10) >>>
        rag_tool = Tool(
            name="Recherche Document Personnel",
            func=run_rag_retriever, # Utilise la fonction wrapper impl√©ment√©e ci-dessus
            description=( "INDISPENSABLE pour rechercher et r√©pondre en utilisant les informations sp√©cifiques des documents PDF/TXT/DOCX fournis par l'utilisateur (fichiers charg√©s). "
                          "Utilise cet outil EN PRIORIT√â si la question concerne des informations personnelles, des projets sp√©cifiques d√©crits dans les documents, "
                          "ou si on demande de chercher dans 'mes fichiers', 'mes documents', ou un document sp√©cifique." )
        )
        # <<< FIN D√âFINITION OUTIL RAG >>>

        # 2. S√©lectionner outils ACTIFS (Phase 10 - TOUT EST ACTIF)
        active_tools = [
            search_tool,
            image_tool,
            list_notes_tool,
            save_note_tool,
            read_note_tool,
            rag_tool  # <<<=== OUTIL RAG ACTIV√â ICI
        ]
        logging.info(f"[Session Start] Outils actifs pour l'agent ({len(active_tools)}): {[tool.name for tool in active_tools]}")

        # 3. Prompt & Agent ReAct (inchang√©s)
        react_prompt = hub.pull("hwchase17/react")
        agent = create_react_agent(llm, active_tools, react_prompt)
        logging.info("[Session Start] Agent ReAct cr√©√©.")

        # 4. AgentExecutor (inchang√©, utilise la liste compl√®te `active_tools`)
        agent_executor = AgentExecutor( agent=agent, tools=active_tools, verbose=True, handle_parsing_errors=True, max_iterations=10 )
        cl.user_session.set("agent_executor", agent_executor)
        logging.info(f"[Session Start] Agent Executor final ({len(active_tools)} outils) initialis√©.")
        # --- FIN AGENT SETUP ---

        # Stocker retriever/vector store pour upload
        cl.user_session.set("retriever", ia_components["retriever"])
        cl.user_session.set("vector_store_lc", ia_components["vector_store_lc"])

        # Inputs & Upload (inchang√©)
        logging.info("[Session Start] Configuration UI: Inputs Texte/Audio/Upload.")
        await cl.ChatSettings( inputs=[ cl.TextInput(id="text_input", label="...", initial=""), cl.AudioInput(id="audio_input", label="...") ] ).send()
        cl.set_config(enable_file_upload=True, file_upload_accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)

        await cl.Message( content=f"Bonjour Halim-IA ! Assistant pr√™t (v4.2 final avec tous les outils).", author="Assistant Khaldounia" ).send()
        logging.info("--- Session Chat Pr√™te (Agent FINAL) ---")

    except Exception as e: error_msg = f"ERREUR CRITIQUE @on_chat_start: {e}"; logging.critical(error_msg, exc_info=True); await cl.Message(content=f"Erreur d√©marrage session: {error_msg}").send()


# process_and_respond (inchang√© - utilise l'agent executor qui a maintenant acc√®s √† RAG Tool)
# ... (Coller ici la fonction process_and_respond compl√®te de Phase 8 v4.2) ...
async def process_and_respond(input_content_sanitized: str): agent_executor = cl.user_session.get("agent_executor"); if not agent_executor: logging.error("[Process] Agent Executor non trouv√©."); await cl.Message(content="Erreur: Agent non initialis√©.").send(); return; msg = cl.Message(content="", author="Assistant Khaldounia", prompt=input_content_sanitized); await msg.send(); final_answer_text = ""; image_to_display = None; try: logging.info(f"[Run] Appel Agent Executor: '{input_content_sanitized[:50]}...'"); response = await agent_executor.ainvoke({"input": input_content_sanitized}); final_answer_text = response.get("output", "Pas de r√©ponse pertinente."); logging.info(f"[Run] R√©ponse brute Agent: '{final_answer_text[:100]}...'"); if isinstance(final_answer_text, str) and final_answer_text.startswith("IMAGE_GENEREE:"): try: relative_image_path = final_answer_text.split(":", 1)[1]; image_path_in_container = Path("/app") / relative_image_path; if image_path_in_container.is_file(): image_to_display = cl.Image(path=str(image_path_in_container), name=os.path.basename(relative_image_path), display="inline"); final_answer_text = f"Voici l'image demand√©e."; logging.info(f"[Run] Image d√©tect√©e: {relative_image_path}"); else: logging.error(f"[Run] Fichier image non trouv√©: {image_path_in_container}"); final_answer_text += " (Erreur: fichier introuvable)"; except Exception as img_err: logging.error(f"[Run] Erreur pr√©pa image: {img_err}", exc_info=True); final_answer_text += " (Erreur affichage)"; await msg.update(content=final_answer_text); logging.info(f"[Run] R√©ponse Agent affich√©e: '{final_answer_text[:100]}...'"); if image_to_display: await cl.Message(content="", elements=[image_to_display], author="Image G√©n√©r√©e").send(); logging.info("[Run] G√©n√©ration audio XTTS..."); try: audio_bytes = text_to_speech(final_answer_text); if audio_bytes: await cl.Message(content="", elements=[cl.Audio(name="response.wav", content=audio_bytes, auto_play=True)], author="Audio Khaldounia").send(); logging.info("[Run] Audio envoy√©."); else: logging.warning("[Run] Echec g√©n√©ration audio interne (apr√®s retries)."); await cl.Message(content="(Erreur interne g√©n√©ration audio)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as tts_err: logging.error(f"[Run] √âchec final appel TTS: {tts_err}", exc_info=True); await cl.Message(content=f"(Erreur communication service audio.)", author="Alerte Syst√®me", parent_id=msg.id).send(); except Exception as e: error_message = f"ERREUR agent execution: {e}"; logging.error(f"[Run] {error_message}", exc_info=True); await msg.update(content="D√©sol√©, erreur interne pendant la r√©flexion.", author="Erreur Syst√®me"); logging.info("--- Fin Traitement Input ---")


# on_message (inchang√©)
@cl.on_message
async def on_text_message(message: cl.Message):
    # ... (Coller code on_message de Phase 8 v4.2) ...
    logging.info(f"\n--- Msg Texte UI ---"); logging.info(f"Input brut: '{message.content[:60]}...'"); try: sanitized_input = sanitize_input(message.content); logging.info(f"Input (Sanitized): '{sanitized_input[:60]}...'"); await process_and_respond(sanitized_input); except Exception as e: logging.error(f"Erreur sanitization/traitement message texte: {e}", exc_info=True); await cl.Message(content="Erreur interne traitement message.").send()

# on_audio_end (inchang√©)
@cl.on_audio_end
async def on_audio_end(audio: cl.Audio):
    # ... (Coller code on_audio_end de Phase 8 v4.2) ...
    logging.info(f"\n--- Audio Re√ßu ---"); logging.info(f"Taille: {len(audio.content)} bytes, mime: {audio.mime}"); transcript_msg = cl.Message(content="*Transcription...*", author="Syst√®me", disable_feedback=True); await transcript_msg.send(); transcribed_text_sanitized = None; try: transcribed_text_raw = transcribe_audio(audio.content); if transcribed_text_raw is not None: transcribed_text_sanitized = sanitize_input(transcribed_text_raw); logging.info(f"Texte transcrit (Sanitized): '{transcribed_text_sanitized[:60]}...'"); await transcript_msg.update(content=f"Vous avez dit : \"{transcribed_text_sanitized}\""); await process_and_respond(transcribed_text_sanitized); else: logging.warning("[STT] Transcription vide/None."); await transcript_msg.update(content="Pas de son d√©tect√© ou transcription vide."); except Exception as e: logging.error(f"[STT] √âchec final transcription/sanitization: {e}", exc_info=True); await transcript_msg.update(content="√âchec transcription apr√®s tentatives.") ; logging.info("--- Fin Traitement Audio ---")


# on_file_upload (inchang√© - Logique d'indexation RAG de Phase 9)
# ... (Coller ici la fonction @cl.on_file_upload compl√®te de Phase 9 v4.2) ...
@cl.on_file_upload(accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"], max_files=5, max_size_mb=100)
async def on_file_upload(files: list[cl.File]):
    logging.info(f"\n--- Fichiers Re√ßus pour RAG ({len(files)}) ---"); if not files: return; vector_store_lc_session = cl.user_session.get("vector_store_lc"); if not vector_store_lc_session: logging.error("[RAG Upload] VectorStore non trouv√©."); await cl.Message(content="Erreur: Base RAG non pr√™te.").send(); return; await cl.Message(content=f"R√©ception {len(files)} fichier(s)...").send(); text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200); successful_files = []; failed_files = [];
    for file in files: file_msg = cl.Message(content=f"Traitement `{file.name}`...", author="Syst√®me"); await file_msg.send(); temp_file_path = None;
    try: temp_file_path = UPLOAD_TEMP_DIR / file.name; UPLOAD_TEMP_DIR.mkdir(parents=True, exist_ok=True); await cl.make_async(temp_file_path.write_bytes)(file.content); file_ext = os.path.splitext(file.name)[1].lower(); loader = None;
    if file_ext == ".pdf": loader = PyPDFLoader(str(temp_file_path))
    elif file_ext == ".txt": loader = TextLoader(str(temp_file_path), encoding='utf-8')
    elif file_ext == ".docx": loader = UnstructuredFileLoader(str(temp_file_path))
    else: await file_msg.update(content=f"Format `{file.name}` non support√©."); failed_files.append(file.name); continue;
    logging.info(f"[RAG Upload] Load {file.name}..."); documents = await cl.make_async(loader.load)(); logging.info(f"[RAG Upload] Split {file.name}..."); chunks = await cl.make_async(text_splitter.split_documents)(documents); logging.info(f"[RAG Upload] Chunks: {len(chunks)}");
    if not chunks: await file_msg.update(content=f"Contenu vide `{file.name}`."); failed_files.append(file.name); continue;
    logging.info(f"[RAG Upload] Add chunks {file.name} to Chroma..."); await cl.make_async(vector_store_lc_session.add_documents)(chunks); logging.info(f"[RAG Upload] Chunks ajout√©s."); await file_msg.update(content=f"`{file.name}` ajout√© ({len(chunks)} chunks)."); successful_files.append(file.name);
    except Exception as e: error_text = f"Erreur `{file.name}`: {e}"; logging.error(f"[RAG Upload] {error_text}", exc_info=True); await file_msg.update(content=error_text); failed_files.append(file.name);
    finally: if temp_file_path and await cl.make_async(temp_file_path.exists)(): try: await cl.make_async(temp_file_path.unlink)(); logging.info(f"[RAG Upload] Temp file deleted: {temp_file_path}"); except Exception as del_e: logging.error(f"[RAG Upload] Erreur suppression temp file: {del_e}");
    summary = "Indexation termin√©e.\n"; summary += f"- Succ√®s: {', '.join(successful_files)}\n" if successful_files else ""; summary += f"- √âchecs: {', '.join(failed_files)}" if failed_files else ""; await cl.Message(content=summary).send(); logging.info("--- Fin Traitement Fichiers ---")

```

* **Action :** Sauvegardez ce fichier `app.py` final (v4.2). Il repr√©sente l'√©tat complet de l'application avec tous les outils actifs, y compris l'outil RAG, sur une base durcie.

---

### √âtape 10.2 : Ex√©cuter cette Phase (Activation Finale Outil RAG)

* **Explication :** Cette √©tape active l'outil RAG dans l'agent en utilisant la version finale de `app.py`.
* **Action :**
    1.  Assurez-vous que `~/projet-khaldounia/assistant-core/app/app.py` contient le code complet de l'√âtape 10.1 ci-dessus.
    2.  Arr√™tez les services Docker :
        ```bash
        cd ~/projet-khaldounia/assistant-core
        docker compose down
        ```
    3.  Reconstruisez l'image `assistant_app` (car `app.py` a chang√©) et red√©marrez tous les services (6 services) :
        ```bash
        docker compose up -d --build
        ```

---

### √âtape 10.3 : Tester l'Int√©gration Compl√®te RAG/Agent

* **Action (Apr√®s red√©marrage √âtape 10.2) :**
    1.  V√©rifiez que tous les 6 conteneurs sont `Up` et `(healthy)` (`docker ps`).
    2.  Ouvrez Chainlit (`http://127.0.0.1:8001`).
    3.  Chargez un ou plusieurs documents de test via l'upload (comme en Phase 9), si ce n'est d√©j√† fait. (Ex: `infos_khaldounia.txt` contenant "Le mod√®le d'embedding est all-MiniLM-L6-v2" et `projet_aladin.docx` mentionnant "r√©union du 15 mars").
    4.  Posez une question dont la r√©ponse est **uniquement** dans un des documents : "Quel mod√®le d'embedding est utilis√© ?" ou "Quelle est la date de la r√©union Aladin ?"
    5.  **Observez attentivement les logs `assistant_app` (`docker logs -f assistant_app`) :**
        * L'agent (`verbose=True`) doit "penser" et **choisir** l'outil `"Recherche Document Personnel"`. La description forte de l'outil ajout√©e en Phase 10 devrait l'y aider.
        * Vous devriez voir les logs `[RAG Tool] Outil RAG demand√©...` et `[RAG Tool] Invocation du retriever...` de la fonction `run_rag_retriever`.
        * L'agent re√ßoit les extraits trouv√©s comme "Observation" (ex: "Voici des extraits pertinents trouv√©s...") et les utilise pour formuler sa r√©ponse finale.
    6.  V√©rifiez que la r√©ponse dans Chainlit est correcte (bas√©e sur le document) et est accompagn√©e de l'audio.
    7.  **Contre-Tests (V√©rifier que l'agent choisit le bon outil) :**
        * Question Web ("M√©t√©o aujourd'hui √† √âpinay-sur-Seine ?") -> Doit utiliser `Recherche Web DuckDuckGo`.
        * Question Image ("Dessine un logo pour Khaldounia") -> Doit utiliser `Generateur Image`.
        * Question Notes ("Liste mes notes personnelles") -> Doit utiliser `Lister Notes Personnelles`.
        * Question simple ("Comment vas-tu ?") -> Doit r√©pondre directement sans outil.
* **En Cas de Probl√®me :**
    * **Agent n'utilise jamais l'outil RAG alors qu'il le devrait :** Logs `assistant_app` (`verbose=True`) -> "Thought". La description de l'outil `Recherche Document Personnel` est-elle assez directive ? Le LLM arrive-t-il √† discriminer RAG vs Web ? (Peut n√©cessiter ajustement description ou prompt syst√®me avanc√© plus tard).
    * **Agent choisit outil RAG, mais √©choue / Erreur :** Logs `assistant_app` : Erreur dans `run_rag_retriever` (`[ERREUR] RAG Tool...`) ? Erreur retourn√©e par retriever (connexion ChromaDB KO ?) ? V√©rifier service `chromadb` (√©tat healthy, logs).
    * **Agent utilise outil RAG, mais "Aucun document pertinent" alors que info existe :** V√©rifier D√©pannage Phase 9.5 (Qualit√© document ? Chunking ? Embedding ?). Observer l'Observation re√ßue par l'agent dans les logs pour voir si le texte pertinent √©tait bien remont√© mais mal interpr√©t√©.

---
### **Conclusion Finale de l'Installation de Base**

F√©licitations ! Si vous avez atteint ce point et que les tests de la Phase 10 sont concluants, vous disposez d'une instance fonctionnelle, s√©curis√©e et robuste de l'assistant Khaldounia avec toutes ses capacit√©s de base (LLM, TTS, STT, RAG, WebSearch, ImageGen, Notes) op√©rationnelles.

Le plan d'installation est maintenant termin√©.

---

Fin de la Phase 10 (R√©vis√©e v4.2 - Finale).
```

```markdown
---


## Annexe A : Strat√©gie de V√©rification et D√©bogage (Finale V3)

**Objectif :** Fournir une m√©thode structur√©e pour identifier et r√©soudre les probl√®mes potentiels lors de l'installation ou de l'utilisation, optimis√©e pour l'interaction avec l'IA guide.

**M√©thode Recommand√©e :**

1.  **Isoler le Probl√®me :**
    * √Ä quelle **Phase** et **√âtape** l'erreur s'est-elle produite ?
    * Quelle √©tait la **derni√®re commande** ex√©cut√©e ou l'**action** effectu√©e ?
    * Quel **service Docker** semble en cause (`docker ps`) ? V√©rifiez son statut (`Up`, `Exited`, `Restarting`...).

2.  **Capturer les Informations Essentielles :**
    * Le **message d'erreur exact** affich√© dans le terminal ou dans l'interface Chainlit.
    * Les **logs pertinents** du ou des conteneurs suspects. **Utilisez principalement la commande `docker logs [nom_du_conteneur]` pour obtenir la sortie standard et les erreurs du service.** (Utilisez `docker logs --tail 100 [nom]` pour les derni√®res lignes ou `docker logs -f [nom]` pour suivre en direct).

3.  **Fournir Infos √† l'IA Guide & Demander un Diagnostic Cibl√© :**
    * **Utilisez le Mod√®le de Rapport ci-dessous** pour fournir les informations √† l'IA (moi, Gemini) de mani√®re structur√©e.
    * **Principe de Diagnostic d'Abord (avec jugement) :** L'IA Guide **doit** chercher √† comprendre la cause racine en suivant une approche hi√©rarchique :
        * **Niveau 1 (V√©rifications Service) :** L'IA doit d'abord demander des v√©rifications de base : √âtat des conteneurs (`docker ps -a`), logs r√©cents du conteneur suspect (`docker logs --tail 100 ...`).
        * **Niveau 2 (V√©rifications API/Connectivit√©) :** Si le service tourne mais l'erreur persiste, l'IA doit demander de tester la connectivit√© ou l'API via `curl` (voir tests en Phase 4.3bis et Annexe F) ou le Script de Validation (Annexe E).
        * **Niveau 3 (V√©rifications Ressources Syst√®me) :** Si des erreurs de VRAM/RAM/CPU sont suspect√©es (lenteur extr√™me, crashs OOM), l'IA doit demander le r√©sultat de `nvidia-smi` (dans WSL) et √©ventuellement `free -h` ou `htop` (dans WSL).
        * **Niveau 4 (V√©rifications Fichiers/Volumes) :** Si une erreur sugg√®re un fichier manquant ou un probl√®me de droits, l'IA doit demander une v√©rification sp√©cifique via `docker exec -it [conteneur] ls -l [chemin]` ou `docker inspect [volume/conteneur]`.
        * **Niveau 5 (Solutions & Reconstruction) :** Ce n'est qu'apr√®s avoir une meilleure id√©e de la cause que l'IA proposera une modification cibl√©e (config, code). La reconstruction compl√®te (`docker compose down && docker compose up -d --build`) ou la suppression de volumes ne doivent √™tre sugg√©r√©es qu'en dernier recours apr√®s √©chec des autres niveaux.
    * Pour une **erreur de syntaxe √©vidente**, l'IA *peut* proposer une correction directe, mais doit revenir au diagnostic si cela √©choue.
    * L'objectif est d'√©viter les suggestions √† l'aveugle.

4.  **Consulter les IA dans VS Code (Copilot/Claude - Si N√©cessaire) :**
    * Uniquement si l'erreur semble √™tre une **erreur de code Python** dans `app.py` et que le diagnostic via les logs n'est pas clair.

5.  **Consulter Claude via API Externe (Dernier Recours) :**
    * Si probl√®me complexe non r√©solu apr√®s diagnostic approfondi.

6.  **Appliquer et Tester It√©rativement :**
    * Appliquez **une seule** suggestion de correction √† la fois.
    * Retestez l'√©tape ou la fonctionnalit√©.
    * **Rapportez le r√©sultat** (succ√®s ou nouvelle erreur/logs) via le mod√®le ci-dessous.
    * **Recherche Externe (si l'IA est bloqu√©e) :** Si, apr√®s diagnostic, l'IA guide ne parvient pas √† identifier la cause d'une erreur tr√®s sp√©cifiques, elle peut sugg√©rer de rechercher le message d'erreur exact sur des sites comme GitHub Issues (pour le projet concern√© : Ollama, Chainlit, Langchain, etc.) ou Stack Overflow.

7.  **Nettoyage Cibl√© apr√®s √âchec (sur suggestion de l'IA) :**
    * Si une √©tape √©choue de mani√®re r√©p√©t√©e, si une image/volume sp√©cifique semble corrompu(e), ou si une r√©initialisation compl√®te d'un composant est jug√©e n√©cessaire apr√®s diagnostic, l'IA guide **peut vous sugg√©rer** d'ex√©cuter des commandes de nettoyage Docker **avant** de retenter l'installation ou la configuration de ce composant.
    * **Objectif :** Assurer un √©tat "propre" pour la nouvelle tentative et lib√©rer de l'espace si des artefacts inutiles ont √©t√© cr√©√©s.
    * **Commandes Possibles (Validez TOUJOURS l'impact avec l'IA avant ex√©cution !) :**
        * üü¢ `docker container prune` : Supprime tous les conteneurs arr√™t√©s. Faible risque. Utile pour nettoyer les conteneurs √©chou√©s.
        * üü¢ `docker image prune` : Supprime les images "dangling" (non tagu√©es, souvent des couches interm√©diaires apr√®s un build). Faible risque.
        * üü† `docker builder prune` : Supprime tout le cache de build Docker. Ralentira le prochain `docker compose build` mais ne supprime pas de donn√©es utiles. Risque moyen (impact temps).
        * üü† `docker image rm [image:tag]` (ex: `docker image rm ghcr.io/coqui-ai/tts:v0.22.0`) : Supprime une image sp√©cifique. N√©cessitera un ret√©l√©chargement complet si l'image est √† nouveau requise. Risque moyen (impact temps).
        * üî¥ `docker volume rm [nom_volume_specifique]` (ex: `docker volume rm khaldounia_ollama_data`) : **Supprime D√âFINITIVEMENT un volume nomm√© et TOUTES les donn√©es qu'il contient** (ex: tous les mod√®les Ollama t√©l√©charg√©s). Risque √©lev√© de perte de donn√©es. √Ä n'utiliser que pour une r√©initialisation compl√®te d'un service.
        * üî¥ `docker compose down -v` : Arr√™te et supprime les conteneurs du projet ET **supprime D√âFINITIVEMENT les volumes nomm√©s associ√©s d√©finis dans `docker-compose.yml`**. Risque √©lev√© de perte de donn√©es (Ollama, ChromaDB, Cache Embedding, Config/Mod√®les/Sorties SD).
        * üî¥ `docker compose down --rmi all` : Comme `down -v`, mais supprime **AUSSI les images Docker** utilis√©es par les services. Risque √©lev√© + longs ret√©l√©chargements.
    * **Important :** L'IA doit justifier pourquoi une commande (surtout üî¥ ou üü†) est sugg√©r√©e. Confirmez que vous comprenez les cons√©quences avant de taper `y` pour valider l'ex√©cution.


**Mod√®le de Rapport d'Erreur (√† fournir √† l'IA Guide) :**

```text
-----------------------------------
RAPPORT D'ERREUR - Projet Khaldounia
-----------------------------------
1.  **Phase et √âtape :** [Ex: Phase 7, √âtape 7.5]
2.  **Derni√®re Action Effectu√©e :** [Ex: J'ai demand√© "Dessine un chat" dans Chainlit]
3.  **Comportement Observ√© / Erreur Exacte :**
    [Copiez ici le message d'erreur complet ou d√©crivez le comportement anormal]

4.  **Logs Pertinents :**
    (Utilisez `docker logs --tail 100 nom_conteneur` pour chaque conteneur pertinent)
    * Logs `assistant_app`:
        ```
        [Collez les logs ici]
        ```
    * Logs [Autre conteneur pertinent, ex: `stable_diffusion_webui`]:
        ```
        [Collez les logs ici]
        ```
    * Logs [Encore un autre si besoin, ex: `ollama`]:
        ```
        [Collez les logs ici]
        ```
5.  **Question / Aide Demand√©e :** [Ex: L'agent utilise bien l'outil image, mais j'ai une erreur dans les logs SD et pas d'image. Que dois-je v√©rifier ensuite (Niveau 1/2 diagnostic) ?]
-----------------------------------
Conseils Suppl√©mentaires :

Utilisez le Script de Validation (Annexe E) et les tests curl (Phase 4.3bis, Annexe F).
Analysez les logs de l'Agent (verbose=True dans docker logs assistant_app).
Pensez aux v√©rifications syst√®me (espace disque df -h, RAM WSL2 via free -h ou .wslconfig, conflits de ports netstat -ano | findstr LISTEN).
L'IA peut vous demander de v√©rifier des fichiers/dossiers dans un conteneur via docker exec -it [nom_conteneur] ls -l [chemin_interne].


## Annexe B : Notes sur la Sauvegarde (Finale - MAJ Gitignore)

**Objectif :** Fournir des conseils simples pour sauvegarder les √©l√©ments importants de votre projet Khaldounia.

* **Donn√©es Critiques √† Sauvegarder :**
    * **Dossier Projet Entier :** Le plus simple est de sauvegarder r√©guli√®rement l'int√©gralit√© du dossier `~/projet-khaldounia/` depuis WSL. Il contient :
        * `assistant-core/` (avec `docker-compose.yml`, `app/Dockerfile`, `app/requirements.txt`, `app/app.py`, et le fichier `.env` si vous l'avez cr√©√©).
        * `tts-data/` (avec votre `speaker_ref.wav` et le cache des mod√®les TTS).
        * Les notes utilisateurs cr√©√©es dans `assistant-core/app/user_notes/`.
        * Les images g√©n√©r√©es dans `assistant-core/app/generated_images/`.
        * (Note : Les historiques de chat sont dans un volume Docker s√©par√©, voir ci-dessous).
    * **Volumes Docker Nomm√©s :** Les donn√©es persistantes importantes sont dans les volumes Docker (`khaldounia_ollama_data`, `khaldounia_chroma_data`, `khaldounia_sd_config`, `khaldounia_sd_models`, `khaldounia_sd_outputs`, `khaldounia_chat_history`). Ceux-ci ne sont *pas* directement dans `~/projet-khaldounia/`. Leur sauvegarde n√©cessite des strat√©gies Docker sp√©cifiques (non couvertes ici, voir documentation Docker) ou la sauvegarde de l'ensemble des donn√©es Docker de WSL. C'est pourquoi il est important de sauvegarder aussi les *sources* :
    * **Documents RAG Originaux :** Conservez une copie de tous les fichiers PDF, TXT, DOCX charg√©s.
    * **Liste des Mod√®les Ollama Install√©s :** Utile pour savoir quoi ret√©l√©charger (`docker exec -it ollama ollama list`).
    * **Mod√®les Stable Diffusion T√©l√©charg√©s :** Conservez une copie des fichiers `.safetensors`.
    * **Ce Fichier Plan :** Gardez ce fichier plan √† jour et sauvegard√© !

* **Strat√©gie de Sauvegarde Simple :**
    1. **Arr√™ter les Services Docker :** `cd ~/projet-khaldounia/assistant-core && docker compose down`.
    2. **Sauvegarder le Dossier Projet (Code & Config) :**
        * Copiez `~/projet-khaldounia` vers un emplacement s√ªr (Disque externe, Cloud...).
        * Ou `tar czvf ~/khaldounia_backup_$(date +%Y%m%d).tar.gz ~/projet-khaldounia`.
    3. **Sauvegarder les Mod√®les Externes & Docs RAG :** Assurez-vous qu'ils sont copi√©s s√©par√©ment.
    4. **(Fortement Recommand√©) Utiliser Git pour le Code/Config :** Initialisez (`git init`), utilisez un `.gitignore` (voir exemple ci-dessous), commitez r√©guli√®rement (`git add .`, `git commit`). C'est id√©al pour suivre les changements du code (`app.py`) et de la configuration (`docker-compose.yml`, `.env`, `Dockerfile`, `requirements.txt`).
        * **Exemple `.gitignore` (Mis √† jour) :**
          ```gitignore
          # Fichier de configuration sensible/local
          .env

          # Caches et Donn√©es Volumineuses (g√©r√©es par volumes Docker)
          /tts-data/cache/
          /assistant-core/app/embedding_cache/
          /assistant-core/app/generated_images/
          /assistant-core/app/temp_uploads/
          /assistant-core/app/user_notes/ # Vous pouvez choisir de les commiter ou non
          /assistant-core/app/chat_history/ # Ignorer le point de montage de l'historique

          # Fichiers Python temporaires/compil√©s
          *.pyc
          __pycache__/
          *.egg-info/

          # Fichiers sp√©cifiques IDE/OS
          .vscode/
          .DS_Store
          *.log
          ```

* **Restauration (Simplifi√©e - Code/Config) :**
    1. Restaurez le dossier `projet-khaldounia` depuis votre sauvegarde (`cp -r` ou `tar xzvf` ou `git checkout`).
    2. Replacez vos mod√®les SD `.safetensors` sources sur votre PC.
    3. Assurez-vous que le fichier `.env` est pr√©sent dans `assistant-core/app/` avec la bonne configuration.
    4. Lancez `cd ~/projet-khaldounia/assistant-core && docker compose up -d --build`. Les volumes nomm√©s seront recr√©√©s (vides au d√©but pour Ollama/Chroma/Historique).
    5. Recopiez les mod√®les SD via `docker cp` (Phase 7.6).
    6. T√©l√©chargez √† nouveau les mod√®les Ollama (`docker exec ... ollama pull ...`).
    7. R√©uploadez vos documents RAG via l'interface Chainlit (Phase 9).



## Annexe C : Notes sur la Gestion des Mod√®les Ollama (Finale)

**Objectif :** Rappeler comment interagir avec les mod√®les LLM g√©r√©s par le service Ollama dans Docker.

* **Commandes Utiles (terminal WSL) :**
    * **Lister les Mod√®les T√©l√©charg√©s :**
        ```bash
        docker exec -it ollama ollama list
        ```
    * **T√©l√©charger ou Mettre √† Jour un Mod√®le :** (Remplacez `nom_modele:tag` par le mod√®le souhait√©, ex: `mistral:latest`, `llama3:8b`)
        ```bash
        docker exec -it ollama ollama pull nom_modele:tag
        ```
    * **Supprimer un Mod√®le Local :**
        ```bash
        docker exec -it ollama ollama rm nom_modele:tag
        ```
    * **Voir les Logs du Service Ollama :** (Utile si un mod√®le ne charge pas)
        ```bash
        docker logs -f ollama
        ```
    * **Changer le Mod√®le Utilis√© par D√©faut par `app.py` :** Modifiez la variable d'environnement `OLLAMA_MODEL` dans le fichier `docker-compose.yml` (section `environment:` du service `assistant_app`) et red√©marrez avec `docker compose up -d --build`.

---

## Annexe D : Notes sur les Mises √† Jour G√©n√©rales (Finale)

**Objectif :** Donner des pistes pour maintenir les diff√©rents composants du syst√®me √† jour **de mani√®re contr√¥l√©e**, en utilisant les versions fig√©es comme point de d√©part.

* **Images Docker (`docker-compose.yml` - Versions Fig√©es) :**
    * **Pourquoi Figer ?** Utiliser des tags sp√©cifiques (ex: `ollama:0.1.41`) garantit la stabilit√©. `:latest` peut casser la compatibilit√© sans pr√©avis.
    * **Mise √† Jour Contr√¥l√©e :**
        1.  Recherchez un nouveau tag de version stable pour l'image (ex: `ollama:0.1.45`). Lisez les notes de version ("changelog") si possible pour anticiper les changements majeurs (API modifi√©e, chemins chang√©s...).
        2.  **Sauvegardez votre projet entier ! (Annexe B)**
        3.  Modifiez le tag dans votre fichier `docker-compose.yml`.
        4.  Arr√™tez les services : `docker compose down`.
        5.  Supprimez l'ancienne image localement (optionnel mais propre) : `docker rmi ollama/ollama:0.1.41` (exemple).
        6.  T√©l√©chargez sp√©cifiquement la nouvelle image : `docker pull ollama/ollama:0.1.45` (exemple).
        7.  Red√©marrez les services : `docker compose up -d`. (Utilisez `--build` seulement si `Dockerfile` ou `requirements.txt` ont aussi chang√©).
        8.  Testez attentivement (Script Annexe E + tests fonctionnels). En cas de probl√®me, revenez √† l'ancien tag et restaurez votre sauvegarde si n√©cessaire.

* **D√©pendances Python (`requirements.txt` - Versions Fig√©es) :**
    * **Pourquoi Figer ?** Utiliser `==X.Y.Z` garantit la compatibilit√© test√©e.
    * **Mise √† Jour Contr√¥l√©e (avec GRANDE Prudence) :**
        1.  Identifiez les nouvelles versions souhait√©es. **Attention :** V√©rifiez la compatibilit√© entre les nouvelles versions (surtout Langchain/Chainlit/Pydantic). C'est souvent complexe.
        2.  **Sauvegardez votre projet entier et/ou utilisez Git !**
        3.  Modifiez les num√©ros de version `==X.Y.Z` dans `requirements.txt`.
        4.  Arr√™tez les services : `docker compose down`.
        5.  Forcez la reconstruction de l'image `assistant_app` pour installer les nouvelles versions et red√©marrez :
            ```bash
            docker compose up -d --build
            ```
        6.  Testez **tr√®s attentivement**. Des modifications dans `app.py` sont **souvent n√©cessaires** apr√®s des mises √† jour majeures de Langchain/Chainlit (fonctions d√©pr√©ci√©es, arguments modifi√©s...). Pr√©parez-vous √† d√©boguer le code `app.py`.

* **Mod√®les IA (Ollama, XTTS, SD) :**
    * **Ollama :** Via `docker exec ... ollama pull nom_nouveau_modele:tag`. Mettre √† jour = `rm` + `pull`.
    * **XTTS / SD :** T√©l√©chargez les nouveaux fichiers mod√®les (`.pth`, `.safetensors`) et remplacez/ajoutez-les dans les volumes Docker mapp√©s (`tts-data/cache` ou `khaldounia_sd_models`) via `docker cp` ou acc√®s direct. Pensez √† v√©rifier la compatibilit√© avec la version du service (ex: un nouveau mod√®le XTTS pourrait n√©cessiter une image `:tts` plus r√©cente).

**Conseil G√©n√©ral :** Sauvegardez toujours avant une mise √† jour. Mettez √† jour un seul composant majeur √† la fois et testez intensivement.

---

## Annexe E : Script de Validation Rapide (`validate_khaldounia.sh`)

**Objectif :** Ex√©cuter rapidement une s√©rie de tests de base pour v√©rifier que les principaux services Docker sont d√©marr√©s et que leurs APIs r√©pondent correctement apr√®s une installation ou un red√©marrage.

**Utilisation :**

1.  **Cr√©er le Script :**
    * Dans votre terminal WSL, placez-vous dans `~/projet-khaldounia/assistant-core`.
    * Cr√©ez un nouveau fichier : `nano validate_khaldounia.sh`
    * Collez le contenu suivant dans le fichier :

    ```bash
    #!/bin/bash

    # Script de validation rapide pour les services Khaldounia v1.0

    # Couleurs
    GREEN='\033[0;32m'
    RED='\033[0;31m'
    YELLOW='\033[1;33m'
    NC='\033[0m' # No Color

    # Fonction pour afficher les messages
    log_ok() { echo -e "${GREEN}[OK]${NC} $1"; }
    log_err() { echo -e "${RED}[ERREUR]${NC} $1"; }
    log_warn() { echo -e "${YELLOW}[WARN]${NC} $1"; }
    log_info() { echo -e "\n--- $1 ---"; }

    HAS_ERROR=false

    # --- V√©rification des Conteneurs Docker ---
    log_info "V√©rification des Conteneurs Docker Khaldounia (Attendus: 6 apr√®s Phase 7+)"
    EXPECTED_CONTAINERS=("ollama" "xtts_server" "chromadb" "whisper_server" "stable_diffusion_webui" "assistant_app")
    ALL_RUNNING=true
    for container in "${EXPECTED_CONTAINERS[@]}"; do
        # V√©rifie si le conteneur existe ET est en cours d'ex√©cution (status=running)
        if ! docker ps --format '{{.Names}}' --filter "name=^/${container}$" --filter "status=running" | grep -q "^${container}$"; then
            # Si non d√©marr√©, v√©rifie s'il existe mais est arr√™t√©
            if docker ps -a --format '{{.Names}}' --filter "name=^/${container}$" | grep -q "^${container}$"; then
                 log_err "Conteneur '$container' existe mais n'est PAS DEMARRE (status non 'running') !"
            else
                 log_err "Conteneur '$container' est INTROUVABLE !"
            fi
            ALL_RUNNING=false
            HAS_ERROR=true
        else
            log_ok "Conteneur '$container' est d√©marr√©."
        fi
    done

    if [ "$ALL_RUNNING" = false ]; then
        log_err ">>> Certains conteneurs ne sont pas d√©marr√©s. V√©rifiez 'docker ps -a' et les logs. Arr√™t probable des tests API. <<<"
        # Optionnel : sortir ici si on ne veut pas tester les APIs si les conteneurs ne tournent pas
        # exit 1
    else
        log_ok "--- Tous les conteneurs attendus sont d√©marr√©s. ---"
    fi


    # --- Tests API ---
    log_info "Test API Ollama (localhost:11434)"
    if curl --fail --connect-timeout 5 -s -X POST http://localhost:11434/api/generate -d '{"model":"mistral:latest","prompt":"ping","stream":false}' > /dev/null 2>&1; then
        log_ok "API Ollama r√©pond."
    else
        log_err "√âchec connexion/r√©ponse API Ollama. (Conteneur d√©marr√© ? Mod√®le 'mistral:latest' pr√©sent ?)"
        HAS_ERROR=true
    fi

    log_info "Test API ChromaDB (localhost:8002)"
    if curl --fail --connect-timeout 5 -s http://localhost:8002/api/v1/heartbeat 2>&1 | grep -q "heartbeat"; then
        log_ok "API ChromaDB r√©pond."
    else
        log_err "√âchec connexion/r√©ponse API ChromaDB."
        HAS_ERROR=true
    fi

    log_info "Test API Whisper (localhost:9000)"
    if curl --fail --connect-timeout 5 -s -I http://localhost:9000/health 2>/dev/null | grep -q "200 OK"; then
         log_ok "API Whisper r√©pond (endpoint /health OK)."
    elif curl --fail --connect-timeout 5 -s -o /dev/null http://localhost:9000/ 2>/dev/null; then
         log_ok "Serveur Whisper semble r√©pondre (port 9000 ouvert, racine test√©e)."
    else
        log_warn "√âchec connexion API Whisper (port 9000). V√©rifiez logs 'whisper_server'."
    fi

    log_info "Test API XTTS (localhost:8050)"
    if curl --fail --connect-timeout 5 -s -o /dev/null http://localhost:8050/ 2>/dev/null; then
         log_ok "Serveur XTTS semble r√©pondre (port 8050 ouvert)."
    else
        log_warn "√âchec connexion API XTTS (port 8050). V√©rifiez logs 'xtts_server'."
    fi

    log_info "Test API Stable Diffusion (localhost:7860/docs)"
    if curl --fail --connect-timeout 10 -s http://localhost:7860/docs -o /dev/null 2>/dev/null; then
        log_ok "API Stable Diffusion semble r√©pondre (endpoint /docs accessible)."
    else
        log_warn "√âchec connexion API Stable Diffusion (/docs). V√©rifiez logs 'stable_diffusion_webui' et option --api."
    fi

    log_info "Test Interface Chainlit (localhost:8001)"
     if curl --fail --connect-timeout 5 -s -o /dev/null http://localhost:8001/ 2>/dev/null; then
         log_ok "Serveur Chainlit semble r√©pondre (port 8001 ouvert)."
    else
        log_err "√âchec connexion Interface Chainlit (port 8001). V√©rifiez logs 'assistant_app'."
        HAS_ERROR=true
    fi

    # --- Test Commande Interne Ollama ---
    log_info "Test Liste Mod√®les Ollama (via docker exec)"
    # Capturer la sortie et le code de retour s√©par√©ment
    OLLAMA_LIST_OUTPUT=$(docker exec ollama ollama list 2>&1)
    OLLAMA_LIST_RC=$?
    if [ $OLLAMA_LIST_RC -eq 0 ]; then
        log_ok "Commande 'ollama list' ex√©cut√©e avec succ√®s dans le conteneur."
        log_info "Mod√®les Ollama install√©s :"
        echo "$OLLAMA_LIST_OUTPUT" | sed 's/^/  /' # Affiche la liste indent√©e
    else
        log_err "√âchec ex√©cution 'ollama list' dans le conteneur."
        echo "Sortie d'erreur: $OLLAMA_LIST_OUTPUT"
        HAS_ERROR=true
    fi


    # --- Conclusion ---
    echo -e "\n----------------------------------"
    if [ "$HAS_ERROR" = true ]; then
        log_err "--- Validation termin√©e avec une ou plusieurs ERREURS critiques d√©tect√©es ---"
        echo "Veuillez examiner les erreurs [ERREUR] ci-dessus et consulter les logs des conteneurs concern√©s."
        exit 1
    else
        log_ok "--- Validation termin√©e avec succ√®s (tests de base OK) ---"
        echo "Tous les tests critiques sont r√©ussis. Les services principaux semblent d√©marr√©s et accessibles."
        echo "Effectuez des tests fonctionnels via l'interface Chainlit pour une validation compl√®te."
        exit 0
    fi
    ```
    * Sauvegardez et fermez nano (`Ctrl+O`, `Entr√©e`, `Ctrl+X`).

2.  **Rendre le Script Ex√©cutable :**
    ```bash
    chmod +x validate_khaldounia.sh
    ```

3.  **Lancer le Script (Apr√®s `docker compose up -d`) :**
    ```bash
    ./validate_khaldounia.sh
    ```

* **R√©sultat Attendu :** Le script v√©rifie chaque point et affiche `[OK]`, `[WARN]` ou `[ERREUR]`. S'il termine avec "Validation termin√©e avec succ√®s", l'infrastructure de base est probablement op√©rationnelle. Sinon, il indique les erreurs critiques d√©tect√©es.

---

## Conclusion Finale du Document Plan

Ce document `Installation_Khaldounia_Plan.md` contient maintenant toutes les phases (0 √† 10) et annexes (A √† E) r√©vis√©es et finalis√©es pour l'installation, la configuration initiale, l'utilisation de base, le d√©bogage, la maintenance et la validation de votre assistant Khaldounia, en tenant compte des suggestions d'am√©lioration pour un environnement WSL2 et un utilisateur novice.

---
**FIN DU PLAN D'INSTALLATION ET DE DOCUMENTATION**
